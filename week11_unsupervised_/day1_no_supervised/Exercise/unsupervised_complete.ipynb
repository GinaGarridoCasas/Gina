{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.9 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "5c4d2f1fdcd3716c7a5eea90ad07be30193490dd4e63617705244f5fd89ea793"
   }
  },
  "interpreter": {
   "hash": "7980ba124835d5faa10419b5aaaaec0d5be537aa3d05dd29d745d0092f32015f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "A partir de los datos de iris:\n",
    "\n",
    "Ejercicio 1:\n",
    "\n",
    "- Carga los datos originales\n",
    "- Utiliza PCA para reducir la dimensionalidad de los datos. No reemplaces X con el resultado, crea una nueva X_pca. Utiliza PCA(2) y otra con PCA(3)\n",
    "- Utiliza Kmeans para agrupar y predecir las clases de los nuevos datos.\n",
    "- Compara los resultados para PCA(2) y PCA(3) con las clases originales (y_real).\n",
    "- ¿Es mejor PCA(2) o PCA(3)?\n",
    "\n",
    "Ejercicio 2: \n",
    "\n",
    "- Repite el proceso con T-SNE y DBSCAN. ¿Cuál da mejores resultados?\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "# al aplicar PCA se asume que los datos de trabajo tienen una distribución gaussiana o normal.  Por tanto, aplicamos a los datos una transformación de normalización de forma que su media sea igual a 0, y su varianza=1. Para ello, usaremos la transformación Standardscaler de sklearn.\n",
    "X = StandardScaler().fit_transform(X)\n",
    "y = iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Creamos el dataframe\n",
    "df = pd.DataFrame(data=iris.data, columns=iris.get(\"feature_names\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "source": [
    "### 2 componentes principales"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establecemos el número de componentes que queremos obtener a partir de las variables que tenemos en nuestro dataFrame\n",
    "\n",
    "pca = PCA(n_components=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "PCA(n_components=2)"
      ]
     },
     "metadata": {},
     "execution_count": 92
    }
   ],
   "source": [
    "# Fijamos el modelo para las variables predictoras de la muestra de entrenamiento\n",
    "pca.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0.71537436, 0.24083209])"
      ]
     },
     "metadata": {},
     "execution_count": 93
    }
   ],
   "source": [
    "# Hallamos la varianza explicativa de la mejor proyección de nuestro PCA. El primer valor es la varianza explicativa de nuestro modelo con la muestra de entrenamiento\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformamos nuestras variables predictoras según nuestro modelo en dos componentes principales\n",
    "# se obtiene el valor que toma cada componente para cada observación en función de las variables originales  \n",
    "\n",
    "X_pca_2_train = pca.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 1-dimensional, but 2 were indexed",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-108-9c5f24d6ef30>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXax\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mix\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mYax\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mix\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcdict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabl\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m40\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmarker\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmarker\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"First Principal Component\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfontsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m14\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for array: array is 1-dimensional, but 2 were indexed"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#graficamos en 2 Dimensiones, tomando los 2 primeros componentes principales\n",
    "Xax=X_pca_2_train[:,0]\n",
    "Yax=X_pca_2_train[:,1]\n",
    "labels=X\n",
    "cdict={0:'red',1:'green'}\n",
    "alpha={0:.3, 1:.5}\n",
    "fig,ax=plt.subplots(figsize=(7,5))\n",
    "fig.patch.set_facecolor('white')\n",
    "for l in np.unique(labels):\n",
    "    ix=np.where(labels==l)\n",
    "    ax.scatter(Xax[ix],Yax[ix],c=cdict[l],label=labl[l],s=40,marker=marker[l],alpha=alpha[l])\n",
    " \n",
    "plt.xlabel(\"First Principal Component\",fontsize=14)\n",
    "plt.ylabel(\"Second Principal Component\",fontsize=14)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "PCA(n_components=2)"
      ]
     },
     "metadata": {},
     "execution_count": 95
    }
   ],
   "source": [
    "# Fijamos el modelo para las variables predictoras de la muestra de test\n",
    "pca.fit(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0.7900007 , 0.17758282])"
      ]
     },
     "metadata": {},
     "execution_count": 96
    }
   ],
   "source": [
    "# Hallamos la varianza explicativa de la mejor proyección de nuestro PCA. El primer valor es la varianza explicativa de nuestro modelo con la muestra de test\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "source": [
    "### 3 componentes principales"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "PCA(n_components=3)"
      ]
     },
     "metadata": {},
     "execution_count": 98
    }
   ],
   "source": [
    "pca.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0.71537436, 0.24083209, 0.03901736])"
      ]
     },
     "metadata": {},
     "execution_count": 99
    }
   ],
   "source": [
    "# No se observa incremento de varianza explicativa respecto a 2 componentes así que con dos componentes principales es suficiente \n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "  X_pca_3_train = pca.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "PCA(n_components=3)"
      ]
     },
     "metadata": {},
     "execution_count": 101
    }
   ],
   "source": [
    "pca.fit(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0.7900007 , 0.17758282, 0.02604515])"
      ]
     },
     "metadata": {},
     "execution_count": 102
    }
   ],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "source": [
    "### 4. Kmeans"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nkmeans.labels_: [1 1 0 1 1 0 0 1 1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0\n 0 1 0 0 1 0 0 0 0 0 0 1 0 0 1 1 0 0 1 0 1 1 0 0 0 0 0 0 0 1 1 0 0 1 1 1 0\n 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0\n 0 0 0 1 0 0 1 0 0]\npredict: [1 1 0 1 1 0 0 1 1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0\n 0 1 0 0 1 0 0 0 0 0 0 1 0 0 1 1 0 0 1 0 1 1 0 0 0 0 0 0 0 1 1 0 0 1 1 1 0\n 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0\n 0 0 0 1 0 0 1 0 0]\nkmeans.cluster_centers_:\n [[ 1.10751085  0.14710663]\n [-2.21502169 -0.29421326]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "\n",
    "kmeans = KMeans(n_clusters=2, random_state=0).fit(X_pca_2_train)\n",
    "print(\"\\nkmeans.labels_:\", kmeans.labels_)\n",
    "y_predict = kmeans.fit_predict(X_pca_2_train)\n",
    "print(\"predict:\", y_predict)\n",
    "clusters = kmeans.cluster_centers_\n",
    "print(\"kmeans.cluster_centers_:\\n\", clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nkmeans.labels_: [1 1 0 1 1 0 0 1 1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0\n 0 1 0 0 1 0 0 0 0 0 0 1 0 0 1 1 0 0 1 0 1 1 0 0 0 0 0 0 0 1 1 0 0 1 1 1 0\n 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0\n 0 0 0 1 0 0 1 0 0]\npredict: [1 1 0 1 1 0 0 1 1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0\n 0 1 0 0 1 0 0 0 0 0 0 1 0 0 1 1 0 0 1 0 1 1 0 0 0 0 0 0 0 1 1 0 0 1 1 1 0\n 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0\n 0 0 0 1 0 0 1 0 0]\nkmeans.cluster_centers_:\n [[ 1.10751085  0.14710663  0.01949137]\n [-2.21502169 -0.29421326 -0.03898273]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "\n",
    "kmeans = KMeans(n_clusters=2, random_state=0).fit(X_pca_3_train)\n",
    "print(\"\\nkmeans.labels_:\", kmeans.labels_)\n",
    "y_predict = kmeans.fit_predict(X_pca_3_train)\n",
    "print(\"predict:\", y_predict)\n",
    "clusters = kmeans.cluster_centers_\n",
    "print(\"kmeans.cluster_centers_:\\n\", clusters)"
   ]
  },
  {
   "source": [
    "### Comparar el modelo de PCA con las clases originales"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fijamos el modelo para todos los valores\n",
    "pca.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# varianza explicada para todos los valores\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}