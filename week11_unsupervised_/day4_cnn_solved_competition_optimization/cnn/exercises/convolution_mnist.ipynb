{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir del dataset mnist (tf.keras.datasets.mnist.load_data()), realiza una clasificación usando:\r\n",
    "\r\n",
    "1. Una CNN con:\r\n",
    "    - 1 capa convolutiva con 8 neuronas\r\n",
    "    - 1 MaxPool quedando las dimensiones de la imagen a la mitad\r\n",
    "    - 1 dropout 0.25\r\n",
    "    - 1 Flatten\r\n",
    "    - 1 dense con 32 neuronas\r\n",
    "    - 1 dense con 10 (salida)\r\n",
    "\r\n",
    "2. Una CNN con:\r\n",
    "    - 1 capa convolutiva con 8 neuronas\r\n",
    "    - 1 MaxPool quedando las dimensiones de la imagen a la mitad\r\n",
    "    - 1 dropout 0.25\r\n",
    "    - 1 Flatten\r\n",
    "    - 1 dense con 16 neuronas\r\n",
    "    - 1 dense con 32 neuronas\r\n",
    "    - 1 dense con 10 (salida)\r\n",
    "\r\n",
    "¿ Cuál ha dado mejor resultado? El segundo. Al poner más capas de neuronas, mejora\r\n",
    "\r\n",
    "\r\n",
    "Para compilar el modelo, usa:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow y tf.keras\r\n",
    "import tensorflow as tf\r\n",
    "from tensorflow import keras\r\n",
    "from tensorflow.keras import datasets, layers, models\r\n",
    "from keras.layers import Dropout\r\n",
    "\r\n",
    "# Librerias de ayuda\r\n",
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descargamos el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits_mnist = keras.datasets.mnist\r\n",
    "\r\n",
    "(x_train, y_train), (x_test, y_test)= digits_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\r\n",
    "x_train = x_train.reshape(-1, 28,28,1)# pasar de 3 a 4 dimensiones\r\n",
    "x_train=tf.cast(x_train,tf.float32) # para pasar de tipo uint8 a float32  \r\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = x_test.reshape(-1, 28,28,1)\r\n",
    "x_test=tf.cast(x_test,tf.float32) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploramos los datos del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([60000, 28, 28, 1])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([10000, 28, 28, 1])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construimos el modelo 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\r\n",
    "model.add(layers.Conv2D(filters=8,kernel_size=(3,3))                        )\r\n",
    "model.add(layers.Dropout(0.25))\r\n",
    "model.add(layers.MaxPooling2D(pool_size=(14,14))), \r\n",
    "model.add(layers.Flatten())\r\n",
    "model.add(layers.Dense(32, activation='relu'))\r\n",
    "model.add(layers.Dense(10,activation='softmax'))\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Añadimos algunas configuraciones más antes de entrenar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',# Aporta información sobre cómo el modelo se va actualizando con el set de datos\r\n",
    "              loss='sparse_categorical_crossentropy', # Aporta información sobre la exactitud del modelo durante el entrenamiento\r\n",
    "              metrics=['accuracy']) # permite monitorizar el proceso de entrenamiento y test. Se utiliza el método accuracy (exactitud)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 1.0431 - accuracy: 0.5980\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 21s 11ms/step - loss: 1.0373 - accuracy: 0.6008\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 1.0367 - accuracy: 0.6003\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 1.0277 - accuracy: 0.6039\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 16s 9ms/step - loss: 1.0281 - accuracy: 0.6046\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 1.0247 - accuracy: 0.6071\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 1.0219 - accuracy: 0.6072\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 1.0217 - accuracy: 0.6075\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 16s 8ms/step - loss: 1.0188 - accuracy: 0.6094\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 1.0155 - accuracy: 0.6100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x19a98a22b20>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluamos la exactitud del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 2s - loss: 0.9948 - accuracy: 0.6267\n",
      "\n",
      "Test accuracy: 0.6266999840736389\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(x_test,  y_test, verbose=2)\r\n",
    "\r\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hacemos predicciones sobre el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construimos el modelo 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\r\n",
    "model.add(layers.Conv2D(filters=8,kernel_size=(3,3))                        )\r\n",
    "model.add(layers.Dropout(0.25))\r\n",
    "model.add(layers.MaxPooling2D(pool_size=(14,14))), \r\n",
    "model.add(layers.Flatten())\r\n",
    "model.add(layers.Dense(16, activation='relu'))\r\n",
    "model.add(layers.Dense(32, activation='relu'))\r\n",
    "model.add(layers.Dense(10,activation='softmax'))\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',# Aporta información sobre cómo el modelo se va actualizando con el set de datos\r\n",
    "              loss='sparse_categorical_crossentropy', # Aporta información sobre la exactitud del modelo durante el entrenamiento\r\n",
    "              metrics=['accuracy']) # permite monitorizar el proceso de entrenamiento y test. Se utiliza el método accuracy (exactitud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 18s 9ms/step - loss: 2.4631 - accuracy: 0.3800\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 1.3042 - accuracy: 0.4887\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 1.1891 - accuracy: 0.5321\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 18s 9ms/step - loss: 1.1257 - accuracy: 0.5612\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 18s 9ms/step - loss: 1.0979 - accuracy: 0.5751\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 1.0900 - accuracy: 0.5816\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 22s 12ms/step - loss: 1.0715 - accuracy: 0.5883\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 20s 10ms/step - loss: 1.0596 - accuracy: 0.5929\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 16s 9ms/step - loss: 1.0524 - accuracy: 0.5976\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 21s 11ms/step - loss: 1.0510 - accuracy: 0.5979\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x19ab8869d30>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 1s - loss: 1.0158 - accuracy: 0.6193\n",
      "\n",
      "Test accuracy: 0.6193000078201294\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(x_test,  y_test, verbose=2)\r\n",
    "\r\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}