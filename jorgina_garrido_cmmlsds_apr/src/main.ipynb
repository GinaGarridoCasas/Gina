{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENS_2017 = pd.read_csv(\"../Data/Bases_originales/ENS_2017_Adultos_1.csv\", sep =';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENS_2017.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Mining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Se eliminan algunas columnas que no tienen interés para el proyecto\r\n",
    "\r\n",
    "#### Se eliminan las columnas correspondientes a los apartados:\r\n",
    "- Identificación del hogar\r\n",
    "- Identificación del informante\r\n",
    "- Relación de la persona seleccionada con la actividad económica\r\n",
    "- Módulo europeo del estado de salud. Se mantiene únicamente del módulo: Estado de salud, la pregunta referente a 'Estado de salud percibido en los últimos 12 meses' y el módulo de prácticas preventivas\r\n",
    "- Módulo determinantes de salud, se han mantenido las más genéricas de cada apartado. Se han eliminado las del apartado referente a: cuidado de otras personas con problemas de salud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TO_ENS_2017 = ['IDENTHOGAR', 'A7_2a', 'PROXY_0','PROXY_1', 'PROXY_2', 'PROXY_2b', 'PROXY_3b', 'PROXY_4', 'PROXY_5', 'E2_1c', 'E2_1d','E3','F6', 'F7','F8_2','F9_2','F10','F11','F12','F13','F14a','F14b','F15','F16','F17','F18a_2','F18b_2','F19a_2','F19b_2','F20',\r\n",
    "'G22','G23','G24','G25a_1','G25b_1','G25c_1','G25a_2','G25b_2','G25c_2','G25a_3','G25b_3','G25c_3','G25a_4','G25b_4','G25c_4','G25a_5','G25b_5','G25c_5','G25a_6','G25b_6','G25c_6','G25a_7','G25b_7','G25c_7','G25a_8','G25b_8','G25c_8','G25a_9','G25b_9','G25c_9','G25a_10','G25b_10','G25c_10','G25a_11','G25b_11','G25c_11','G25a_12','G25b_12','G25c_12','G25a_13','G25b_13','G25c_13','G25a_14','G25b_14','G25c_14','G25a_15','G25b_15','G25c_15','G25a_16','G25b_16','G25c_16','G25a_17','G25b_17','G25c_17','G25a_18','G25b_18','G25c_18','G25a_19','G25b_19','G25c_19','G25a_20','G25b_20','G25c_20','G25a_21','G25b_21','G25c_21','G25a_22','G25b_22','G25c_22','G25a_23','G25b_23','G25c_23','G25a_24','G25b_24','G25c_24','G25a_25','G25b_25','G25c_25','G25a_26','G25b_26','G25c_26','G25a_27','G25b_27','G25c_27','G25a_28','G25b_28','G25c_28','G25a_29','G25b_29','G25c_29','G25a_30','G25b_30','G25c_30','G25a_31','G25b_31','G25c_31','G25a_32','G25b_32','G25c_32',\r\n",
    "'H26_1','H26_2','H26_3','H27',\r\n",
    "'I28_1','I28_2','I29_1','I29_2',\r\n",
    "'K32','K33','K34','K35','K36','K37','K38','K38a',\r\n",
    "'L39_1','L39_2','L39_3','L39_4','L39_5','L40','L41','L42_1','L42_2','L42_3','L42_4','L42_5','L42_6','L42_7','L43','L44','L45','L46','M47_1','M47_2','M47_3','M47_4','M47_5','M47_6','M47_7','M47_8','M47_9','M47_10','M47_11','M47_12','M47a','M47b',\r\n",
    "'N48','N49','N50','N51','N52','N53','N54','N55_1','N55_2','N55_3','N56_1','N56_2','N56_3','N57','N58_1','N58_2','N58_3','N59','N60_1','N60_2','N60_3','N60_4','N60a_1','N60a_2','N60a_3','N60a_4','N61_1','N61_2','N61_3','N61_4','N61_5','N62','N62b','N63_1','N63_2','N63_3','N63_4','N63_5','N63_6','N63_7','N63_8','N63_9','N63_10','N64','N65_1','N65_2','N65_3','N65_4','N65_5','N65_6','N65_7','N65_8',\r\n",
    "'O66','O67','O69','O70','O71','O72','O73','O74','O75','O76','O77','O78','O79','O80_1','O80_2','O80_3','O81_1','O81_2','O81_3','O82_1','O82_2','O83','O84_1','O84_2','O84_3','O84_4','O84_5','O84_6','O84_7','O84_8','O84_9',\r\n",
    "'P85','P86','P87_1a','P87_1b','P87_2a','P87_2b','P87_3a','P87_3b','P87_4a','P87_4b','P87_5a','P87_5b','P87_6a','P87_6b','P87_7a','P87_7b','P87_8a','P87_8b','P87_9a','P87_9b','P87_10a','P87_10b','P87_11a','P87_11b','P87_12a','P87_12b','P87_13a','P87_13b','P87_14a','P87_14b','P87_15a','P87_15b','P87_16a','P87_16b','P87_17a','P87_17b','P87_18a','P87_18b','P87_19a','P87_19b','P87_20a','P87_20b','P87_21a','P87_21b','P87_22a','P87_22b','P87_23a','P87_23b',\r\n",
    "'Q90', 'Q92','Q94', 'Q96', 'Q97', 'Q99', 'Q100', 'Q101','Q102','Q103','Q104','Q105',\r\n",
    "'R106','R107','R108_1','R108_2','R108_3','R108_4','T111', 'T113', 'T114_1','T114_2', 'T115', 'T116_1', 'T116_2', 'T117', 'T117', 'T118_2','T118_1','T119_1','T119_2',\r\n",
    "'U120_1a','U120_7a','U120_15a','U120FZ','U120CANTFZ',\r\n",
    "'V122','V123','V124','V125','V126',\r\n",
    "'W128Cer','W128Cer_1','W128Cer_2','W128Cer_3','W128Cer_4','W128Cer_5','W128Cer_6','W128Cer_7','W128Vin','W128Vin_1','W128Vin_2','W128Vin_3','W128Vin_4','W128Vin_5','W128Vin_6','W128Vin_7','W128Vermut','W128Vermut_1','W128Vermut_2','W128Vermut_3','W128Vermut_4','W128Vermut_5','W128Vermut_6','W128Vermut_7','W128Lic','W128Lic_1','W128Lic_2','W128Lic_3','W128Lic_4','W128Lic_5','W128Lic_6','W128Lic_7','W128Comb','W128Comb_1','W128Comb_2','W128Comb_3',\r\n",
    "'W128Comb_4','W128Comb_5','W128Comb_6','W128Comb_7',\r\n",
    "'W128Sidra','W128Sidra_1','W128Sidra_2','W128Sidra_3',\r\n",
    "'W128Sidra_4','W128Sidra_5','W128Sidra_6','W128Sidra_7','W129','Y133','Y134','Y135','CMD1','CMD2','CMD3','FACTORADULTO',\r\n",
    "'Unnamed: 455']\r\n",
    "\r\n",
    "ENS_2017.drop(TO_ENS_2017, inplace = True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vemos las características de la nueva base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENS_2017.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENS_2017.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENS_2017.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crea una nueva base para hacer las modificaciones necesarias\r\n",
    "ENS_2017_1 = ENS_2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calidad de los datos de la base\r\n",
    "### Missing\r\n",
    "#### Pasamos las categorías de \"no sabe\", \"no contesta\" a missing y vemos en qué variables tenemos más de un 10% de missing. En caso de que haya alguna, la eliminaremos. Si el porcentaje de missing es inferior al 10% se sustituirán por la moda en las variables categóricas y por la mediana en las numéricas (Altura y Peso). En las variables de, CCAA, sexo y edad no existe la opción de \"no sabe\", \"no contesta\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_categoricas = ['ACTIVa', 'E1_1', 'E2_1a', 'E2_1b', 'E4',\r\n",
    "       'E4b', 'NIVEST', 'G21', 'Q88', 'Q89', 'Q91', 'Q93', 'Q95', 'Q98',\r\n",
    "       'S109', 'S110', 'T112', 'U120_1', 'U120_2', 'U120_3', 'U120_4',\r\n",
    "       'U120_5', 'U120_6', 'U120_7', 'U120_8', 'U120_9', 'U120_10', 'U120_11',\r\n",
    "       'U120_12', 'U120_13', 'U120_14', 'U120_15', 'U2_120F', 'V121', 'W127',\r\n",
    "       'X130_1', 'X130_2', 'X130_3', 'X130_4', 'X130_5', 'X130_6', 'X130_7',\r\n",
    "       'X130_8', 'X130_9', 'X130_10', 'X130_11', 'CLASE_PR', 'IMCa']\r\n",
    "\r\n",
    "for i in variables_categoricas:\r\n",
    "    \r\n",
    "    if i == 'ACTIVa':\r\n",
    "        ENS_2017_1['ACTIVa']= ENS_2017_1['ACTIVa'].replace({7: np.nan, 8: np.nan})\r\n",
    "        \r\n",
    "        na_ratio = ((ENS_2017_1[i].isnull().sum() / len(ENS_2017_1[i]))*100)\r\n",
    "        print (f'El porcentaje de missing value de la variable {i} es: {na_ratio}')\r\n",
    "    \r\n",
    "        ENS_2017_1[i].fillna(ENS_2017_1[i].mode()[0], inplace=True)\r\n",
    "        print(\"missing value, una vez sustituidos por la moda: \" + str(ENS_2017_1[i].isnull().sum()))\r\n",
    "    \r\n",
    "\r\n",
    "    elif i == 'NIVEST' or i == 'W127':\r\n",
    "        ENS_2017_1['NIVEST']= ENS_2017_1['NIVEST'].replace({98: np.nan, 99: np.nan})\r\n",
    "        ENS_2017_1['W127']= ENS_2017_1['W127'].replace({98: np.nan, 99: np.nan})\r\n",
    "        \r\n",
    "        na_ratio = ((ENS_2017_1[i].isnull().sum() / len(ENS_2017_1[i]))*100)\r\n",
    "        print (f'El porcentaje de missing value de la variable {i} es: {na_ratio}')\r\n",
    "    \r\n",
    "        ENS_2017_1[i].fillna(ENS_2017_1[i].mode()[0], inplace=True)\r\n",
    "        print(\"missing value, una vez sustituidos por la moda: \" + str(ENS_2017_1[i].isnull().sum()))\r\n",
    "\r\n",
    "    elif i == 'CLASE_PR' or i == 'IMCa':\r\n",
    "        ENS_2017_1['CLASE_PR']= ENS_2017_1['CLASE_PR'].replace({9: np.nan})\r\n",
    "        ENS_2017_1['IMCa']= ENS_2017_1['IMCa'].replace({9: np.nan})\r\n",
    "        \r\n",
    "        na_ratio = ((ENS_2017_1[i].isnull().sum() / len(ENS_2017_1[i]))*100)\r\n",
    "        print (f'El porcentaje de missing value de la variable {i} es: {na_ratio}')\r\n",
    "    \r\n",
    "        ENS_2017_1[i].fillna(ENS_2017_1[i].mode()[0], inplace=True)\r\n",
    "        print(\"missing value, una vez sustituidos por la moda: \" + str(ENS_2017_1[i].isnull().sum())) \r\n",
    "\r\n",
    "    else:\r\n",
    "        ENS_2017_1[i]= ENS_2017_1[i].replace({8: np.nan, 9: np.nan})\r\n",
    "\r\n",
    "        na_ratio = ((ENS_2017_1[i].isnull().sum() / len(ENS_2017_1[i]))*100)\r\n",
    "        print (f'El porcentaje de missing value de la variable {i} es: {na_ratio}')\r\n",
    "        \r\n",
    "        ENS_2017_1[i].fillna(ENS_2017_1[i].mode()[0], inplace=True)\r\n",
    "        print(\"missing value, una vez sustituidos por la moda: \" + str(ENS_2017_1[i].isnull().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_numericas = ['S109','S110']\r\n",
    "\r\n",
    "for i in variables_numericas:\r\n",
    "\r\n",
    "    ENS_2017_1[i]= ENS_2017_1[i].replace({998: np.nan, 999: np.nan})\r\n",
    "        \r\n",
    "    na_ratio = ((ENS_2017_1[i].isnull().sum() / len(ENS_2017_1[i]))*100)\r\n",
    "    print (f'El porcentaje de missing value de la variable {i} es: {na_ratio}')\r\n",
    "    \r\n",
    "    ENS_2017_1[i].fillna(ENS_2017_1[i].median(), inplace=True)\r\n",
    "    print(\"missing value, una vez sustituidos por la moda: \" + str(ENS_2017_1[i].isnull().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Duplicados = ENS_2017_1.duplicated()\r\n",
    "Duplicados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,6))\r\n",
    "\r\n",
    "boxplot = ENS_2017_1.boxplot(column=['CCAA', 'SEXOa', 'EDADa', 'ACTIVa'])\r\n",
    "boxplot.plot()\r\n",
    "\r\n",
    "plt.savefig(\"../reports/outliers/ENS_2017_1.1.jpg\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,6))\r\n",
    "\r\n",
    "boxplot = ENS_2017_1.boxplot(column=['E1_1', 'E2_1a', 'E2_1b','E4', 'E4b', 'NIVEST'])\r\n",
    "boxplot.plot()\r\n",
    "\r\n",
    "plt.savefig(\"../reports/outliers/ENS_2017_1.2.jpg\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,6))\r\n",
    "\r\n",
    "boxplot = ENS_2017_1.boxplot(column=['G21', 'Q88', 'Q89', 'Q91'])\r\n",
    "boxplot.plot()\r\n",
    "\r\n",
    "plt.savefig(\"../reports/outliers/ENS_2017_1.3.jpg\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,6))\r\n",
    "\r\n",
    "boxplot = ENS_2017_1.boxplot(column=['Q93', 'Q95', 'Q98','T112'])\r\n",
    "boxplot.plot()\r\n",
    "\r\n",
    "plt.savefig(\"../reports/outliers/ENS_2017_1.4.jpg\", bbox_inches='tight')\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,6))\r\n",
    "\r\n",
    "boxplot = ENS_2017_1.boxplot(column=['S109', 'S110'])\r\n",
    "boxplot.plot()\r\n",
    "\r\n",
    "plt.savefig(\"../reports/outliers/ENS_2017_1.5.jpg\", bbox_inches='tight')\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,6))\r\n",
    "\r\n",
    "boxplot = ENS_2017_1.boxplot(column=['U120_1', 'U120_2','U120_3', 'U120_4','U120_5', 'U120_6'])\r\n",
    "boxplot.plot()\r\n",
    "\r\n",
    "plt.savefig(\"../reports/outliers/ENS_2017_1.6.jpg\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,6))\r\n",
    "\r\n",
    "boxplot = ENS_2017_1.boxplot(column=['U120_7', 'U120_8', 'U120_9', 'U120_10', 'U120_11', 'U120_12','U120_13', 'U120_14', 'U120_15'])\r\n",
    "boxplot.plot()\r\n",
    "\r\n",
    "plt.savefig(\"../reports/outliers/ENS_2017_1.7.jpg\", bbox_inches='tight')\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,6))\r\n",
    "\r\n",
    "boxplot = ENS_2017_1.boxplot(column=['U2_120F', 'V121', 'W127'])\r\n",
    "boxplot.plot()\r\n",
    "\r\n",
    "plt.savefig(\"../reports/outliers/ENS_2017_1.8.jpg\", bbox_inches='tight')\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,6))\r\n",
    "\r\n",
    "boxplot = ENS_2017_1.boxplot(column=['X130_1', 'X130_2', 'X130_3', 'X130_4', 'X130_5', 'X130_6', 'X130_7','X130_8', 'X130_9', 'X130_10', 'X130_11'])\r\n",
    "boxplot.plot()\r\n",
    "\r\n",
    "plt.savefig(\"../reports/outliers/ENS_2017_1.9.jpg\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,6))\r\n",
    "\r\n",
    "boxplot = ENS_2017_1.boxplot(column=['CLASE_PR','IMCa'])\r\n",
    "boxplot.plot()\r\n",
    "\r\n",
    "plt.savefig(\"../reports/outliers/ENS_2017_1.10.jpg\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renombramos las variables que entran en el proyecto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENS_2017_1 = ENS_2017_1.rename(columns = \r\n",
    "{'SEXOa': 'Sexo', \r\n",
    "'EDADa': 'Edad', \r\n",
    "'ACTIVa': 'Actividad_economica_actual', \r\n",
    "'E1_1': 'País_nacimiento',\r\n",
    "'E2_1a': 'Nacionalidad_española', \r\n",
    "'E2_1b':'Nacionalidad_extranjera',\r\n",
    "'E4': 'Convivencia', \r\n",
    "'E4b': 'Estado_civil', \r\n",
    "'NIVEST': 'Nivel_estudios',\r\n",
    "'G21': 'Salud_percibida', \r\n",
    "'Q88':'Vacunación_gripe',\r\n",
    "'Q89':'Toma_tensiónArterial_profesional',\r\n",
    "'Q91': 'Medición_colesterol', \r\n",
    "'Q93': 'Medición_azúcarSangre', \r\n",
    "'Q95': 'Prueba_sangreHeces', \r\n",
    "'Q98': 'Colonoscopia',\r\n",
    "'S109': 'Altura(cm)', \r\n",
    "'S110':'Peso(Kg)',\r\n",
    "'T112': 'Freq_ActividadFísica', \r\n",
    "'U120_1': 'Freq_Consumo_FrutaFresca', \r\n",
    "'U120_2': 'Freq_Consumo_Carne',\r\n",
    "'U120_3': 'Freq_Consumo_Huevos', \r\n",
    "'U120_4':'Freq_Consumo_Pescado',\r\n",
    "'U120_5': 'Freq_Consumo_PastaArrozPatatas', \r\n",
    "'U120_6': 'Freq_Consumo_PanCereales',\r\n",
    "'U120_7': 'Freq_Consumo_VerdurasEnsaladasHortalizas', \r\n",
    "'U120_8':'Freq_Consumo_Legumbres',\r\n",
    "'U120_9': 'Freq_Consumo_EmbutidosFiambres', \r\n",
    "'U120_10': 'Freq_Consumo_Lácteos',\r\n",
    "'U120_11': 'Freq_Consumo_Dulces', \r\n",
    "'U120_12':'Freq_Consumo_RefrescosAzúcar',\r\n",
    "'U120_13': 'Freq_Consumo_ComidaRápida', \r\n",
    "'U120_14': 'Freq_Consumo_Aperitivos',\r\n",
    "'U120_15': 'Freq_Consumo_ZumoNatural', \r\n",
    "'U2_120F':'Freq_Diaria_CepilladoDientes',\r\n",
    "'V121': '¿Fuma actualmente',\r\n",
    "'W127': 'Freq_Consumo_Alcohol', \r\n",
    "'X130_1':'ApoyoAfectivoPersonal_AmigosFamiliares',\r\n",
    "'X130_2': 'ApoyoAfectivoPersonal_AsuntosCasa', \r\n",
    "'X130_3': 'ApoyoAfectivoPersonal_ReconocimientoTrabajo',\r\n",
    "'X130_4': 'ApoyoAfectivoPersonal_PersonasSePreocupan', \r\n",
    "'X130_5':'ApoyoAfectivoPersonal_RecibirAmorAfecto',\r\n",
    "'X130_6':'ApoyoAfectivoPersonal_HablarProblemasTrabajoCasa',\r\n",
    "'X130_7': 'ApoyoAfectivoPersonal_HablarProblemasPersonalesFamiliares', \r\n",
    "'X130_8': 'ApoyoAfectivoPersonal_HablarProblemasEconómicos',\r\n",
    "'X130_9': 'ApoyoAfectivoPersonal_RecibirInvitacionesSalirConOtrasPersonas', \r\n",
    "'X130_10':'ApoyoAfectivoPersonal_RecibirConsejosÚtiles',\r\n",
    "'X130_11':'ApoyoAfectivoPersonal_RecibirAyudaEnfermoCama',\r\n",
    "'CLASE_PR':'ClaseSocial_BasadaOcupación',\r\n",
    "'IMCa':'Índice_MasaCorporal'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Archivamos la base con los cambios realizados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENS_2017_valida = ENS_2017_1\r\n",
    "\r\n",
    "ENS_2017_valida.to_csv('../data/Bases_trabajo/ENS_2017_valida.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENS_2017_valida = pd.read_csv(\"../data/Bases_trabajo/ENS_2017_valida.csv\", sep =',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se elimina la columna 'Unnamed: 0'\r\n",
    "TO_ENS_2017_valida = ['Unnamed: 0']\r\n",
    "ENS_2017_valida.drop(TO_ENS_2017_valida, inplace = True, axis=1)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vemos la distribución de la variable dependiente\r\n",
    "\r\n",
    "freq_R = ENS_2017_valida['Salud_percibida'].value_counts() / len(ENS_2017_valida['Salud_percibida'])*100\r\n",
    "freq_R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creo una base de datos en la que la VD tendrán 3 valores\r\n",
    "\r\n",
    "ENS_2017_valida_1 = ENS_2017_valida"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recodificamos la variable dependiente (VD): Salud percibida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENS_2017_valida_1['Salud_percibida'] = ENS_2017_valida_1['Salud_percibida'].replace({2:1,3:2,4:3,5:3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_R_1 = ENS_2017_valida_1['Salud_percibida'].value_counts() / len(ENS_2017_valida_1['Salud_percibida'])*100\r\n",
    "freq_R_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENS_2017_valida_1.to_csv('../data/Bases_trabajo/ENS_2017_valida_1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vemos las correlaciones de todas las variables entre sí. Nos centramos en la de la VD con el resto\r\n",
    "\r\n",
    "### Para poder ver con claridad la información de las correlaciones en los gráficos de Heatmap, creamos diferentes dataframes en los que se incluye la VD con grupos del resto de variables en cada uno de ellos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Salud_percibida_1 = ENS_2017_valida_1.iloc[:,[10,0,1,2,3,4,5,6,7,8,9]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Salud_percibida_2 = ENS_2017_valida_1.iloc[:,[10,11,12,13,14,15,16,17,18]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Salud_percibida_3 = ENS_2017_valida_1.iloc[:,[10,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Salud_percibida_4 = ENS_2017_valida_1.iloc[:,[10,35,36,37,38,39,40,41,42,43,44,45,46,47,48]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Salud_percibida_5 = ENS_2017_valida_1.iloc[:,[10,49,50]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(13, 10))\r\n",
    "sns.heatmap(Salud_percibida_1.corr(),\r\n",
    "           vmin = -1,\r\n",
    "           vmax = 1,\r\n",
    "            annot = True,\r\n",
    "           linewidths = .5)\r\n",
    "\r\n",
    "plt.savefig(\"../reports/heatmap/Salud_percibida_1.jpg\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(13, 10))\r\n",
    "sns.heatmap(Salud_percibida_2.corr(),\r\n",
    "           vmin = -1,\r\n",
    "           vmax = 1,\r\n",
    "            annot = True,\r\n",
    "           linewidths = .5)\r\n",
    "plt.savefig(\"../reports/heatmap/Salud_percibida_2.jpg\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(13, 10))\r\n",
    "sns.heatmap(Salud_percibida_3.corr(),\r\n",
    "           vmin = -1,\r\n",
    "           vmax = 1,\r\n",
    "            annot = True,\r\n",
    "           linewidths = .5)\r\n",
    "\r\n",
    "plt.savefig(\"../reports/heatmap/Salud_percibida_3.jpg\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(13, 10))\r\n",
    "sns.heatmap(Salud_percibida_4.corr(),\r\n",
    "           vmin = -1,\r\n",
    "           vmax = 1,\r\n",
    "            annot = True,\r\n",
    "           linewidths = .5)\r\n",
    "\r\n",
    "plt.savefig(\"../reports/heatmap/Salud_percibida_4.jpg\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(9, 8))\r\n",
    "sns.heatmap(Salud_percibida_5.corr(),\r\n",
    "           vmin = -1,\r\n",
    "           vmax = 1,\r\n",
    "            annot = True,\r\n",
    "           linewidths = .5)\r\n",
    "plt.savefig(\"../reports/heatmap/Salud_percibida_5.jpg\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Se eliminan las variables entre las que existe mayor colinealidad (Pearson >= 0.40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos una nueva base de datos en la que se eliminan las columnas con variables colineales\r\n",
    "ENS_2017_valida_2 = ENS_2017_valida_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TO_ENS_2017_valida_2 = ['País_nacimiento','Nacionalidad_extranjera','Medición_azúcarSangre','Altura(cm)','Freq_Consumo_RefrescosAzúcar', 'Freq_Consumo_Aperitivos','ApoyoAfectivoPersonal_AsuntosCasa',\r\n",
    "       'ApoyoAfectivoPersonal_ReconocimientoTrabajo',\r\n",
    "       'ApoyoAfectivoPersonal_PersonasSePreocupan',\r\n",
    "       'ApoyoAfectivoPersonal_RecibirAmorAfecto',\r\n",
    "       'ApoyoAfectivoPersonal_HablarProblemasTrabajoCasa',\r\n",
    "       'ApoyoAfectivoPersonal_HablarProblemasPersonalesFamiliares',\r\n",
    "       'ApoyoAfectivoPersonal_HablarProblemasEconómicos',\r\n",
    "       'ApoyoAfectivoPersonal_RecibirInvitacionesSalirConOtrasPersonas',\r\n",
    "       'ApoyoAfectivoPersonal_RecibirConsejosÚtiles',\r\n",
    "       'ApoyoAfectivoPersonal_RecibirAyudaEnfermoCama',]\r\n",
    "\r\n",
    "ENS_2017_valida_2.drop(TO_ENS_2017_valida_2, inplace = True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENS_2017_valida_2.to_csv('../data/Bases_trabajo/ENS_2017_valida_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENS_2017_valida_2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KMEANS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn import metrics\r\n",
    "from sklearn.preprocessing import StandardScaler\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENS_2017_valida_2 = pd.read_csv(\"../data/Bases_trabajo/ENS_2017_valida_2.csv\", sep =',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pasamos a array la variable que queremos predecir \r\n",
    "y = np.array(ENS_2017_valida_2['Salud_percibida'])\r\n",
    "\r\n",
    "# Eliminamos del dataframe la variable que queremos predecir y mantenemos el resto como columnas (serán las variables predictoras:X)\r\n",
    "X= np.array(ENS_2017_valida_2.drop('Salud_percibida', axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividimos en muestra de entrenamiento y de test\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\r\n",
    "                                                    y,\r\n",
    "                                                    test_size=0.2,\r\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determinamos el número de clusters óptimo en la muestra de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nc = range(1, 10)\r\n",
    "kmeans = [KMeans(n_clusters=i) for i in Nc]\r\n",
    "kmeans\r\n",
    "score = [kmeans[i].fit(X_train).score(X_train) for i in range(len(kmeans))]\r\n",
    "score\r\n",
    "plt.plot(Nc,score)\r\n",
    "plt.xlabel('Number of Clusters')\r\n",
    "plt.ylabel('Score')\r\n",
    "plt.title('Elbow Curve')\r\n",
    "plt.show()\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kmeans. 3 Clústers y 4 Clústers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (3,5):\r\n",
    "    print ('n_cluster_train:', i)\r\n",
    "    kmeans_train = KMeans(n_clusters=i, random_state=42).fit(X_train)\r\n",
    "    print(\"kmeans.labels_:\", kmeans_train.labels_)\r\n",
    "    predict_train = kmeans_train.predict(X_train)\r\n",
    "    print(\"\\npredict:\", predict_train)\r\n",
    "    clusters_train = kmeans_train.cluster_centers_\r\n",
    "    print(f'\\nKMeans cluster centers 3:\\n {clusters_train}')\r\n",
    "\r\n",
    "    k_train_score = metrics.accuracy_score(y_train, predict_train)\r\n",
    "    print(f'K_train_Score: {k_train_score.round(2)}')\r\n",
    "\r\n",
    "    print ('n_cluster_test:', i)\r\n",
    "    kmeans_test = KMeans(n_clusters=i, random_state=42).fit(X_test)\r\n",
    "    print(\"kmeans.labels_:\", kmeans_test.labels_)\r\n",
    "    predict_test = kmeans_test.predict(X_test)\r\n",
    "    print(\"\\npredict:\", predict_test)\r\n",
    "    clusters_test = kmeans_test.cluster_centers_\r\n",
    "    print(f'\\nKMeans cluster centers 3:\\n {clusters_test}')\r\n",
    "\r\n",
    "    k_test_score = metrics.accuracy_score(y_test, predict_test)\r\n",
    "    print(f'K_train_Score: {k_test_score.round(2)}')\r\n",
    "\r\n",
    "    print ('...................................')\r\n",
    "    print ('...................................')\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vemos si mejoran los resultados para 3 y 4 clústers con los datos estandarizados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (3,5):\r\n",
    "    X_train = StandardScaler().fit_transform(X_train)\r\n",
    "\r\n",
    "    print ('n_cluster_train:', i)\r\n",
    "    kmeans_train = KMeans(n_clusters=i, random_state=42).fit(X_train)\r\n",
    "    print(\"kmeans.labels_:\", kmeans_train.labels_)\r\n",
    "    predict_train = kmeans_train.predict(X_train)\r\n",
    "    print(\"\\npredict:\", predict_train)\r\n",
    "    clusters_train = kmeans_train.cluster_centers_\r\n",
    "    print(f'\\nKMeans cluster centers 3:\\n {clusters_train}')\r\n",
    "\r\n",
    "    k_train_score = metrics.accuracy_score(y_train, predict_train)\r\n",
    "    print(f'K_train_Score: {k_train_score.round(2)}')\r\n",
    "\r\n",
    "    print ('...........................')\r\n",
    "    X_test = StandardScaler().fit_transform(X_test)\r\n",
    "    \r\n",
    "    print ('n_cluster_test:', i)\r\n",
    "    kmeans_test = KMeans(n_clusters=i, random_state=42).fit(X_test)\r\n",
    "    print(\"kmeans.labels_:\", kmeans_test.labels_)\r\n",
    "    predict_test = kmeans_test.predict(X_test)\r\n",
    "    print(\"\\npredict:\", predict_test)\r\n",
    "    clusters_test = kmeans_test.cluster_centers_\r\n",
    "    print(f'\\nKMeans cluster centers 3:\\n {clusters_test}')\r\n",
    "\r\n",
    "    k_test_score = metrics.accuracy_score(y_test, predict_test)\r\n",
    "    print(f'K_train_Score: {k_test_score.round(2)}')\r\n",
    "\r\n",
    "    print ('...................................')\r\n",
    "    print ('...................................')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aplicamos el modelo a todos los datos. Con 3 Clúster sin normalizar. Es el modelo en el que se obtienen un mejor Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=3, random_state=42).fit(X)\r\n",
    "print(\"kmeans.labels_:\", kmeans.labels_)\r\n",
    "predict = kmeans.predict(X)\r\n",
    "print(\"\\npredict:\", predict)\r\n",
    "clusters = kmeans.cluster_centers_\r\n",
    "print(f'\\nKMeans cluster centers 3:\\n {clusters}')\r\n",
    "\r\n",
    "k_score = metrics.accuracy_score(y, predict)\r\n",
    "print(f'K_Score: {k_score.round(2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vemos si mejora el modelo de 3 Clúster sin normalizar reduciendo las variables con PCA (análisis de componentes principales)\r\n",
    "#### Como el score en train y test es el mismo e igual que con todos los datos, aplicaremos el modelo PCA a todos los datos\r\n",
    "#### Probaremos reduciendo a 3, 4 y 5 componentes principales "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\r\n",
    "\r\n",
    "for i in range (3,6):\r\n",
    "    print ('PCA:', i)\r\n",
    "    pca = PCA(n_components=i)\r\n",
    "    pca.fit(X)\r\n",
    "    X_pca = pca.transform(X)\r\n",
    "    print('Varianza explicativa para PCA:', i)\r\n",
    "    print(f'Varianza explicativa \\n{pca.explained_variance_ratio_}')\r\n",
    "    total_var_pca = pca.explained_variance_ratio_[0]\r\n",
    "    print(f'\\nTotal varianza explicativa: \\n{total_var_pca.round(2)}')\r\n",
    "\r\n",
    "    print('Kmeans para PCA:', i)\r\n",
    "    kmeans_pca = KMeans(n_clusters=3, random_state=11).fit(X_pca)\r\n",
    "    print(\"kmeans.labels_:\", kmeans_pca.labels_)\r\n",
    "    predict_pca = kmeans_pca.predict(X_pca)\r\n",
    "    print(\"\\npredict:\", predict_pca)\r\n",
    "    clusters_pca = kmeans_pca.cluster_centers_\r\n",
    "    print(f'\\nKMeans cluster centers con PCA: i {clusters_pca}')\r\n",
    "\r\n",
    "    print('Score para PCA:', i)\r\n",
    "    k_pca_score = metrics.accuracy_score(y, predict_pca)\r\n",
    "    print(f'PCA_Score: {k_pca_score}')\r\n",
    "    print(f'PCA_Score: {k_pca_score.round(2)}')\r\n",
    "\r\n",
    "    print ('....................................')\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mejora un poco con 4 componentes principales. Mantenemos el modelo de Kmeans con 3 Clústers y 4 componentes principales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENS_2017_valida_2 = pd.read_csv(\"../data/Bases_trabajo/ENS_2017_valida_2.csv\", sep =',')\r\n",
    "\r\n",
    "# Pasamos a array la variable que queremos predecir \r\n",
    "y = np.array(ENS_2017_valida_2['Salud_percibida'])\r\n",
    "\r\n",
    "# Eliminamos del dataframe la variable que queremos predecir y mantenemos el resto como columnas (serán las variables predictoras:X)\r\n",
    "\r\n",
    "X= np.array(ENS_2017_valida_2.drop('Salud_percibida', axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividimos en muestra de entrenamiento y de test\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\r\n",
    "                                                    y,\r\n",
    "                                                    test_size=0.2,\r\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vemos con qué número de epsilón y min_samples es el que obtiene mejores resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos DBSCAN\r\n",
    "from sklearn.cluster import DBSCAN\r\n",
    "\r\n",
    "\r\n",
    "for i in range (5,21):\r\n",
    "    for j in range (2,11):\r\n",
    "        print ('eps:', i)\r\n",
    "        print ('min_sample:', j)\r\n",
    "        db_train = DBSCAN(eps=i, min_samples=j).fit(X_train)\r\n",
    "        core_samples_mask = np.zeros_like(db_train.labels_, dtype=bool)\r\n",
    "        core_samples_mask[db_train.core_sample_indices_] = True\r\n",
    "        y_db_train = db_train.labels_\r\n",
    "\r\n",
    "        db_train_Score = metrics.accuracy_score(y_train, y_db_train)\r\n",
    "        print('DB_train_Score:', db_train_Score.round(2))\r\n",
    "        print('DB_train_Score:', db_train_Score)\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probamos con los datos estandarizados a ver si mejora el modelo con el número de epsilon y min_samples que mejores resultados hemos obtenido: \r\n",
    "### epsilon = 19, min_samples = 2\r\n",
    "### DB_train_Score: 0.01; DB_train_Score: 0.012560229549022792"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizamos los datos\r\n",
    "X_train = StandardScaler().fit_transform(X_train)\r\n",
    "\r\n",
    "# Definimos DBSCAN \r\n",
    "db_train = DBSCAN(eps= 19, min_samples=3).fit(X_train)\r\n",
    "core_samples_mask = np.zeros_like(db_train.labels_, dtype=bool)\r\n",
    "core_samples_mask[db_train.core_sample_indices_] = True\r\n",
    "y_db_train = db_train.labels_\r\n",
    "\r\n",
    "db_train_Score = metrics.accuracy_score(y_train, y_db_train)\r\n",
    "print('DB_train_Score:', db_train_Score.round(2))\r\n",
    "print('DB_train_Score:', db_train_Score)\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusión Clusters: El mejor modelo para agrupar los registros en Clúster es el de Kmeans con 3 Cluster y las variables agrupadas en 4 componentes principales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Añadimos una columna a nuestro Dataframe con la asignación de los Clústers a cada una de las filas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENS_2017_valida_2 = pd.read_csv(\"../data/Bases_trabajo/ENS_2017_valida_2.csv\", sep =',')\r\n",
    "\r\n",
    "y = np.array(ENS_2017_valida_2['Salud_percibida'])\r\n",
    "\r\n",
    "X= np.array(ENS_2017_valida_2.drop('Salud_percibida', axis = 1))\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=4)\r\n",
    "pca.fit(X)\r\n",
    "X_pca = pca.transform(X)\r\n",
    "print('Varianza explicativa para PCA:', 4)\r\n",
    "print(f'Varianza explicativa \\n{pca.explained_variance_ratio_}')\r\n",
    "total_var_pca = pca.explained_variance_ratio_[0]\r\n",
    "print(f'\\nTotal varianza explicativa: \\n{total_var_pca.round(2)}')\r\n",
    "\r\n",
    "print('Kmeans para PCA:', 4)\r\n",
    "kmeans_pca = KMeans(n_clusters=3, random_state=11).fit(X_pca)\r\n",
    "print(\"kmeans.labels_:\", kmeans_pca.labels_)\r\n",
    "predict_pca = kmeans_pca.predict(X_pca)\r\n",
    "print(\"\\npredict:\", predict_pca)\r\n",
    "clusters_pca = kmeans_pca.cluster_centers_\r\n",
    "print(f'\\nKMeans cluster centers con PCA: i {clusters_pca}')\r\n",
    "\r\n",
    "print('Score para PCA:', 4)\r\n",
    "k_pca_score = metrics.accuracy_score(y, predict_pca)\r\n",
    "print(f'PCA_Score: {k_pca_score}')\r\n",
    "print(f'PCA_Score: {k_pca_score.round(2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Clusters = kmeans_pca.predict(X_pca)\r\n",
    "ENS_2017_valida_2['Clusters'] = Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos una nueva base en la que se encuentra la columna de Clústers añadida\r\n",
    "\r\n",
    "ENS_2017_C = ENS_2017_valida_2\r\n",
    "ENS_2017_C.to_csv('../data/Bases_trabajo/ENS_2017_C.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtenemos el porcentaje y el número de observaciones en cada Clúster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENS_2017_C= pd.read_csv(\"../data/Bases_trabajo/ENS_2017_C.csv\", sep =',')\r\n",
    "\r\n",
    "freq_Clusters = ENS_2017_C['Clusters'].value_counts() / len(ENS_2017_C['Clusters'])*100\r\n",
    "freq_Clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identificamos el perfil de cada Clúster cruzando las diferentes variables del dataset con la columna de Clúster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cruzamos la VD con los Clústers\r\n",
    "\r\n",
    "Cluster_SaludPercibida = pd.crosstab(index =ENS_2017_C['Clusters'],columns =ENS_2017_C['Salud_percibida']).apply(lambda r: r/r.sum() *100,axis=0)\r\n",
    "\r\n",
    "Cluster_SaludPercibida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cruzamos las VI categóricas con los Clústers\r\n",
    "\r\n",
    "variables = ['CCAA', 'Sexo', \r\n",
    "       'Actividad_economica_actual', 'Nacionalidad_española', 'Convivencia',\r\n",
    "       'Estado_civil', 'Nivel_estudios', 'Vacunación_gripe',\r\n",
    "       'Toma_tensiónArterial_profesional', 'Medición_colesterol',\r\n",
    "       'Prueba_sangreHeces', 'Colonoscopia', \r\n",
    "       'Freq_ActividadFísica', 'Freq_Consumo_FrutaFresca',\r\n",
    "       'Freq_Consumo_Carne', 'Freq_Consumo_Huevos', 'Freq_Consumo_Pescado',\r\n",
    "       'Freq_Consumo_PastaArrozPatatas', 'Freq_Consumo_PanCereales',\r\n",
    "       'Freq_Consumo_VerdurasEnsaladasHortalizas', 'Freq_Consumo_Legumbres',\r\n",
    "       'Freq_Consumo_EmbutidosFiambres', 'Freq_Consumo_Lácteos',\r\n",
    "       'Freq_Consumo_Dulces', 'Freq_Consumo_ComidaRápida',\r\n",
    "       'Freq_Consumo_ZumoNatural', 'Freq_Diaria_CepilladoDientes',\r\n",
    "       '¿Fuma actualmente', 'Freq_Consumo_Alcohol',\r\n",
    "       'ApoyoAfectivoPersonal_AmigosFamiliares', 'ClaseSocial_BasadaOcupación',\r\n",
    "       'Índice_MasaCorporal']\r\n",
    "       \r\n",
    "for i in variables:\r\n",
    "    Cluster_i = pd.crosstab(index =ENS_2017_C['Clusters'],columns =ENS_2017_C[i]).apply(lambda r: r/r.sum() *100,axis=0)\r\n",
    "    print(Cluster_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cruzamos las VI numéricas con los Clústers\r\n",
    "\r\n",
    "variables = ['Edad', 'Peso(Kg)']\r\n",
    "\r\n",
    "for i in variables:\r\n",
    "    Cluster_i = ENS_2017_C.groupby(['Clusters'])[i].describe()\r\n",
    "\r\n",
    "    print(Cluster_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creamos una base independiente por cada clúster\r\n",
    "\r\n",
    "### Aplicaremos en cada uno de los clústers los modelos a entrenar, de forma independiente\r\n",
    "\r\n",
    "### Identificaremos de esta forma si la variabilidad en cada clúster se explica por diferentes modelos. En caso de ser así, se realizaría un filtro al hacer las predicciones. En caso de que en los tres clústers se obtengan los mismos resultados se aplicaría a todos ellos el mismo modelo para hacer las predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENS_2017_C0 = (ENS_2017_C[ENS_2017_C['Clusters'] == 0)\r\n",
    "ENS_2017_C0.to_csv('../data/Bases_trabajo/ENS_2017_C0.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENS_2017_C1 = (ENS_2017_C[ENS_2017_C['Clusters'] == 1])\r\n",
    "ENS_2017_C1.to_csv('../data/Bases_trabajo/ENS_2017_C1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENS_2017_C2 = (ENS_2017_C[ENS_2017_C['Clusters'] == 2])\r\n",
    "ENS_2017_C2.to_csv('../data/Bases_trabajo/ENS_2017_C2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos de regresión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\r\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENS_2017_C0 = pd.read_csv(\"../data/Bases_trabajo/ENS_2017_C0.csv\", sep =',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ENS_2017_C0[['CCAA', 'Sexo', 'Edad', 'Actividad_economica_actual', 'Nacionalidad_española', 'Convivencia',\r\n",
    "       'Estado_civil', 'Nivel_estudios', 'Vacunación_gripe','Toma_tensiónArterial_profesional', 'Medición_colesterol',\r\n",
    "       'Prueba_sangreHeces', 'Colonoscopia', 'Peso(Kg)', 'Freq_ActividadFísica', 'Freq_Consumo_FrutaFresca',\r\n",
    "       'Freq_Consumo_Carne', 'Freq_Consumo_Huevos', 'Freq_Consumo_Pescado', 'Freq_Consumo_PastaArrozPatatas', 'Freq_Consumo_PanCereales',\r\n",
    "       'Freq_Consumo_VerdurasEnsaladasHortalizas', 'Freq_Consumo_Legumbres', 'Freq_Consumo_EmbutidosFiambres', 'Freq_Consumo_Lácteos',\r\n",
    "       'Freq_Consumo_Dulces', 'Freq_Consumo_ComidaRápida', 'Freq_Consumo_ZumoNatural', 'Freq_Diaria_CepilladoDientes',\r\n",
    "       '¿Fuma actualmente', 'Freq_Consumo_Alcohol', 'ApoyoAfectivoPersonal_AmigosFamiliares', 'ClaseSocial_BasadaOcupación',\r\n",
    "       'Índice_MasaCorporal']]\r\n",
    "       \r\n",
    "y = ENS_2017_C0['Salud_percibida']\r\n",
    "\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)\r\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Cluster 0: Train')\r\n",
    "\r\n",
    "\r\n",
    "lm = LinearRegression(n_jobs=-1)\r\n",
    "lm.fit(X_train, y_train)\r\n",
    "Intercept = lm.intercept_\r\n",
    "print('intercept:', Intercept)\r\n",
    "lm.coef_ # Pendientes de Xn\r\n",
    "coeff_df = pd.DataFrame(lm.coef_, X.columns, columns=['Coefficient'])\r\n",
    "print(coeff_df)\r\n",
    "Score_train = lm.score(X_train, y_train) *100\r\n",
    "print ('Score_train:', Score_train)\r\n",
    "y_pred_train = lm.predict(X_train)\r\n",
    "MSE_train= mean_squared_error(y_train, y_pred)\r\n",
    "print ('MSE_train:', MSE_train)\r\n",
    "\r\n",
    "\r\n",
    "print ('......................')\r\n",
    "print ('Cluster 0: Test')\r\n",
    "\r\n",
    "lm = LinearRegression(n_jobs=-1)\r\n",
    "lm.fit(X_test, y_test)\r\n",
    "Intercept = lm.intercept_\r\n",
    "print('intercept:', Intercept)\r\n",
    "lm.coef_ # Pendientes de Xn\r\n",
    "coeff_df = pd.DataFrame(lm.coef_, X.columns, columns=['Coefficient'])\r\n",
    "print(coeff_df)\r\n",
    "Score_test = lm.score(X_test, y_test) *100\r\n",
    "print ('Score_test:', Score_test)\r\n",
    "y_pred_test = lm.predict(X_test)\r\n",
    "MSE_test = mean_squared_error(y_test, y_pred)\r\n",
    "print ('MSE_test:', MSE_test)\r\n",
    "\r\n",
    "print ('......................')\r\n",
    "print ('Cluster 0: Total')\r\n",
    "\r\n",
    "lm = LinearRegression(n_jobs=-1)\r\n",
    "lm.fit(X, y)\r\n",
    "Intercept = lm.intercept_\r\n",
    "print('intercept:', Intercept)\r\n",
    "lm.coef_ # Pendientes de Xn\r\n",
    "coeff_df = pd.DataFrame(lm.coef_, X.columns, columns=['Coefficient'])\r\n",
    "print(coeff_df)\r\n",
    "Score_total = lm.score(X, y) *100\r\n",
    "print ('Score_total:', Score_total)\r\n",
    "y_pred = lm.predict(X)\r\n",
    "MSE_total = mean_squared_error(y, y_pred)\r\n",
    "print ('MSE_total:', MSE_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENS_2017_C1 = pd.read_csv(\"../data/Bases_trabajo/ENS_2017_C1.csv\", sep =',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ENS_2017_C1[['CCAA', 'Sexo', 'Edad', 'Actividad_economica_actual', 'Nacionalidad_española', 'Convivencia',\r\n",
    "       'Estado_civil', 'Nivel_estudios', 'Vacunación_gripe','Toma_tensiónArterial_profesional', 'Medición_colesterol',\r\n",
    "       'Prueba_sangreHeces', 'Colonoscopia', 'Peso(Kg)', 'Freq_ActividadFísica', 'Freq_Consumo_FrutaFresca',\r\n",
    "       'Freq_Consumo_Carne', 'Freq_Consumo_Huevos', 'Freq_Consumo_Pescado', 'Freq_Consumo_PastaArrozPatatas', 'Freq_Consumo_PanCereales',\r\n",
    "       'Freq_Consumo_VerdurasEnsaladasHortalizas', 'Freq_Consumo_Legumbres', 'Freq_Consumo_EmbutidosFiambres', 'Freq_Consumo_Lácteos',\r\n",
    "       'Freq_Consumo_Dulces', 'Freq_Consumo_ComidaRápida', 'Freq_Consumo_ZumoNatural', 'Freq_Diaria_CepilladoDientes',\r\n",
    "       '¿Fuma actualmente', 'Freq_Consumo_Alcohol', 'ApoyoAfectivoPersonal_AmigosFamiliares', 'ClaseSocial_BasadaOcupación',\r\n",
    "       'Índice_MasaCorporal']]\r\n",
    "       \r\n",
    "y = ENS_2017_C1['Salud_percibida']\r\n",
    "\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)\r\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Cluster 1: Train')\r\n",
    "\r\n",
    "\r\n",
    "lm = LinearRegression(n_jobs=-1)\r\n",
    "lm.fit(X_train, y_train)\r\n",
    "Intercept = lm.intercept_\r\n",
    "print('intercept:', Intercept)\r\n",
    "lm.coef_ # Pendientes de Xn\r\n",
    "coeff_df = pd.DataFrame(lm.coef_, X.columns, columns=['Coefficient'])\r\n",
    "print(coeff_df)\r\n",
    "Score_train = lm.score(X_train, y_train) *100\r\n",
    "print ('Score_train:', Score_train)\r\n",
    "y_pred_train = lm.predict(X_train)\r\n",
    "MSE_train= mean_squared_error(y_train, y_pred)\r\n",
    "print ('MSE_train:', MSE_train)\r\n",
    "\r\n",
    "\r\n",
    "print ('......................')\r\n",
    "print ('Cluster 1: Test')\r\n",
    "\r\n",
    "lm = LinearRegression(n_jobs=-1)\r\n",
    "lm.fit(X_test, y_test)\r\n",
    "Intercept = lm.intercept_\r\n",
    "print('intercept:', Intercept)\r\n",
    "lm.coef_ # Pendientes de Xn\r\n",
    "coeff_df = pd.DataFrame(lm.coef_, X.columns, columns=['Coefficient'])\r\n",
    "print(coeff_df)\r\n",
    "Score_test = lm.score(X_test, y_test) *100\r\n",
    "print ('Score_test:', Score_test)\r\n",
    "y_pred_test = lm.predict(X_test)\r\n",
    "MSE_test = mean_squared_error(y_test, y_pred)\r\n",
    "print ('MSE_test:', MSE_test)\r\n",
    "\r\n",
    "print ('......................')\r\n",
    "print ('Cluster 1: Total')\r\n",
    "\r\n",
    "lm = LinearRegression(n_jobs=-1)\r\n",
    "lm.fit(X, y)\r\n",
    "Intercept = lm.intercept_\r\n",
    "print('intercept:', Intercept)\r\n",
    "lm.coef_ \r\n",
    "coeff_df = pd.DataFrame(lm.coef_, X.columns, columns=['Coefficient'])\r\n",
    "print(coeff_df)\r\n",
    "Score_total = lm.score(X, y) *100\r\n",
    "print ('Score_total:', Score_total)\r\n",
    "y_pred = lm.predict(X)\r\n",
    "MSE_total = mean_squared_error(y, y_pred)\r\n",
    "print ('MSE_total:', MSE_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENS_2017_C2 = pd.read_csv(\"../data/Bases_trabajo/ENS_2017_C2.csv\", sep =',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ENS_2017_C2[['CCAA', 'Sexo', 'Edad', 'Actividad_economica_actual', 'Nacionalidad_española', 'Convivencia',\r\n",
    "       'Estado_civil', 'Nivel_estudios', 'Vacunación_gripe','Toma_tensiónArterial_profesional', 'Medición_colesterol',\r\n",
    "       'Prueba_sangreHeces', 'Colonoscopia', 'Peso(Kg)', 'Freq_ActividadFísica', 'Freq_Consumo_FrutaFresca',\r\n",
    "       'Freq_Consumo_Carne', 'Freq_Consumo_Huevos', 'Freq_Consumo_Pescado', 'Freq_Consumo_PastaArrozPatatas', 'Freq_Consumo_PanCereales',\r\n",
    "       'Freq_Consumo_VerdurasEnsaladasHortalizas', 'Freq_Consumo_Legumbres', 'Freq_Consumo_EmbutidosFiambres', 'Freq_Consumo_Lácteos',\r\n",
    "       'Freq_Consumo_Dulces', 'Freq_Consumo_ComidaRápida', 'Freq_Consumo_ZumoNatural', 'Freq_Diaria_CepilladoDientes',\r\n",
    "       '¿Fuma actualmente', 'Freq_Consumo_Alcohol', 'ApoyoAfectivoPersonal_AmigosFamiliares', 'ClaseSocial_BasadaOcupación',\r\n",
    "       'Índice_MasaCorporal']]\r\n",
    "       \r\n",
    "y = ENS_2017_C2['Salud_percibida']\r\n",
    "\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)\r\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Cluster 2: Train')\r\n",
    "\r\n",
    "\r\n",
    "lm = LinearRegression(n_jobs=-1)\r\n",
    "lm.fit(X_train, y_train)\r\n",
    "Intercept = lm.intercept_\r\n",
    "print('intercept:', Intercept)\r\n",
    "lm.coef_ # Pendientes de Xn\r\n",
    "coeff_df = pd.DataFrame(lm.coef_, X.columns, columns=['Coefficient'])\r\n",
    "print(coeff_df)\r\n",
    "Score_train = lm.score(X_train, y_train) *100\r\n",
    "print ('Score_train:', Score_train)\r\n",
    "y_pred_train = lm.predict(X_train)\r\n",
    "MSE_train= mean_squared_error(y_train, y_pred)\r\n",
    "print ('MSE_train:', MSE_train)\r\n",
    "\r\n",
    "\r\n",
    "print ('......................')\r\n",
    "print ('Cluster 2: Test')\r\n",
    "\r\n",
    "lm = LinearRegression(n_jobs=-1)\r\n",
    "lm.fit(X_test, y_test)\r\n",
    "Intercept = lm.intercept_\r\n",
    "print('intercept:', Intercept)\r\n",
    "lm.coef_ # Pendientes de Xn\r\n",
    "coeff_df = pd.DataFrame(lm.coef_, X.columns, columns=['Coefficient'])\r\n",
    "print(coeff_df)\r\n",
    "Score_test = lm.score(X_test, y_test) *100\r\n",
    "print ('Score_test:', Score_test)\r\n",
    "y_pred_test = lm.predict(X_test)\r\n",
    "MSE_test = mean_squared_error(y_test, y_pred)\r\n",
    "print ('MSE_test:', MSE_test)\r\n",
    "\r\n",
    "print ('......................')\r\n",
    "print ('Cluster 2: Total')\r\n",
    "\r\n",
    "lm = LinearRegression(n_jobs=-1)\r\n",
    "lm.fit(X, y)\r\n",
    "Intercept = lm.intercept_\r\n",
    "print('intercept:', Intercept)\r\n",
    "lm.coef_ # Pendientes de Xn\r\n",
    "coeff_df = pd.DataFrame(lm.coef_, X.columns, columns=['Coefficient'])\r\n",
    "print(coeff_df)\r\n",
    "Score_total = lm.score(X, y) *100\r\n",
    "print ('Score_total:', Score_total)\r\n",
    "y_pred = lm.predict(X)\r\n",
    "MSE_total = mean_squared_error(y, y_pred)\r\n",
    "print ('MSE_total:', MSE_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENS_2017_C= pd.read_csv('../data/Bases_trabajo/ENS_2017_C.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ENS_2017_C[['CCAA', 'Sexo', 'Edad', 'Actividad_economica_actual', 'Nacionalidad_española', 'Convivencia',\r\n",
    "       'Estado_civil', 'Nivel_estudios', 'Vacunación_gripe','Toma_tensiónArterial_profesional', 'Medición_colesterol',\r\n",
    "       'Prueba_sangreHeces', 'Colonoscopia', 'Peso(Kg)', 'Freq_ActividadFísica', 'Freq_Consumo_FrutaFresca',\r\n",
    "       'Freq_Consumo_Carne', 'Freq_Consumo_Huevos', 'Freq_Consumo_Pescado', 'Freq_Consumo_PastaArrozPatatas', 'Freq_Consumo_PanCereales',\r\n",
    "       'Freq_Consumo_VerdurasEnsaladasHortalizas', 'Freq_Consumo_Legumbres', 'Freq_Consumo_EmbutidosFiambres', 'Freq_Consumo_Lácteos',\r\n",
    "       'Freq_Consumo_Dulces', 'Freq_Consumo_ComidaRápida', 'Freq_Consumo_ZumoNatural', 'Freq_Diaria_CepilladoDientes',\r\n",
    "       '¿Fuma actualmente', 'Freq_Consumo_Alcohol', 'ApoyoAfectivoPersonal_AmigosFamiliares', 'ClaseSocial_BasadaOcupación',\r\n",
    "       'Índice_MasaCorporal']]\r\n",
    "       \r\n",
    "y = ENS_2017_C['Salud_percibida']\r\n",
    "\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)\r\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Total: Train')\r\n",
    "\r\n",
    "\r\n",
    "lm = LinearRegression(n_jobs=-1)\r\n",
    "lm.fit(X_train, y_train)\r\n",
    "Intercept = lm.intercept_\r\n",
    "print('intercept:', Intercept)\r\n",
    "lm.coef_ # Pendientes de Xn\r\n",
    "coeff_df = pd.DataFrame(lm.coef_, X.columns, columns=['Coefficient'])\r\n",
    "print(coeff_df)\r\n",
    "Score_train = lm.score(X_train, y_train) *100\r\n",
    "print ('Score_train:', Score_train)\r\n",
    "y_pred_train = lm.predict(X_train)\r\n",
    "MSE_train= mean_squared_error(y_train, y_pred)\r\n",
    "print ('MSE_train:', MSE_train)\r\n",
    "\r\n",
    "\r\n",
    "print ('......................')\r\n",
    "print ('Total: Test')\r\n",
    "\r\n",
    "lm = LinearRegression(n_jobs=-1)\r\n",
    "lm.fit(X_test, y_test)\r\n",
    "Intercept = lm.intercept_\r\n",
    "print('intercept:', Intercept)\r\n",
    "lm.coef_ # Pendientes de Xn\r\n",
    "coeff_df = pd.DataFrame(lm.coef_, X.columns, columns=['Coefficient'])\r\n",
    "print(coeff_df)\r\n",
    "Score_test = lm.score(X_test, y_test) *100\r\n",
    "print ('Score_test:', Score_test)\r\n",
    "y_pred_test = lm.predict(X_test)\r\n",
    "MSE_test = mean_squared_error(y_test, y_pred)\r\n",
    "print ('MSE_test:', MSE_test)\r\n",
    "\r\n",
    "print ('......................')\r\n",
    "print ('Total: Total')\r\n",
    "\r\n",
    "lm = LinearRegression(n_jobs=-1)\r\n",
    "lm.fit(X, y)\r\n",
    "Intercept = lm.intercept_\r\n",
    "print('intercept:', Intercept)\r\n",
    "lm.coef_ \r\n",
    "coeff_df = pd.DataFrame(lm.coef_, X.columns, columns=['Coefficient'])\r\n",
    "print(coeff_df)\r\n",
    "Score_total = lm.score(X, y) *100\r\n",
    "print ('Score_total:', Score_total)\r\n",
    "y_pred = lm.predict(X)\r\n",
    "MSE_total = mean_squared_error(y, y_pred)\r\n",
    "print ('MSE_total:', MSE_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\r\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\r\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENS_2017_C0 = pd.read_csv(\"../data/Bases_trabajo/ENS_2017_C0.csv\", sep =',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ENS_2017_C0[['CCAA', 'Sexo', 'Edad',\r\n",
    "       'Actividad_economica_actual', 'Nacionalidad_española', 'Convivencia',\r\n",
    "       'Estado_civil', 'Nivel_estudios', 'Vacunación_gripe',\r\n",
    "       'Toma_tensiónArterial_profesional', 'Medición_colesterol',\r\n",
    "       'Prueba_sangreHeces', 'Colonoscopia', 'Peso(Kg)',\r\n",
    "       'Freq_ActividadFísica', 'Freq_Consumo_FrutaFresca',\r\n",
    "       'Freq_Consumo_Carne', 'Freq_Consumo_Huevos', 'Freq_Consumo_Pescado',\r\n",
    "       'Freq_Consumo_PastaArrozPatatas', 'Freq_Consumo_PanCereales',\r\n",
    "       'Freq_Consumo_VerdurasEnsaladasHortalizas', 'Freq_Consumo_Legumbres',\r\n",
    "       'Freq_Consumo_EmbutidosFiambres', 'Freq_Consumo_Lácteos',\r\n",
    "       'Freq_Consumo_Dulces', 'Freq_Consumo_ComidaRápida',\r\n",
    "       'Freq_Consumo_ZumoNatural', 'Freq_Diaria_CepilladoDientes',\r\n",
    "       '¿Fuma actualmente', 'Freq_Consumo_Alcohol',\r\n",
    "       'ApoyoAfectivoPersonal_AmigosFamiliares', 'ClaseSocial_BasadaOcupación',\r\n",
    "       'Índice_MasaCorporal']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = ENS_2017_C0['Salud_percibida']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vemos cuantos degrees son los más adecuados para establecer el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree_min = 2\r\n",
    "degree_max = 4\r\n",
    "\r\n",
    "#Creamos un diccionario para obtener los resultados con los diferents degrees\r\n",
    "\r\n",
    "dictionary_scores = {\"degree\":[], \"score train\":[], \"MSE_train\":[], \"score test\":[], \"MSE_test\":[]}\r\n",
    "\r\n",
    "for degree in range(degree_min,degree_max+1):\r\n",
    "    \r\n",
    "    polinominal_model = PolynomialFeatures(degree) \r\n",
    "    X_poly_train = polinominal_model.fit_transform(X_train, y_train)\r\n",
    "    print(\"X_poly_train.shape: \",X_poly_train.shape)\r\n",
    "\r\n",
    "    model = LinearRegression()\r\n",
    "    model.fit(X_poly_train, y_train)\r\n",
    "    y_train_pred = model.predict(X_poly_train)\r\n",
    "    print(\"y_train_pred\", y_train_pred.shape)\r\n",
    "    \r\n",
    "    score_train = r2_score(y_train, y_train_pred)\r\n",
    "    MSE_train = mean_squared_error(y_train, y_train_pred)\r\n",
    "    \r\n",
    "    # para predecir\r\n",
    "    X_poly_test = polinominal_model.fit_transform(X_test, y_test)\r\n",
    "    model.fit(X_poly_test, y_test)\r\n",
    "    y_test_pred = model.predict(X_poly_test)\r\n",
    "    print(\"y_test_pred\", y_test_pred.shape)\r\n",
    "    \r\n",
    "    score_test = r2_score(y_test, y_test_pred)\r\n",
    "    MSE_test = mean_squared_error(y_test, y_test_pred)\r\n",
    "       \r\n",
    "    #código para crear un dataframe con los score\r\n",
    "    lista_val = [degree, score_train, MSE_train, score_test, MSE_test]\r\n",
    "    for i,e in enumerate([\"degree\", \"score train\", \"MSE_train\", \"score test\", \"MSE_test\"]):\r\n",
    "        dictionary_scores[e].append(lista_val[i])\r\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_score = pd.DataFrame(dictionary_scores)\r\n",
    "df_score.groupby([\"degree\"]).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENS_2017_C1 = pd.read_csv(\"../data/Bases_trabajo/ENS_2017_C1.csv\", sep =',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ENS_2017_C1[['CCAA', 'Sexo', 'Edad', 'Actividad_economica_actual', 'Nacionalidad_española', 'Convivencia',\r\n",
    "       'Estado_civil', 'Nivel_estudios', 'Vacunación_gripe','Toma_tensiónArterial_profesional', 'Medición_colesterol',\r\n",
    "       'Prueba_sangreHeces', 'Colonoscopia', 'Peso(Kg)', 'Freq_ActividadFísica', 'Freq_Consumo_FrutaFresca',\r\n",
    "       'Freq_Consumo_Carne', 'Freq_Consumo_Huevos', 'Freq_Consumo_Pescado', 'Freq_Consumo_PastaArrozPatatas', 'Freq_Consumo_PanCereales',\r\n",
    "       'Freq_Consumo_VerdurasEnsaladasHortalizas', 'Freq_Consumo_Legumbres', 'Freq_Consumo_EmbutidosFiambres', 'Freq_Consumo_Lácteos',\r\n",
    "       'Freq_Consumo_Dulces', 'Freq_Consumo_ComidaRápida', 'Freq_Consumo_ZumoNatural', 'Freq_Diaria_CepilladoDientes',\r\n",
    "       '¿Fuma actualmente', 'Freq_Consumo_Alcohol', 'ApoyoAfectivoPersonal_AmigosFamiliares', 'ClaseSocial_BasadaOcupación',\r\n",
    "       'Índice_MasaCorporal']]\r\n",
    "       \r\n",
    "y = ENS_2017_C1['Salud_percibida']\r\n",
    "\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree_min = 2\r\n",
    "degree_max = 4\r\n",
    "\r\n",
    "#Creamos un diccionario para obtener los resultados con los diferentes degrees\r\n",
    "\r\n",
    "dictionary_scores = {\"degree\":[], \"score train\":[], \"MSE_train\":[], \"score test\":[], \"MSE_test\":[]}\r\n",
    "\r\n",
    "for degree in range(degree_min,degree_max+1):\r\n",
    "    \r\n",
    "    polinominal_model = PolynomialFeatures(degree) \r\n",
    "    X_poly_train = polinominal_model.fit_transform(X_train, y_train)\r\n",
    "    print(\"X_poly_train.shape: \",X_poly_train.shape)\r\n",
    "\r\n",
    "    model = LinearRegression()\r\n",
    "    model.fit(X_poly_train, y_train)\r\n",
    "    y_train_pred = model.predict(X_poly_train)\r\n",
    "    print(\"y_train_pred\", y_train_pred.shape)\r\n",
    "    \r\n",
    "    score_train = r2_score(y_train, y_train_pred)\r\n",
    "    MSE_train = mean_squared_error(y_train, y_train_pred)\r\n",
    "    \r\n",
    "    # para predecir\r\n",
    "    X_poly_test = polinominal_model.fit_transform(X_test, y_test)\r\n",
    "    model.fit(X_poly_test, y_test)\r\n",
    "    y_test_pred = model.predict(X_poly_test)\r\n",
    "    print(\"y_test_pred\", y_test_pred.shape)\r\n",
    "    \r\n",
    "    score_test = r2_score(y_test, y_test_pred)\r\n",
    "    MSE_test = mean_squared_error(y_test, y_test_pred)\r\n",
    "       \r\n",
    "    #código para crear un dataframe con los score\r\n",
    "    lista_val = [degree, score_train, MSE_train, score_test, MSE_test]\r\n",
    "    for i,e in enumerate([\"degree\", \"score train\", \"MSE_train\", \"score test\", \"MSE_test\"]):\r\n",
    "        dictionary_scores[e].append(lista_val[i])\r\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_score = pd.DataFrame(dictionary_scores)\r\n",
    "df_score.groupby([\"degree\"]).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENS_2017_C2= pd.read_csv('../data/Bases_trabajo/ENS_2017_C2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ENS_2017_C2[['CCAA', 'Sexo', 'Edad', 'Actividad_economica_actual', 'Nacionalidad_española', 'Convivencia',\r\n",
    "       'Estado_civil', 'Nivel_estudios', 'Vacunación_gripe','Toma_tensiónArterial_profesional', 'Medición_colesterol',\r\n",
    "       'Prueba_sangreHeces', 'Colonoscopia', 'Peso(Kg)', 'Freq_ActividadFísica', 'Freq_Consumo_FrutaFresca',\r\n",
    "       'Freq_Consumo_Carne', 'Freq_Consumo_Huevos', 'Freq_Consumo_Pescado', 'Freq_Consumo_PastaArrozPatatas', 'Freq_Consumo_PanCereales',\r\n",
    "       'Freq_Consumo_VerdurasEnsaladasHortalizas', 'Freq_Consumo_Legumbres', 'Freq_Consumo_EmbutidosFiambres', 'Freq_Consumo_Lácteos',\r\n",
    "       'Freq_Consumo_Dulces', 'Freq_Consumo_ComidaRápida', 'Freq_Consumo_ZumoNatural', 'Freq_Diaria_CepilladoDientes',\r\n",
    "       '¿Fuma actualmente', 'Freq_Consumo_Alcohol', 'ApoyoAfectivoPersonal_AmigosFamiliares', 'ClaseSocial_BasadaOcupación',\r\n",
    "       'Índice_MasaCorporal']]\r\n",
    "       \r\n",
    "y = ENS_2017_C2['Salud_percibida']\r\n",
    "\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)\r\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree_min = 2\r\n",
    "degree_max = 4\r\n",
    "\r\n",
    "#Creamos un diccionario para obtener los resultados con los diferents degrees\r\n",
    "\r\n",
    "dictionary_scores = {\"degree\":[], \"score train\":[], \"MSE_train\":[], \"score test\":[], \"MSE_test\":[]}\r\n",
    "\r\n",
    "for degree in range(degree_min,degree_max+1):\r\n",
    "    \r\n",
    "    polinominal_model = PolynomialFeatures(degree) \r\n",
    "    X_poly_train = polinominal_model.fit_transform(X_train, y_train)\r\n",
    "    print(\"X_poly_train.shape: \",X_poly_train.shape)\r\n",
    "\r\n",
    "    model = LinearRegression()\r\n",
    "    model.fit(X_poly_train, y_train)\r\n",
    "    y_train_pred = model.predict(X_poly_train)\r\n",
    "    print(\"y_train_pred\", y_train_pred.shape)\r\n",
    "    \r\n",
    "    score_train = r2_score(y_train, y_train_pred)\r\n",
    "    MSE_train = mean_squared_error(y_train, y_train_pred)\r\n",
    "    \r\n",
    "    # para predecir\r\n",
    "    X_poly_test = polinominal_model.fit_transform(X_test, y_test)\r\n",
    "    model.fit(X_poly_test, y_test)\r\n",
    "    y_test_pred = model.predict(X_poly_test)\r\n",
    "    print(\"y_test_pred\", y_test_pred.shape)\r\n",
    "    \r\n",
    "    score_test = r2_score(y_test, y_test_pred)\r\n",
    "    MSE_test = mean_squared_error(y_test, y_test_pred)\r\n",
    "       \r\n",
    "    #código para crear un dataframe con los score\r\n",
    "    lista_val = [degree, score_train, MSE_train, score_test, MSE_test]\r\n",
    "    for i,e in enumerate([\"degree\", \"score train\", \"MSE_train\", \"score test\", \"MSE_test\"]):\r\n",
    "        dictionary_scores[e].append(lista_val[i])\r\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_score = pd.DataFrame(dictionary_scores)\r\n",
    "df_score.groupby([\"degree\"]).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENS_2017_C= pd.read_csv('../data/Bases_trabajo/ENS_2017_C.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ENS_2017_C[['CCAA', 'Sexo', 'Edad', 'Actividad_economica_actual', 'Nacionalidad_española', 'Convivencia',\r\n",
    "       'Estado_civil', 'Nivel_estudios', 'Vacunación_gripe','Toma_tensiónArterial_profesional', 'Medición_colesterol',\r\n",
    "       'Prueba_sangreHeces', 'Colonoscopia', 'Peso(Kg)', 'Freq_ActividadFísica', 'Freq_Consumo_FrutaFresca',\r\n",
    "       'Freq_Consumo_Carne', 'Freq_Consumo_Huevos', 'Freq_Consumo_Pescado', 'Freq_Consumo_PastaArrozPatatas', 'Freq_Consumo_PanCereales',\r\n",
    "       'Freq_Consumo_VerdurasEnsaladasHortalizas', 'Freq_Consumo_Legumbres', 'Freq_Consumo_EmbutidosFiambres', 'Freq_Consumo_Lácteos',\r\n",
    "       'Freq_Consumo_Dulces', 'Freq_Consumo_ComidaRápida', 'Freq_Consumo_ZumoNatural', 'Freq_Diaria_CepilladoDientes',\r\n",
    "       '¿Fuma actualmente', 'Freq_Consumo_Alcohol', 'ApoyoAfectivoPersonal_AmigosFamiliares', 'ClaseSocial_BasadaOcupación',\r\n",
    "       'Índice_MasaCorporal']]\r\n",
    "       \r\n",
    "y = ENS_2017_C['Salud_percibida']\r\n",
    "\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)\r\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree_min = 2\r\n",
    "degree_max = 4\r\n",
    "\r\n",
    "#Creamos un diccionario para obtener los resultados con los diferents degrees\r\n",
    "\r\n",
    "dictionary_scores = {\"degree\":[], \"score train\":[], \"MSE_train\":[], \"score test\":[], \"MSE_test\":[]}\r\n",
    "\r\n",
    "for degree in range(degree_min,degree_max+1):\r\n",
    "    \r\n",
    "    polinominal_model = PolynomialFeatures(degree) \r\n",
    "    X_poly_train = polinominal_model.fit_transform(X_train, y_train)\r\n",
    "    print(\"X_poly_train.shape: \",X_poly_train.shape)\r\n",
    "\r\n",
    "    model = LinearRegression()\r\n",
    "    model.fit(X_poly_train, y_train)\r\n",
    "    y_train_pred = model.predict(X_poly_train)\r\n",
    "    print(\"y_train_pred\", y_train_pred.shape)\r\n",
    "    \r\n",
    "    score_train = r2_score(y_train, y_train_pred)\r\n",
    "    MSE_train = mean_squared_error(y_train, y_train_pred)\r\n",
    "    \r\n",
    "    # para predecir\r\n",
    "    X_poly_test = polinominal_model.fit_transform(X_test, y_test)\r\n",
    "    model.fit(X_poly_test, y_test)\r\n",
    "    y_test_pred = model.predict(X_poly_test)\r\n",
    "    print(\"y_test_pred\", y_test_pred.shape)\r\n",
    "    \r\n",
    "    score_test = r2_score(y_test, y_test_pred)\r\n",
    "    MSE_test = mean_squared_error(y_test, y_test_pred)\r\n",
    "       \r\n",
    "    #código para crear un dataframe con los score\r\n",
    "    lista_val = [degree, score_train, MSE_train, score_test, MSE_test]\r\n",
    "    for i,e in enumerate([\"degree\", \"score train\", \"MSE_train\", \"score test\", \"MSE_test\"]):\r\n",
    "        dictionary_scores[e].append(lista_val[i])\r\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_score = pd.DataFrame(dictionary_scores)\r\n",
    "df_score.groupby([\"degree\"]).max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENS_2017_C0 = pd.read_csv(\"../data/Bases_trabajo/ENS_2017_C0.csv\", sep =',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ENS_2017_C0[['CCAA', 'Sexo', 'Edad',\r\n",
    "       'Actividad_economica_actual', 'Nacionalidad_española', 'Convivencia',\r\n",
    "       'Estado_civil', 'Nivel_estudios', 'Vacunación_gripe',\r\n",
    "       'Toma_tensiónArterial_profesional', 'Medición_colesterol',\r\n",
    "       'Prueba_sangreHeces', 'Colonoscopia', 'Peso(Kg)',\r\n",
    "       'Freq_ActividadFísica', 'Freq_Consumo_FrutaFresca',\r\n",
    "       'Freq_Consumo_Carne', 'Freq_Consumo_Huevos', 'Freq_Consumo_Pescado',\r\n",
    "       'Freq_Consumo_PastaArrozPatatas', 'Freq_Consumo_PanCereales',\r\n",
    "       'Freq_Consumo_VerdurasEnsaladasHortalizas', 'Freq_Consumo_Legumbres',\r\n",
    "       'Freq_Consumo_EmbutidosFiambres', 'Freq_Consumo_Lácteos',\r\n",
    "       'Freq_Consumo_Dulces', 'Freq_Consumo_ComidaRápida',\r\n",
    "       'Freq_Consumo_ZumoNatural', 'Freq_Diaria_CepilladoDientes',\r\n",
    "       '¿Fuma actualmente', 'Freq_Consumo_Alcohol',\r\n",
    "       'ApoyoAfectivoPersonal_AmigosFamiliares', 'ClaseSocial_BasadaOcupación',\r\n",
    "       'Índice_MasaCorporal']]\r\n",
    "\r\n",
    "y = ENS_2017_C0['Salud_percibida']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_rbf = SVR(kernel='rbf', C=100, gamma=0.1, epsilon=.1)\r\n",
    "\r\n",
    "model = svr_rbf.fit(X_train, y_train)\r\n",
    "print(\"model.score_train:\", model.score(X_train, y_train))\r\n",
    "y_prediction_train = model.predict(X_train)\r\n",
    "MSE_train = mean_squared_error(y_train, y_prediction_train)\r\n",
    "print(\"MSE_train:\", MSE_train)\r\n",
    "\r\n",
    "print ('.........................')\r\n",
    "\r\n",
    "svr_rbf = SVR(kernel='rbf', C=100, gamma=0.1, epsilon=.1)\r\n",
    "model = svr_rbf.fit(X_test, y_test)\r\n",
    "print(\"model.score_test:\", model.score(X_test, y_test))\r\n",
    "y_prediction_test = model.predict(X_test)\r\n",
    "MSE_test = mean_squared_error(y_test, y_prediction_test)\r\n",
    "print(\"MSE_test:\", MSE_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENS_2017_C1 = pd.read_csv(\"../data/Bases_trabajo/ENS_2017_C1.csv\", sep =',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ENS_2017_C1[['CCAA', 'Sexo', 'Edad',\r\n",
    "       'Actividad_economica_actual', 'Nacionalidad_española', 'Convivencia',\r\n",
    "       'Estado_civil', 'Nivel_estudios', 'Vacunación_gripe',\r\n",
    "       'Toma_tensiónArterial_profesional', 'Medición_colesterol',\r\n",
    "       'Prueba_sangreHeces', 'Colonoscopia', 'Peso(Kg)',\r\n",
    "       'Freq_ActividadFísica', 'Freq_Consumo_FrutaFresca',\r\n",
    "       'Freq_Consumo_Carne', 'Freq_Consumo_Huevos', 'Freq_Consumo_Pescado',\r\n",
    "       'Freq_Consumo_PastaArrozPatatas', 'Freq_Consumo_PanCereales',\r\n",
    "       'Freq_Consumo_VerdurasEnsaladasHortalizas', 'Freq_Consumo_Legumbres',\r\n",
    "       'Freq_Consumo_EmbutidosFiambres', 'Freq_Consumo_Lácteos',\r\n",
    "       'Freq_Consumo_Dulces', 'Freq_Consumo_ComidaRápida',\r\n",
    "       'Freq_Consumo_ZumoNatural', 'Freq_Diaria_CepilladoDientes',\r\n",
    "       '¿Fuma actualmente', 'Freq_Consumo_Alcohol',\r\n",
    "       'ApoyoAfectivoPersonal_AmigosFamiliares', 'ClaseSocial_BasadaOcupación',\r\n",
    "       'Índice_MasaCorporal']]\r\n",
    "\r\n",
    "y = ENS_2017_C1['Salud_percibida']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_rbf = SVR(kernel='rbf', C=100, gamma=0.1, epsilon=.1)\r\n",
    "\r\n",
    "model = svr_rbf.fit(X_train, y_train)\r\n",
    "print(\"model.score_train:\", model.score(X_train, y_train))\r\n",
    "y_prediction_train = model.predict(X_train)\r\n",
    "MSE_train = mean_squared_error(y_train, y_prediction_train)\r\n",
    "print(\"MSE_train:\", MSE_train)\r\n",
    "\r\n",
    "print ('.........................')\r\n",
    "\r\n",
    "svr_rbf = SVR(kernel='rbf', C=100, gamma=0.1, epsilon=.1)\r\n",
    "model = svr_rbf.fit(X_test, y_test)\r\n",
    "print(\"model.score_test:\", model.score(X_test, y_test))\r\n",
    "y_prediction_test = model.predict(X_test)\r\n",
    "MSE_test = mean_squared_error(y_test, y_prediction_test)\r\n",
    "print(\"MSE_test:\", MSE_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENS_2017_C2 = pd.read_csv(\"../data/Bases_trabajo/ENS_2017_C2.csv\", sep =',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ENS_2017_C2[['CCAA', 'Sexo', 'Edad',\r\n",
    "       'Actividad_economica_actual', 'Nacionalidad_española', 'Convivencia',\r\n",
    "       'Estado_civil', 'Nivel_estudios', 'Vacunación_gripe',\r\n",
    "       'Toma_tensiónArterial_profesional', 'Medición_colesterol',\r\n",
    "       'Prueba_sangreHeces', 'Colonoscopia', 'Peso(Kg)',\r\n",
    "       'Freq_ActividadFísica', 'Freq_Consumo_FrutaFresca',\r\n",
    "       'Freq_Consumo_Carne', 'Freq_Consumo_Huevos', 'Freq_Consumo_Pescado',\r\n",
    "       'Freq_Consumo_PastaArrozPatatas', 'Freq_Consumo_PanCereales',\r\n",
    "       'Freq_Consumo_VerdurasEnsaladasHortalizas', 'Freq_Consumo_Legumbres',\r\n",
    "       'Freq_Consumo_EmbutidosFiambres', 'Freq_Consumo_Lácteos',\r\n",
    "       'Freq_Consumo_Dulces', 'Freq_Consumo_ComidaRápida',\r\n",
    "       'Freq_Consumo_ZumoNatural', 'Freq_Diaria_CepilladoDientes',\r\n",
    "       '¿Fuma actualmente', 'Freq_Consumo_Alcohol',\r\n",
    "       'ApoyoAfectivoPersonal_AmigosFamiliares', 'ClaseSocial_BasadaOcupación',\r\n",
    "       'Índice_MasaCorporal']]\r\n",
    "\r\n",
    "y = ENS_2017_C2['Salud_percibida']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_rbf = SVR(kernel='rbf', C=100, gamma=0.1, epsilon=.1)\r\n",
    "\r\n",
    "model = svr_rbf.fit(X_train, y_train)\r\n",
    "print(\"model.score_train:\", model.score(X_train, y_train))\r\n",
    "y_prediction_train = model.predict(X_train)\r\n",
    "MSE_train = mean_squared_error(y_train, y_prediction_train)\r\n",
    "print(\"MSE_train:\", MSE_train)\r\n",
    "\r\n",
    "print ('.........................')\r\n",
    "\r\n",
    "svr_rbf = SVR(kernel='rbf', C=100, gamma=0.1, epsilon=.1)\r\n",
    "model = svr_rbf.fit(X_test, y_test)\r\n",
    "print(\"model.score_test:\", model.score(X_test, y_test))\r\n",
    "y_prediction_test = model.predict(X_test)\r\n",
    "MSE_test = mean_squared_error(y_test, y_prediction_test)\r\n",
    "print(\"MSE_test:\", MSE_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENS_2017_C = pd.read_csv(\"../data/Bases_trabajo/ENS_2017_C.csv\", sep =',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ENS_2017_C[['CCAA', 'Sexo', 'Edad',\r\n",
    "       'Actividad_economica_actual', 'Nacionalidad_española', 'Convivencia',\r\n",
    "       'Estado_civil', 'Nivel_estudios', 'Vacunación_gripe',\r\n",
    "       'Toma_tensiónArterial_profesional', 'Medición_colesterol',\r\n",
    "       'Prueba_sangreHeces', 'Colonoscopia', 'Peso(Kg)',\r\n",
    "       'Freq_ActividadFísica', 'Freq_Consumo_FrutaFresca',\r\n",
    "       'Freq_Consumo_Carne', 'Freq_Consumo_Huevos', 'Freq_Consumo_Pescado',\r\n",
    "       'Freq_Consumo_PastaArrozPatatas', 'Freq_Consumo_PanCereales',\r\n",
    "       'Freq_Consumo_VerdurasEnsaladasHortalizas', 'Freq_Consumo_Legumbres',\r\n",
    "       'Freq_Consumo_EmbutidosFiambres', 'Freq_Consumo_Lácteos',\r\n",
    "       'Freq_Consumo_Dulces', 'Freq_Consumo_ComidaRápida',\r\n",
    "       'Freq_Consumo_ZumoNatural', 'Freq_Diaria_CepilladoDientes',\r\n",
    "       '¿Fuma actualmente', 'Freq_Consumo_Alcohol',\r\n",
    "       'ApoyoAfectivoPersonal_AmigosFamiliares', 'ClaseSocial_BasadaOcupación',\r\n",
    "       'Índice_MasaCorporal']]\r\n",
    "\r\n",
    "y = ENS_2017_C['Salud_percibida']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_rbf = SVR(kernel='rbf', C=100, gamma=0.1, epsilon=.1)\r\n",
    "\r\n",
    "model = svr_rbf.fit(X_train, y_train)\r\n",
    "print(\"model.score_train:\", model.score(X_train, y_train))\r\n",
    "y_prediction_train = model.predict(X_train)\r\n",
    "MSE_train = mean_squared_error(y_train, y_prediction_train)\r\n",
    "print(\"MSE_train:\", MSE_train)\r\n",
    "\r\n",
    "print ('.........................')\r\n",
    "\r\n",
    "svr_rbf = SVR(kernel='rbf', C=100, gamma=0.1, epsilon=.1)\r\n",
    "model = svr_rbf.fit(X_test, y_test)\r\n",
    "print(\"model.score_test:\", model.score(X_test, y_test))\r\n",
    "y_prediction_test = model.predict(X_test)\r\n",
    "MSE_test = mean_squared_error(y_test, y_prediction_test)\r\n",
    "print(\"MSE_test:\", MSE_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusión Modelos Regresión \r\n",
    "## El mejor modelo de regresión es el de  regresión polinómica con 4 degrees. Con este modelo se obtiene en el total de la base: \r\n",
    "## score_test: 1.000000\r\n",
    "## MSE_test: 3.419487e-24 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos de clasificación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Se pasan a variables categóricas las variables numéricas: edad y peso\r\n",
    "\r\n",
    "#### Hallamos la mediana y los cuartiles 25 y 75 para establecer las categorías en ambas variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENS_2017_C = pd.read_csv(\"../data/Bases_trabajo/ENS_2017_C.csv\", sep =',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENS_2017_C_agr = ENS_2017_C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mediana_Edad = ENS_2017_C_agr['Edad'].median()\r\n",
    "Cuartil25_Edad =ENS_2017_C_agr['Edad'].quantile(0.25)\r\n",
    "Cuartil75_Edad =ENS_2017_C_agr['Edad'].quantile(0.75)\r\n",
    "Mediana_Peso = ENS_2017_C_agr['Peso(Kg)'].median()\r\n",
    "Cuartil25_Peso = ENS_2017_C_agr['Peso(Kg)'].quantile(0.25)\r\n",
    "Cuartil75_Peso = ENS_2017_C_agr['Peso(Kg)'].quantile(0.75)\r\n",
    "\r\n",
    "print (f'Edad: {Mediana_Edad}, {Cuartil25_Edad}, {Cuartil75_Edad}')\r\n",
    "print (f'Peso: {Mediana_Peso}, {Cuartil25_Peso}, {Cuartil75_Peso}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Establecemos 4 categorías en función de la mediana y los cuartiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edad\r\n",
    "ENS_2017_C_agr['Edad_ag'] = ENS_2017_C_agr['Edad']\r\n",
    "\r\n",
    "ENS_2017_C_agr.loc[ENS_2017_C_agr['Edad_ag']<= 40,'Edad_ag'] = 1\r\n",
    "ENS_2017_C_agr.loc[(ENS_2017_C_agr['Edad_ag']>40) & (ENS_2017_C_agr['Edad_ag']<=53),'Edad_ag'] = 2\r\n",
    "ENS_2017_C_agr.loc[(ENS_2017_C_agr['Edad_ag']>53) & (ENS_2017_C_agr['Edad_ag']<=68),'Edad_ag'] = 3\r\n",
    "ENS_2017_C_agr.loc[ENS_2017_C_agr['Edad_ag']>68,'Edad_ag'] = 4\r\n",
    "\r\n",
    "# Peso\r\n",
    "ENS_2017_C_agr['Peso_ag'] = ENS_2017_C_agr['Peso(Kg)']\r\n",
    "\r\n",
    "ENS_2017_C_agr.loc[ENS_2017_C_agr['Peso_ag']<= 62,'Peso_ag'] = 1\r\n",
    "ENS_2017_C_agr.loc[(ENS_2017_C_agr['Peso_ag']>62) & (ENS_2017_C_agr['Peso_ag']<=71),'Peso_ag'] = 2\r\n",
    "ENS_2017_C_agr.loc[(ENS_2017_C_agr['Peso_ag']>71) & (ENS_2017_C_agr['Peso_ag']<=82),'Peso_ag'] = 3\r\n",
    "ENS_2017_C_agr.loc[ENS_2017_C_agr['Peso_ag']>82,'Peso_ag'] = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Una vez creadas las nuevas variables de edad y peso agrupadas, archivamos la nueva base y creamos bases independientes con estas nuevas variables de cada uno de los clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENS_2017_C_agr.to csv ('../data/Bases_trabajo/ENS_2017_C_agr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENS_2017_C_agr = pd.read_csv(\"../data/Bases_trabajo/ENS_2017_C_agr.csv\", sep =',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cluster0= ENS_2017_C_agr.loc[:, 'Clusters'] == 0\r\n",
    "ENS_2017_C0_agr = ENS_2017_C_agr.loc[Cluster0]\r\n",
    "ENS_2017_C0_agr.to csv ('../data/Bases_trabajo/ENS_2017_C0_agr.csv')\r\n",
    "\r\n",
    "Cluster1= ENS_2017_C_agr.loc[:, 'Clusters'] == 1\r\n",
    "ENS_2017_C1_agr = ENS_2017_C_agr.loc[Cluster1]\r\n",
    "ENS_2017_C1_agr.to csv ('../data/Bases_trabajo/ENS_2017_C1_agr.csv')\r\n",
    "\r\n",
    "Cluster2= ENS_2017_C_agr.loc[:, 'Clusters'] == 2\r\n",
    "ENS_2017_C2_agr = ENS_2017_C_agr.loc[Cluster2]\r\n",
    "ENS_2017_C2_agr.to csv ('../data/Bases_trabajo/ENS_2017_C2_agr.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\r\n",
    "from sklearn.linear_model import LogisticRegression\r\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENS_2017_C0_agr = pd.read_csv(\"../data/Bases_trabajo/ENS_2017_C0_agr.csv\", sep =',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ENS_2017_C0_agr[['CCAA', 'Sexo', \r\n",
    "       'Actividad_economica_actual', 'Nacionalidad_española', 'Convivencia',\r\n",
    "       'Estado_civil', 'Nivel_estudios', 'Vacunación_gripe',\r\n",
    "       'Toma_tensiónArterial_profesional', 'Medición_colesterol',\r\n",
    "       'Prueba_sangreHeces', 'Colonoscopia', \r\n",
    "       'Freq_ActividadFísica', 'Freq_Consumo_FrutaFresca',\r\n",
    "       'Freq_Consumo_Carne', 'Freq_Consumo_Huevos', 'Freq_Consumo_Pescado',\r\n",
    "       'Freq_Consumo_PastaArrozPatatas', 'Freq_Consumo_PanCereales',\r\n",
    "       'Freq_Consumo_VerdurasEnsaladasHortalizas', 'Freq_Consumo_Legumbres',\r\n",
    "       'Freq_Consumo_EmbutidosFiambres', 'Freq_Consumo_Lácteos',\r\n",
    "       'Freq_Consumo_Dulces', 'Freq_Consumo_ComidaRápida',\r\n",
    "       'Freq_Consumo_ZumoNatural', 'Freq_Diaria_CepilladoDientes',\r\n",
    "       '¿Fuma actualmente', 'Freq_Consumo_Alcohol',\r\n",
    "       'ApoyoAfectivoPersonal_AmigosFamiliares', 'ClaseSocial_BasadaOcupación',\r\n",
    "       'Índice_MasaCorporal','Edad_ag','Peso_ag']]\r\n",
    "\r\n",
    "y = ENS_2017_C0_agr['Salud_percibida']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (' Cluster: 0')\r\n",
    "\r\n",
    "model = linear_model.LogisticRegression(max_iter=100)\r\n",
    "model.fit(X_train,y_train)\r\n",
    "score_train = model.score(X_train, y_train)\r\n",
    "y_predict_train = model.predict(X_train)\r\n",
    "Accuracy_train = accuracy_score(y_train, y_predict_train)\r\n",
    "print('Score_train:', score_train)\r\n",
    "print('Accuracy_train:', Accuracy_train)\r\n",
    "\r\n",
    "print ('......................')\r\n",
    "\r\n",
    "model.fit(X_test,y_test)\r\n",
    "score_test = model.score(X_test, y_test)\r\n",
    "y_predict_test = model.predict(X_test)\r\n",
    "Accuracy_test = accuracy_score(y_test, y_predict_test)\r\n",
    "print('Score_test:', score_test)\r\n",
    "print('Accuracy_test:', Accuracy_test)\r\n",
    "\r\n",
    "print ('.......................')\r\n",
    "\r\n",
    "model.fit(X, y)\r\n",
    "score_total = model.score(X, y)\r\n",
    "y_predict = model.predict(X)\r\n",
    "Accuracy_total = accuracy_score(y, y_predict)\r\n",
    "print('Score_total:', score_total)\r\n",
    "print('Accuracy_total:', Accuracy_total)\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENS_2017_C1_agr = pd.read_csv(\"../data/Bases_trabajo/ENS_2017_C1_agr.csv\", sep =',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ENS_2017_C1_agr[['CCAA', 'Sexo', \r\n",
    "       'Actividad_economica_actual', 'Nacionalidad_española', 'Convivencia',\r\n",
    "       'Estado_civil', 'Nivel_estudios', 'Vacunación_gripe',\r\n",
    "       'Toma_tensiónArterial_profesional', 'Medición_colesterol',\r\n",
    "       'Prueba_sangreHeces', 'Colonoscopia', \r\n",
    "       'Freq_ActividadFísica', 'Freq_Consumo_FrutaFresca',\r\n",
    "       'Freq_Consumo_Carne', 'Freq_Consumo_Huevos', 'Freq_Consumo_Pescado',\r\n",
    "       'Freq_Consumo_PastaArrozPatatas', 'Freq_Consumo_PanCereales',\r\n",
    "       'Freq_Consumo_VerdurasEnsaladasHortalizas', 'Freq_Consumo_Legumbres',\r\n",
    "       'Freq_Consumo_EmbutidosFiambres', 'Freq_Consumo_Lácteos',\r\n",
    "       'Freq_Consumo_Dulces', 'Freq_Consumo_ComidaRápida',\r\n",
    "       'Freq_Consumo_ZumoNatural', 'Freq_Diaria_CepilladoDientes',\r\n",
    "       '¿Fuma actualmente', 'Freq_Consumo_Alcohol',\r\n",
    "       'ApoyoAfectivoPersonal_AmigosFamiliares', 'ClaseSocial_BasadaOcupación',\r\n",
    "       'Índice_MasaCorporal','Edad_ag','Peso_ag']]\r\n",
    "\r\n",
    "y = ENS_2017_C1_agr['Salud_percibida']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Cluster:1')\r\n",
    "\r\n",
    "model = linear_model.LogisticRegression(max_iter=100)\r\n",
    "\r\n",
    "model.fit(X_train,y_train)\r\n",
    "score_train = model.score(X_train, y_train)\r\n",
    "y_predict_train = model.predict(X_train)\r\n",
    "Accuracy_train = accuracy_score(y_train, y_predict_train)\r\n",
    "print('Score_train:', score_train)\r\n",
    "print('Accuracy_train:', Accuracy_train)\r\n",
    "\r\n",
    "print ('......................')\r\n",
    "\r\n",
    "model.fit(X_test,y_test)\r\n",
    "score_test = model.score(X_test, y_test)\r\n",
    "y_predict_test = model.predict(X_test)\r\n",
    "Accuracy_test = accuracy_score(y_test, y_predict_test)\r\n",
    "print('Score_test:', score_test)\r\n",
    "print('Accuracy_test:', Accuracy_test)\r\n",
    "\r\n",
    "print ('.......................')\r\n",
    "\r\n",
    "model.fit(X, y)\r\n",
    "score_total = model.score(X, y)\r\n",
    "y_predict = model.predict(X)\r\n",
    "Accuracy_total = accuracy_score(y, y_predict)\r\n",
    "print('Score_total:', score_total)\r\n",
    "print('Accuracy_total:', Accuracy_total)\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENS_2017_C2_agr = pd.read_csv(\"../data/Bases_trabajo/ENS_2017_C2_agr.csv\", sep =',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ENS_2017_C2_agr[['CCAA', 'Sexo', \r\n",
    "       'Actividad_economica_actual', 'Nacionalidad_española', 'Convivencia',\r\n",
    "       'Estado_civil', 'Nivel_estudios', 'Vacunación_gripe',\r\n",
    "       'Toma_tensiónArterial_profesional', 'Medición_colesterol',\r\n",
    "       'Prueba_sangreHeces', 'Colonoscopia', \r\n",
    "       'Freq_ActividadFísica', 'Freq_Consumo_FrutaFresca',\r\n",
    "       'Freq_Consumo_Carne', 'Freq_Consumo_Huevos', 'Freq_Consumo_Pescado',\r\n",
    "       'Freq_Consumo_PastaArrozPatatas', 'Freq_Consumo_PanCereales',\r\n",
    "       'Freq_Consumo_VerdurasEnsaladasHortalizas', 'Freq_Consumo_Legumbres',\r\n",
    "       'Freq_Consumo_EmbutidosFiambres', 'Freq_Consumo_Lácteos',\r\n",
    "       'Freq_Consumo_Dulces', 'Freq_Consumo_ComidaRápida',\r\n",
    "       'Freq_Consumo_ZumoNatural', 'Freq_Diaria_CepilladoDientes',\r\n",
    "       '¿Fuma actualmente', 'Freq_Consumo_Alcohol',\r\n",
    "       'ApoyoAfectivoPersonal_AmigosFamiliares', 'ClaseSocial_BasadaOcupación',\r\n",
    "       'Índice_MasaCorporal','Edad_ag','Peso_ag']]\r\n",
    "\r\n",
    "y = ENS_2017_C2_agr['Salud_percibida']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Cluster: 2')\r\n",
    "\r\n",
    "model = linear_model.LogisticRegression(max_iter=100)\r\n",
    "\r\n",
    "model.fit(X_train,y_train)\r\n",
    "score_train = model.score(X_train, y_train)\r\n",
    "y_predict_train = model.predict(X_train)\r\n",
    "Accuracy_train = accuracy_score(y_train, y_predict_train)\r\n",
    "print('Score_train:', score_train)\r\n",
    "print('Accuracy_train:', Accuracy_train)\r\n",
    "\r\n",
    "print ('......................')\r\n",
    "\r\n",
    "model.fit(X_test,y_test)\r\n",
    "score_test = model.score(X_test, y_test)\r\n",
    "y_predict_test = model.predict(X_test)\r\n",
    "Accuracy_test = accuracy_score(y_test, y_predict_test)\r\n",
    "print('Score_test:', score_test)\r\n",
    "print('Accuracy_test:', Accuracy_test)\r\n",
    "\r\n",
    "print ('.......................')\r\n",
    "\r\n",
    "model.fit(X, y)\r\n",
    "score_total = model.score(X, y)\r\n",
    "y_predict = model.predict(X)\r\n",
    "Accuracy_total = accuracy_score(y, y_predict)\r\n",
    "print('Score_total:', score_total)\r\n",
    "print('Accuracy_total:', Accuracy_total)\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENS_2017_C_agr = pd.read_csv(\"../data/Bases_trabajo/ENS_2017_C_agr.csv\", sep =',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ENS_2017_C_agr[['CCAA', 'Sexo', \r\n",
    "       'Actividad_economica_actual', 'Nacionalidad_española', 'Convivencia',\r\n",
    "       'Estado_civil', 'Nivel_estudios', 'Vacunación_gripe',\r\n",
    "       'Toma_tensiónArterial_profesional', 'Medición_colesterol',\r\n",
    "       'Prueba_sangreHeces', 'Colonoscopia', \r\n",
    "       'Freq_ActividadFísica', 'Freq_Consumo_FrutaFresca',\r\n",
    "       'Freq_Consumo_Carne', 'Freq_Consumo_Huevos', 'Freq_Consumo_Pescado',\r\n",
    "       'Freq_Consumo_PastaArrozPatatas', 'Freq_Consumo_PanCereales',\r\n",
    "       'Freq_Consumo_VerdurasEnsaladasHortalizas', 'Freq_Consumo_Legumbres',\r\n",
    "       'Freq_Consumo_EmbutidosFiambres', 'Freq_Consumo_Lácteos',\r\n",
    "       'Freq_Consumo_Dulces', 'Freq_Consumo_ComidaRápida',\r\n",
    "       'Freq_Consumo_ZumoNatural', 'Freq_Diaria_CepilladoDientes',\r\n",
    "       '¿Fuma actualmente', 'Freq_Consumo_Alcohol',\r\n",
    "       'ApoyoAfectivoPersonal_AmigosFamiliares', 'ClaseSocial_BasadaOcupación',\r\n",
    "       'Índice_MasaCorporal','Edad_ag','Peso_ag']]\r\n",
    "\r\n",
    "y = ENS_2017_C_agr['Salud_percibida']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Base completa')\r\n",
    "\r\n",
    "model = linear_model.LogisticRegression(max_iter=100)\r\n",
    "model.fit(X_train,y_train)\r\n",
    "score_train = model.score(X_train, y_train)\r\n",
    "y_predict_train = model.predict(X_train)\r\n",
    "Accuracy_train = accuracy_score(y_train, y_predict_train)\r\n",
    "print('Score_train:', score_train)\r\n",
    "print('Accuracy_train:', Accuracy_train)\r\n",
    "\r\n",
    "print ('......................')\r\n",
    "\r\n",
    "model.fit(X_test,y_test)\r\n",
    "score_test = model.score(X_test, y_test)\r\n",
    "y_predict_test = model.predict(X_test)\r\n",
    "Accuracy_test = accuracy_score(y_test, y_predict_test)\r\n",
    "print('Score_test:', score_test)\r\n",
    "print('Accuracy_test:', Accuracy_test)\r\n",
    "\r\n",
    "print ('.......................')\r\n",
    "\r\n",
    "model.fit(X, y)\r\n",
    "score_total = model.score(X, y)\r\n",
    "y_predict = model.predict(X)\r\n",
    "Accuracy_total = accuracy_score(y, y_predict)\r\n",
    "print('Score_total:', score_total)\r\n",
    "print('Accuracy_total:', Accuracy_total)\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vemos que número de neighbors es el más adecuado para establecer el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENS_2017_C0_agr = pd.read_csv(\"../data/Bases_trabajo/ENS_2017_C0_agr.csv\", sep =',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ENS_2017_C0_agr[['CCAA', 'Sexo', \r\n",
    "       'Actividad_economica_actual', 'Nacionalidad_española', 'Convivencia',\r\n",
    "       'Estado_civil', 'Nivel_estudios', 'Vacunación_gripe',\r\n",
    "       'Toma_tensiónArterial_profesional', 'Medición_colesterol',\r\n",
    "       'Prueba_sangreHeces', 'Colonoscopia', \r\n",
    "       'Freq_ActividadFísica', 'Freq_Consumo_FrutaFresca',\r\n",
    "       'Freq_Consumo_Carne', 'Freq_Consumo_Huevos', 'Freq_Consumo_Pescado',\r\n",
    "       'Freq_Consumo_PastaArrozPatatas', 'Freq_Consumo_PanCereales',\r\n",
    "       'Freq_Consumo_VerdurasEnsaladasHortalizas', 'Freq_Consumo_Legumbres',\r\n",
    "       'Freq_Consumo_EmbutidosFiambres', 'Freq_Consumo_Lácteos',\r\n",
    "       'Freq_Consumo_Dulces', 'Freq_Consumo_ComidaRápida',\r\n",
    "       'Freq_Consumo_ZumoNatural', 'Freq_Diaria_CepilladoDientes',\r\n",
    "       '¿Fuma actualmente', 'Freq_Consumo_Alcohol',\r\n",
    "       'ApoyoAfectivoPersonal_AmigosFamiliares', 'ClaseSocial_BasadaOcupación',\r\n",
    "       'Índice_MasaCorporal','Edad_ag','Peso_ag']]\r\n",
    "\r\n",
    "y = ENS_2017_C0_agr['Salud_percibida']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Cluster: 0')\r\n",
    "\r\n",
    "neighbors_min = 2\r\n",
    "neighbors_max = 4\r\n",
    "\r\n",
    "for neighbors in range (neighbors_min,neighbors_max +1):\r\n",
    "    print ('neighbors:', neighbors)\r\n",
    "\r\n",
    "    model = KNeighborsClassifier(neighbors)\r\n",
    "    model.fit(X_train, y_train)\r\n",
    "    score_train = model.score(X_train, y_train)\r\n",
    "    y_pred_train = model.predict(X_train)\r\n",
    "    print(\"Score_train:\", score_train)\r\n",
    "    print(\"Accuracy_train:\", metrics.accuracy_score(y_train, y_pred_train))\r\n",
    "    \r\n",
    "    model.fit(X_test, y_test)\r\n",
    "    score_test = model.score(X_test, y_test)\r\n",
    "    y_pred_test = model.predict(X_test)\r\n",
    "    print(\"Score_test:\", score_test)\r\n",
    "    print(\"Accuracy_test:\", metrics.accuracy_score(y_test, y_pred_test))\r\n",
    "    print ('..........................')\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENS_2017_C1_agr = pd.read_csv(\"../data/Bases_trabajo/ENS_2017_C1_agr.csv\", sep =',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ENS_2017_C1_agr[['CCAA', 'Sexo', \r\n",
    "       'Actividad_economica_actual', 'Nacionalidad_española', 'Convivencia',\r\n",
    "       'Estado_civil', 'Nivel_estudios', 'Vacunación_gripe',\r\n",
    "       'Toma_tensiónArterial_profesional', 'Medición_colesterol',\r\n",
    "       'Prueba_sangreHeces', 'Colonoscopia', \r\n",
    "       'Freq_ActividadFísica', 'Freq_Consumo_FrutaFresca',\r\n",
    "       'Freq_Consumo_Carne', 'Freq_Consumo_Huevos', 'Freq_Consumo_Pescado',\r\n",
    "       'Freq_Consumo_PastaArrozPatatas', 'Freq_Consumo_PanCereales',\r\n",
    "       'Freq_Consumo_VerdurasEnsaladasHortalizas', 'Freq_Consumo_Legumbres',\r\n",
    "       'Freq_Consumo_EmbutidosFiambres', 'Freq_Consumo_Lácteos',\r\n",
    "       'Freq_Consumo_Dulces', 'Freq_Consumo_ComidaRápida',\r\n",
    "       'Freq_Consumo_ZumoNatural', 'Freq_Diaria_CepilladoDientes',\r\n",
    "       '¿Fuma actualmente', 'Freq_Consumo_Alcohol',\r\n",
    "       'ApoyoAfectivoPersonal_AmigosFamiliares', 'ClaseSocial_BasadaOcupación',\r\n",
    "       'Índice_MasaCorporal','Edad_ag','Peso_ag']]\r\n",
    "\r\n",
    "y = ENS_2017_C1_agr['Salud_percibida']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENS_2017_C2_agr = pd.read_csv(\"../data/Bases_trabajo/ENS_2017_C2_agr.csv\", sep =',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Cluster: 1')\r\n",
    "\r\n",
    "neighbors_min = 2\r\n",
    "neighbors_max = 4\r\n",
    "\r\n",
    "for neighbors in range (neighbors_min,neighbors_max +1):\r\n",
    "    print ('neighbors:', neighbors)\r\n",
    "\r\n",
    "    model = KNeighborsClassifier(neighbors)\r\n",
    "    model.fit(X_train, y_train)\r\n",
    "    score_train = model.score(X_train, y_train)\r\n",
    "    y_pred_train = model.predict(X_train)\r\n",
    "    print(\"Score_train:\", score_train)\r\n",
    "    print(\"Accuracy_train:\", metrics.accuracy_score(y_train, y_pred_train))\r\n",
    "    \r\n",
    "    model.fit(X_test, y_test)\r\n",
    "    score_test = model.score(X_test, y_test)\r\n",
    "    y_pred_test = model.predict(X_test)\r\n",
    "    print(\"Score_test:\", score_test)\r\n",
    "    print(\"Accuracy_test:\", metrics.accuracy_score(y_test, y_pred_test))\r\n",
    "    print ('..........................')\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ENS_2017_C2_agr[['CCAA', 'Sexo', \r\n",
    "       'Actividad_economica_actual', 'Nacionalidad_española', 'Convivencia',\r\n",
    "       'Estado_civil', 'Nivel_estudios', 'Vacunación_gripe',\r\n",
    "       'Toma_tensiónArterial_profesional', 'Medición_colesterol',\r\n",
    "       'Prueba_sangreHeces', 'Colonoscopia', \r\n",
    "       'Freq_ActividadFísica', 'Freq_Consumo_FrutaFresca',\r\n",
    "       'Freq_Consumo_Carne', 'Freq_Consumo_Huevos', 'Freq_Consumo_Pescado',\r\n",
    "       'Freq_Consumo_PastaArrozPatatas', 'Freq_Consumo_PanCereales',\r\n",
    "       'Freq_Consumo_VerdurasEnsaladasHortalizas', 'Freq_Consumo_Legumbres',\r\n",
    "       'Freq_Consumo_EmbutidosFiambres', 'Freq_Consumo_Lácteos',\r\n",
    "       'Freq_Consumo_Dulces', 'Freq_Consumo_ComidaRápida',\r\n",
    "       'Freq_Consumo_ZumoNatural', 'Freq_Diaria_CepilladoDientes',\r\n",
    "       '¿Fuma actualmente', 'Freq_Consumo_Alcohol',\r\n",
    "       'ApoyoAfectivoPersonal_AmigosFamiliares', 'ClaseSocial_BasadaOcupación',\r\n",
    "       'Índice_MasaCorporal','Edad_ag','Peso_ag']]\r\n",
    "\r\n",
    "y = ENS_2017_C2_agr['Salud_percibida']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Cluster: 2')\r\n",
    "\r\n",
    "neighbors_min = 2\r\n",
    "neighbors_max = 4\r\n",
    "\r\n",
    "for neighbors in range (neighbors_min,neighbors_max +1):\r\n",
    "    print ('neighbors:', neighbors)\r\n",
    "\r\n",
    "    model = KNeighborsClassifier(neighbors)\r\n",
    "    model.fit(X_train, y_train)\r\n",
    "    score_train = model.score(X_train, y_train)\r\n",
    "    y_pred_train = model.predict(X_train)\r\n",
    "    print(\"Score_train:\", score_train)\r\n",
    "    print(\"Accuracy_train:\", metrics.accuracy_score(y_train, y_pred_train))\r\n",
    "    \r\n",
    "    model.fit(X_test, y_test)\r\n",
    "    score_test = model.score(X_test, y_test)\r\n",
    "    y_pred_test = model.predict(X_test)\r\n",
    "    print(\"Score_test:\", score_test)\r\n",
    "    print(\"Accuracy_test:\", metrics.accuracy_score(y_test, y_pred_test))\r\n",
    "    print ('..........................')\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENS_2017_C_agr = pd.read_csv(\"../data/Bases_trabajo/ENS_2017_C_agr.csv\", sep =',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ENS_2017_C_agr[['CCAA', 'Sexo', \r\n",
    "       'Actividad_economica_actual', 'Nacionalidad_española', 'Convivencia',\r\n",
    "       'Estado_civil', 'Nivel_estudios', 'Vacunación_gripe',\r\n",
    "       'Toma_tensiónArterial_profesional', 'Medición_colesterol',\r\n",
    "       'Prueba_sangreHeces', 'Colonoscopia', \r\n",
    "       'Freq_ActividadFísica', 'Freq_Consumo_FrutaFresca',\r\n",
    "       'Freq_Consumo_Carne', 'Freq_Consumo_Huevos', 'Freq_Consumo_Pescado',\r\n",
    "       'Freq_Consumo_PastaArrozPatatas', 'Freq_Consumo_PanCereales',\r\n",
    "       'Freq_Consumo_VerdurasEnsaladasHortalizas', 'Freq_Consumo_Legumbres',\r\n",
    "       'Freq_Consumo_EmbutidosFiambres', 'Freq_Consumo_Lácteos',\r\n",
    "       'Freq_Consumo_Dulces', 'Freq_Consumo_ComidaRápida',\r\n",
    "       'Freq_Consumo_ZumoNatural', 'Freq_Diaria_CepilladoDientes',\r\n",
    "       '¿Fuma actualmente', 'Freq_Consumo_Alcohol',\r\n",
    "       'ApoyoAfectivoPersonal_AmigosFamiliares', 'ClaseSocial_BasadaOcupación',\r\n",
    "       'Índice_MasaCorporal','Edad_ag','Peso_ag']]\r\n",
    "\r\n",
    "y = ENS_2017_C_agr['Salud_percibida']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Base total')\r\n",
    "\r\n",
    "neighbors_min = 2\r\n",
    "neighbors_max = 4\r\n",
    "\r\n",
    "for neighbors in range (neighbors_min,neighbors_max +1):\r\n",
    "    print ('neighbors:', neighbors)\r\n",
    "\r\n",
    "    model = KNeighborsClassifier(neighbors)\r\n",
    "    model.fit(X_train, y_train)\r\n",
    "    score_train = model.score(X_train, y_train)\r\n",
    "    y_pred_train = model.predict(X_train)\r\n",
    "    print(\"Score_train:\", score_train)\r\n",
    "    print(\"Accuracy_train:\", metrics.accuracy_score(y_train, y_pred_train))\r\n",
    "    \r\n",
    "    model.fit(X_test, y_test)\r\n",
    "    score_test = model.score(X_test, y_test)\r\n",
    "    y_pred_test = model.predict(X_test)\r\n",
    "    print(\"Score_test:\", score_test)\r\n",
    "    print(\"Accuracy_test:\", metrics.accuracy_score(y_test, y_pred_test))\r\n",
    "    print ('..........................')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENS_2017_C0_agr = pd.read_csv(\"../data/Bases_trabajo/ENS_2017_C0_agr.csv\", sep =',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ENS_2017_C0_agr[['CCAA', 'Sexo', \r\n",
    "       'Actividad_economica_actual', 'Nacionalidad_española', 'Convivencia',\r\n",
    "       'Estado_civil', 'Nivel_estudios', 'Vacunación_gripe',\r\n",
    "       'Toma_tensiónArterial_profesional', 'Medición_colesterol',\r\n",
    "       'Prueba_sangreHeces', 'Colonoscopia', \r\n",
    "       'Freq_ActividadFísica', 'Freq_Consumo_FrutaFresca',\r\n",
    "       'Freq_Consumo_Carne', 'Freq_Consumo_Huevos', 'Freq_Consumo_Pescado',\r\n",
    "       'Freq_Consumo_PastaArrozPatatas', 'Freq_Consumo_PanCereales',\r\n",
    "       'Freq_Consumo_VerdurasEnsaladasHortalizas', 'Freq_Consumo_Legumbres',\r\n",
    "       'Freq_Consumo_EmbutidosFiambres', 'Freq_Consumo_Lácteos',\r\n",
    "       'Freq_Consumo_Dulces', 'Freq_Consumo_ComidaRápida',\r\n",
    "       'Freq_Consumo_ZumoNatural', 'Freq_Diaria_CepilladoDientes',\r\n",
    "       '¿Fuma actualmente', 'Freq_Consumo_Alcohol',\r\n",
    "       'ApoyoAfectivoPersonal_AmigosFamiliares', 'ClaseSocial_BasadaOcupación',\r\n",
    "       'Índice_MasaCorporal','Edad_ag','Peso_ag']]\r\n",
    "\r\n",
    "y = ENS_2017_C0_agr['Salud_percibida']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Cluster: 0')\r\n",
    "\r\n",
    "C_cands = [10, 30, 1000, 100]\r\n",
    "gamma_cands = [1, 3, 10, 30]\r\n",
    "max_score = -1\r\n",
    "C_pick = -1\r\n",
    "gamma_pick = -1\r\n",
    "for C in C_cands:\r\n",
    "    for gamma in gamma_cands:\r\n",
    "        clf = svm.SVC(C=C, kernel='rbf', gamma=gamma)\r\n",
    "        clf.fit(X_train, y_train)\r\n",
    "        score = clf.score(X_train, y_train)\r\n",
    "        if score > max_score:\r\n",
    "            max_score = score\r\n",
    "            C_pick = C\r\n",
    "            gamma_pick = gamma\r\n",
    "\r\n",
    "print (C_pick, gamma_pick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(C=10, kernel='rbf', gamma= 1)\r\n",
    "clf.fit(X_train, y_train)\r\n",
    "y_pred_train = clf.predict(X_train)\r\n",
    "print ('score_train:', clf.score(X_train, y_train))\r\n",
    "print(\"Accuracy_test:\", metrics.accuracy_score(y_train, y_pred_train))\r\n",
    "\r\n",
    "clf = svm.SVC(C=10, kernel='rbf', gamma= 1)\r\n",
    "clf.fit(X_test, y_test)\r\n",
    "y_pred_test = clf.predict(X_test)\r\n",
    "print ('score_test:', clf.score(X_test, y_test))\r\n",
    "print(\"Accuracy_test:\", metrics.accuracy_score(y_test, y_pred_test))\r\n",
    "\r\n",
    "clf = svm.SVC(C=10, kernel='rbf', gamma= 1)\r\n",
    "clf.fit(X, y)\r\n",
    "y_pred = clf.predict(X)\r\n",
    "print ('score_total:', clf.score(X, y))\r\n",
    "print(\"Accuracy_total:\", metrics.accuracy_score(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENS_2017_C1_agr = pd.read_csv(\"../data/Bases_trabajo/ENS_2017_C1_agr.csv\", sep =',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ENS_2017_C1_agr[['CCAA', 'Sexo', \r\n",
    "       'Actividad_economica_actual', 'Nacionalidad_española', 'Convivencia',\r\n",
    "       'Estado_civil', 'Nivel_estudios', 'Vacunación_gripe',\r\n",
    "       'Toma_tensiónArterial_profesional', 'Medición_colesterol',\r\n",
    "       'Prueba_sangreHeces', 'Colonoscopia', \r\n",
    "       'Freq_ActividadFísica', 'Freq_Consumo_FrutaFresca',\r\n",
    "       'Freq_Consumo_Carne', 'Freq_Consumo_Huevos', 'Freq_Consumo_Pescado',\r\n",
    "       'Freq_Consumo_PastaArrozPatatas', 'Freq_Consumo_PanCereales',\r\n",
    "       'Freq_Consumo_VerdurasEnsaladasHortalizas', 'Freq_Consumo_Legumbres',\r\n",
    "       'Freq_Consumo_EmbutidosFiambres', 'Freq_Consumo_Lácteos',\r\n",
    "       'Freq_Consumo_Dulces', 'Freq_Consumo_ComidaRápida',\r\n",
    "       'Freq_Consumo_ZumoNatural', 'Freq_Diaria_CepilladoDientes',\r\n",
    "       '¿Fuma actualmente', 'Freq_Consumo_Alcohol',\r\n",
    "       'ApoyoAfectivoPersonal_AmigosFamiliares', 'ClaseSocial_BasadaOcupación',\r\n",
    "       'Índice_MasaCorporal','Edad_ag','Peso_ag']]\r\n",
    "\r\n",
    "y = ENS_2017_C1_agr['Salud_percibida']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Cluster: 1')\r\n",
    "\r\n",
    "C_cands = [10, 30, 1000, 100]\r\n",
    "gamma_cands = [1, 3, 10, 30]\r\n",
    "max_score = -1\r\n",
    "C_pick = -1\r\n",
    "gamma_pick = -1\r\n",
    "for C in C_cands:\r\n",
    "    for gamma in gamma_cands:\r\n",
    "        clf = svm.SVC(C=C, kernel='rbf', gamma=gamma)\r\n",
    "        clf.fit(X_train, y_train)\r\n",
    "        score = clf.score(X_train, y_train)\r\n",
    "        if score > max_score:\r\n",
    "            max_score = score\r\n",
    "            C_pick = C\r\n",
    "            gamma_pick = gamma\r\n",
    "\r\n",
    "print (C_pick, gamma_pick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(C=10, kernel='rbf', gamma= 1)\r\n",
    "clf.fit(X_train, y_train)\r\n",
    "y_pred_train = clf.predict(X_train)\r\n",
    "print ('score_train:', clf.score(X_train, y_train))\r\n",
    "print(\"Accuracy_test:\", metrics.accuracy_score(y_train, y_pred_train))\r\n",
    "\r\n",
    "clf = svm.SVC(C=10, kernel='rbf', gamma= 1)\r\n",
    "clf.fit(X_test, y_test)\r\n",
    "y_pred_test = clf.predict(X_test)\r\n",
    "print ('score_test:', clf.score(X_test, y_test))\r\n",
    "print(\"Accuracy_test:\", metrics.accuracy_score(y_test, y_pred_test))\r\n",
    "\r\n",
    "clf = svm.SVC(C=10, kernel='rbf', gamma= 1)\r\n",
    "clf.fit(X, y)\r\n",
    "y_pred = clf.predict(X)\r\n",
    "print ('score_total:', clf.score(X, y))\r\n",
    "print(\"Accuracy_total:\", metrics.accuracy_score(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENS_2017_C2_agr = pd.read_csv(\"../data/Bases_trabajo/ENS_2017_C2_agr.csv\", sep =',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ENS_2017_C2_agr[['CCAA', 'Sexo', \r\n",
    "       'Actividad_economica_actual', 'Nacionalidad_española', 'Convivencia',\r\n",
    "       'Estado_civil', 'Nivel_estudios', 'Vacunación_gripe',\r\n",
    "       'Toma_tensiónArterial_profesional', 'Medición_colesterol',\r\n",
    "       'Prueba_sangreHeces', 'Colonoscopia', \r\n",
    "       'Freq_ActividadFísica', 'Freq_Consumo_FrutaFresca',\r\n",
    "       'Freq_Consumo_Carne', 'Freq_Consumo_Huevos', 'Freq_Consumo_Pescado',\r\n",
    "       'Freq_Consumo_PastaArrozPatatas', 'Freq_Consumo_PanCereales',\r\n",
    "       'Freq_Consumo_VerdurasEnsaladasHortalizas', 'Freq_Consumo_Legumbres',\r\n",
    "       'Freq_Consumo_EmbutidosFiambres', 'Freq_Consumo_Lácteos',\r\n",
    "       'Freq_Consumo_Dulces', 'Freq_Consumo_ComidaRápida',\r\n",
    "       'Freq_Consumo_ZumoNatural', 'Freq_Diaria_CepilladoDientes',\r\n",
    "       '¿Fuma actualmente', 'Freq_Consumo_Alcohol',\r\n",
    "       'ApoyoAfectivoPersonal_AmigosFamiliares', 'ClaseSocial_BasadaOcupación',\r\n",
    "       'Índice_MasaCorporal','Edad_ag','Peso_ag']]\r\n",
    "\r\n",
    "y = ENS_2017_C2_agr['Salud_percibida']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Cluster: 2')\r\n",
    "\r\n",
    "C_cands = [10, 30, 1000, 100]\r\n",
    "gamma_cands = [1, 3, 10, 30]\r\n",
    "max_score = -1\r\n",
    "C_pick = -1\r\n",
    "gamma_pick = -1\r\n",
    "for C in C_cands:\r\n",
    "    for gamma in gamma_cands:\r\n",
    "        clf = svm.SVC(C=C, kernel='rbf', gamma=gamma)\r\n",
    "        clf.fit(X_train, y_train)\r\n",
    "        score = clf.score(X_train, y_train)\r\n",
    "        if score > max_score:\r\n",
    "            max_score = score\r\n",
    "            C_pick = C\r\n",
    "            gamma_pick = gamma\r\n",
    "\r\n",
    "print (C_pick, gamma_pick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(C=10, kernel='rbf', gamma= 1)\r\n",
    "clf.fit(X_train, y_train)\r\n",
    "y_pred_train = clf.predict(X_train)\r\n",
    "print ('score_train:', clf.score(X_train, y_train))\r\n",
    "print(\"Accuracy_test:\", metrics.accuracy_score(y_train, y_pred_train))\r\n",
    "\r\n",
    "clf = svm.SVC(C=10, kernel='rbf', gamma= 1)\r\n",
    "clf.fit(X_test, y_test)\r\n",
    "y_pred_test = clf.predict(X_test)\r\n",
    "print ('score_test:', clf.score(X_test, y_test))\r\n",
    "print(\"Accuracy_test:\", metrics.accuracy_score(y_test, y_pred_test))\r\n",
    "\r\n",
    "clf = svm.SVC(C=10, kernel='rbf', gamma= 1)\r\n",
    "clf.fit(X, y)\r\n",
    "y_pred = clf.predict(X)\r\n",
    "print ('score_total:', clf.score(X, y))\r\n",
    "print(\"Accuracy_total:\", metrics.accuracy_score(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENS_2017_C_agr = pd.read_csv(\"../data/Bases_trabajo/ENS_2017_C_agr.csv\", sep =',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ENS_2017_C_agr[['CCAA', 'Sexo', \r\n",
    "       'Actividad_economica_actual', 'Nacionalidad_española', 'Convivencia',\r\n",
    "       'Estado_civil', 'Nivel_estudios', 'Vacunación_gripe',\r\n",
    "       'Toma_tensiónArterial_profesional', 'Medición_colesterol',\r\n",
    "       'Prueba_sangreHeces', 'Colonoscopia', \r\n",
    "       'Freq_ActividadFísica', 'Freq_Consumo_FrutaFresca',\r\n",
    "       'Freq_Consumo_Carne', 'Freq_Consumo_Huevos', 'Freq_Consumo_Pescado',\r\n",
    "       'Freq_Consumo_PastaArrozPatatas', 'Freq_Consumo_PanCereales',\r\n",
    "       'Freq_Consumo_VerdurasEnsaladasHortalizas', 'Freq_Consumo_Legumbres',\r\n",
    "       'Freq_Consumo_EmbutidosFiambres', 'Freq_Consumo_Lácteos',\r\n",
    "       'Freq_Consumo_Dulces', 'Freq_Consumo_ComidaRápida',\r\n",
    "       'Freq_Consumo_ZumoNatural', 'Freq_Diaria_CepilladoDientes',\r\n",
    "       '¿Fuma actualmente', 'Freq_Consumo_Alcohol',\r\n",
    "       'ApoyoAfectivoPersonal_AmigosFamiliares', 'ClaseSocial_BasadaOcupación',\r\n",
    "       'Índice_MasaCorporal','Edad_ag','Peso_ag']]\r\n",
    "\r\n",
    "y = ENS_2017_C_agr['Salud_percibida']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vemos que C y gamma es más adecuado para establecer el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Base total')\r\n",
    "\r\n",
    "C_cands = [10, 30, 1000, 100]\r\n",
    "gamma_cands = [1, 3, 10, 30]\r\n",
    "max_score = -1\r\n",
    "C_pick = -1\r\n",
    "gamma_pick = -1\r\n",
    "for C in C_cands:\r\n",
    "    for gamma in gamma_cands:\r\n",
    "        clf = svm.SVC(C=C, kernel='rbf', gamma=gamma)\r\n",
    "        clf.fit(X_train, y_train)\r\n",
    "        score = clf.score(X_train, y_train)\r\n",
    "        if score > max_score:\r\n",
    "            max_score = score\r\n",
    "            C_pick = C\r\n",
    "            gamma_pick = gamma\r\n",
    "\r\n",
    "print (C_pick, gamma_pick)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### El valor de C más adecuado es: 10\r\n",
    "### El valor de gamma más adecuado es: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(C=10, kernel='rbf', gamma= 1)\r\n",
    "clf.fit(X_train, y_train)\r\n",
    "y_pred_train = clf.predict(X_train)\r\n",
    "print ('score_train:', clf.score(X_train, y_train))\r\n",
    "print(\"Accuracy_test:\", metrics.accuracy_score(y_train, y_pred_train))\r\n",
    "\r\n",
    "clf = svm.SVC(C=10, kernel='rbf', gamma= 1)\r\n",
    "clf.fit(X_test, y_test)\r\n",
    "y_pred_test = clf.predict(X_test)\r\n",
    "print ('score_test:', clf.score(X_test, y_test))\r\n",
    "print(\"Accuracy_test:\", metrics.accuracy_score(y_test, y_pred_test))\r\n",
    "\r\n",
    "clf = svm.SVC(C=10, kernel='rbf', gamma= 1)\r\n",
    "clf.fit(X, y)\r\n",
    "y_pred = clf.predict(X)\r\n",
    "print ('score_ total:', clf.score(X, y))\r\n",
    "print(\"Accuracy_total:\", metrics.accuracy_score(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusión Modelos Clasificación\r\n",
    "## El mejor modelo de clasificación es SCV con un kernel='rbf', C= 10 y gamma = 1. Con este modelo se obtiene en el total de la base: \r\n",
    "## score_test: 1.0\r\n",
    "## recall_test: 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decission Tree y Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decission Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENS_2017_C0 = pd.read_csv(\"../data/Bases_trabajo/ENS_2017_C0.csv\", sep =',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ENS_2017_C0[['CCAA', 'Sexo', 'Edad',\r\n",
    "       'Actividad_economica_actual', 'Nacionalidad_española', 'Convivencia',\r\n",
    "       'Estado_civil', 'Nivel_estudios', 'Vacunación_gripe',\r\n",
    "       'Toma_tensiónArterial_profesional', 'Medición_colesterol',\r\n",
    "       'Prueba_sangreHeces', 'Colonoscopia', 'Peso(Kg)',\r\n",
    "       'Freq_ActividadFísica', 'Freq_Consumo_FrutaFresca',\r\n",
    "       'Freq_Consumo_Carne', 'Freq_Consumo_Huevos', 'Freq_Consumo_Pescado',\r\n",
    "       'Freq_Consumo_PastaArrozPatatas', 'Freq_Consumo_PanCereales',\r\n",
    "       'Freq_Consumo_VerdurasEnsaladasHortalizas', 'Freq_Consumo_Legumbres',\r\n",
    "       'Freq_Consumo_EmbutidosFiambres', 'Freq_Consumo_Lácteos',\r\n",
    "       'Freq_Consumo_Dulces', 'Freq_Consumo_ComidaRápida',\r\n",
    "       'Freq_Consumo_ZumoNatural', 'Freq_Diaria_CepilladoDientes',\r\n",
    "       '¿Fuma actualmente', 'Freq_Consumo_Alcohol',\r\n",
    "       'ApoyoAfectivoPersonal_AmigosFamiliares', 'ClaseSocial_BasadaOcupación',\r\n",
    "       'Índice_MasaCorporal']]\r\n",
    "\r\n",
    "y = ENS_2017_C0['Salud_percibida']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Cluster: 0')\r\n",
    "\r\n",
    "max_depth_min = 3\r\n",
    "max_depth_max = 5\r\n",
    "\r\n",
    "for max_depth in range (max_depth_min,max_depth_max +1):\r\n",
    "    \r\n",
    "    print ('max_depth:', max_depth)\r\n",
    "\r\n",
    "    print ('Train')\r\n",
    "\r\n",
    "    dtr = DecisionTreeRegressor(max_depth = max_depth)\r\n",
    "    dtr.fit(X_train, y_train)\r\n",
    "    score_train = dtr.score(X_train, y_train)\r\n",
    "    print ('Score_train:', score_train)\r\n",
    "    predictions_train = dtr.predict(X_train)\r\n",
    "    errores_train = abs(predictions_train - y_train)\r\n",
    "    np.mean(errores_train)\r\n",
    "    prop = 100 * (errores_train/y_train)\r\n",
    "    mape_train = np.mean(prop)\r\n",
    "    print ('MAPE_train, mape_train)\r\n",
    "    \r\n",
    "    import_dict = {\r\n",
    "        'features': X_train.columns,\r\n",
    "        'importance_train': dtr.feature_importances_\r\n",
    "    }\r\n",
    "\r\n",
    "    Importance_variables_train = pd.DataFrame(import_dict).sort_values('importance_train', ascending=False)\r\n",
    "    print (Importance_variables_train)\r\n",
    "\r\n",
    "    print ('Test')\r\n",
    "\r\n",
    "    dtr = DecisionTreeRegressor(max_depth = max_depth)\r\n",
    "    dtr.fit(X_test, y_test)\r\n",
    "    score_test = dtr.score(X_test,y_test)\r\n",
    "    print ('Score_test:', score_test)\r\n",
    "    predictions_test = dtr.predict(X_test)\r\n",
    "    errores_test = abs(predictions_test - y_test)\r\n",
    "    np.mean(errores_test)\r\n",
    "    prop = 100 * (errores_test/y_test)\r\n",
    "    mape_test = np.mean(prop)\r\n",
    "    print ('MAPE_test:', mape_test)\r\n",
    "\r\n",
    "    import_dict = {\r\n",
    "        'features': X_test.columns,\r\n",
    "        'importance_test': dtr.feature_importances_\r\n",
    "    }\r\n",
    "\r\n",
    "    Importance_variables_test = pd.DataFrame(import_dict).sort_values('importance_test', ascending=False)\r\n",
    "    print (Importance_variables_test)\r\n",
    "\r\n",
    "    print ('Total')  \r\n",
    "    \r\n",
    "    dtr = DecisionTreeRegressor(max_depth = max_depth)\r\n",
    "    dtr.fit(X, y)\r\n",
    "    score_total = dtr.score(X,y)\r\n",
    "    print ('Score_total:', score_total)\r\n",
    "    predictions_total = dtr.predict(X)\r\n",
    "    errores_total = abs(predictions_total - y)\r\n",
    "    np.mean(errores_total)\r\n",
    "    prop = 100 * (errores_total/y)\r\n",
    "    mape_total = np.mean(prop)\r\n",
    "    print ('MAPE_total:', mape_total)\r\n",
    "\r\n",
    "    import_dict = {\r\n",
    "        'features': X.columns,\r\n",
    "        'importance_total': dtr.feature_importances_\r\n",
    "    }\r\n",
    "\r\n",
    "    Importance_variables_total = pd.DataFrame(import_dict).sort_values('importance_total', ascending=False)\r\n",
    "    print (Importance_variables_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENS_2017_C1 = pd.read_csv(\"../data/Bases_trabajo/ENS_2017_C1.csv\", sep =',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ENS_2017_C1[['CCAA', 'Sexo', 'Edad',\r\n",
    "       'Actividad_economica_actual', 'Nacionalidad_española', 'Convivencia',\r\n",
    "       'Estado_civil', 'Nivel_estudios', 'Vacunación_gripe',\r\n",
    "       'Toma_tensiónArterial_profesional', 'Medición_colesterol',\r\n",
    "       'Prueba_sangreHeces', 'Colonoscopia', 'Peso(Kg)',\r\n",
    "       'Freq_ActividadFísica', 'Freq_Consumo_FrutaFresca',\r\n",
    "       'Freq_Consumo_Carne', 'Freq_Consumo_Huevos', 'Freq_Consumo_Pescado',\r\n",
    "       'Freq_Consumo_PastaArrozPatatas', 'Freq_Consumo_PanCereales',\r\n",
    "       'Freq_Consumo_VerdurasEnsaladasHortalizas', 'Freq_Consumo_Legumbres',\r\n",
    "       'Freq_Consumo_EmbutidosFiambres', 'Freq_Consumo_Lácteos',\r\n",
    "       'Freq_Consumo_Dulces', 'Freq_Consumo_ComidaRápida',\r\n",
    "       'Freq_Consumo_ZumoNatural', 'Freq_Diaria_CepilladoDientes',\r\n",
    "       '¿Fuma actualmente', 'Freq_Consumo_Alcohol',\r\n",
    "       'ApoyoAfectivoPersonal_AmigosFamiliares', 'ClaseSocial_BasadaOcupación',\r\n",
    "       'Índice_MasaCorporal']]\r\n",
    "\r\n",
    "y = ENS_2017_C1['Salud_percibida']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Cluster: 1')\r\n",
    "\r\n",
    "max_depth_min = 3\r\n",
    "max_depth_max = 5\r\n",
    "\r\n",
    "for max_depth in range (max_depth_min,max_depth_max +1):\r\n",
    "    \r\n",
    "    print ('max_depth:', max_depth)\r\n",
    "\r\n",
    "    print ('Train')\r\n",
    "\r\n",
    "    dtr = DecisionTreeRegressor(max_depth = max_depth)\r\n",
    "    dtr.fit(X_train, y_train)\r\n",
    "    score_train = dtr.score(X_train, y_train)\r\n",
    "    print ('Score_train:', score_train)\r\n",
    "    predictions_train = dtr.predict(X_train)\r\n",
    "    errores_train = abs(predictions_train - y_train)\r\n",
    "    np.mean(errores_train)\r\n",
    "    prop = 100 * (errores_train/y_train)\r\n",
    "    mape_train = np.mean(prop)\r\n",
    "    print ('MAPE_train:', mape_train)\r\n",
    "    \r\n",
    "    import_dict = {\r\n",
    "        'features': X_train.columns,\r\n",
    "        'importance_train': dtr.feature_importances_\r\n",
    "    }\r\n",
    "\r\n",
    "    Importance_variables_train = pd.DataFrame(import_dict).sort_values('importance_train', ascending=False)\r\n",
    "    print (Importance_variables_train)\r\n",
    "\r\n",
    "    print ('Test')\r\n",
    "\r\n",
    "    dtr = DecisionTreeRegressor(max_depth = max_depth)\r\n",
    "    dtr.fit(X_test, y_test)\r\n",
    "    score_test = dtr.score(X_test,y_test)\r\n",
    "    print ('Score_test:', score_test)\r\n",
    "    predictions_test = dtr.predict(X_test)\r\n",
    "    errores_test = abs(predictions_test - y_test)\r\n",
    "    np.mean(errores_test)\r\n",
    "    prop = 100 * (errores_test/y_test)\r\n",
    "    mape_test = np.mean(prop)\r\n",
    "    print ('MAPE_test:', mape_test)\r\n",
    "\r\n",
    "    import_dict = {\r\n",
    "        'features': X_test.columns,\r\n",
    "        'importance_test': dtr.feature_importances_\r\n",
    "    }\r\n",
    "\r\n",
    "    Importance_variables_test = pd.DataFrame(import_dict).sort_values('importance_test', ascending=False)\r\n",
    "    print (Importance_variables_test)\r\n",
    "\r\n",
    "    print ('Total')  \r\n",
    "    \r\n",
    "    dtr = DecisionTreeRegressor(max_depth = max_depth)\r\n",
    "    dtr.fit(X, y)\r\n",
    "    score_total = dtr.score(X,y)\r\n",
    "    print ('Score_total:', score_total)\r\n",
    "    predictions_total = dtr.predict(X)\r\n",
    "    errores_total = abs(predictions_total - y)\r\n",
    "    np.mean(errores_total)\r\n",
    "    prop = 100 * (errores_total/y)\r\n",
    "    mape_total = np.mean(prop)\r\n",
    "    print ('MAPE_total:', mape_total)\r\n",
    "\r\n",
    "    import_dict = {\r\n",
    "        'features': X.columns,\r\n",
    "        'importance_total': dtr.feature_importances_\r\n",
    "    }\r\n",
    "\r\n",
    "    Importance_variables_total = pd.DataFrame(import_dict).sort_values('importance_total', ascending=False)\r\n",
    "    print (Importance_variables_total)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENS_2017_C2 = pd.read_csv(\"../data/Bases_trabajo/ENS_2017_C2.csv\", sep =',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ENS_2017_C2[['CCAA', 'Sexo', 'Edad',\r\n",
    "       'Actividad_economica_actual', 'Nacionalidad_española', 'Convivencia',\r\n",
    "       'Estado_civil', 'Nivel_estudios', 'Vacunación_gripe',\r\n",
    "       'Toma_tensiónArterial_profesional', 'Medición_colesterol',\r\n",
    "       'Prueba_sangreHeces', 'Colonoscopia', 'Peso(Kg)',\r\n",
    "       'Freq_ActividadFísica', 'Freq_Consumo_FrutaFresca',\r\n",
    "       'Freq_Consumo_Carne', 'Freq_Consumo_Huevos', 'Freq_Consumo_Pescado',\r\n",
    "       'Freq_Consumo_PastaArrozPatatas', 'Freq_Consumo_PanCereales',\r\n",
    "       'Freq_Consumo_VerdurasEnsaladasHortalizas', 'Freq_Consumo_Legumbres',\r\n",
    "       'Freq_Consumo_EmbutidosFiambres', 'Freq_Consumo_Lácteos',\r\n",
    "       'Freq_Consumo_Dulces', 'Freq_Consumo_ComidaRápida',\r\n",
    "       'Freq_Consumo_ZumoNatural', 'Freq_Diaria_CepilladoDientes',\r\n",
    "       '¿Fuma actualmente', 'Freq_Consumo_Alcohol',\r\n",
    "       'ApoyoAfectivoPersonal_AmigosFamiliares', 'ClaseSocial_BasadaOcupación',\r\n",
    "       'Índice_MasaCorporal']]\r\n",
    "\r\n",
    "y = ENS_2017_C2['Salud_percibida']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Clúster: 2')\r\n",
    "\r\n",
    "max_depth_min = 3\r\n",
    "max_depth_max = 5\r\n",
    "\r\n",
    "for max_depth in range (max_depth_min,max_depth_max +1):\r\n",
    "    \r\n",
    "    print ('max_depth:', max_depth)\r\n",
    "\r\n",
    "    print ('Train')\r\n",
    "\r\n",
    "    dtr = DecisionTreeRegressor(max_depth = max_depth)\r\n",
    "    dtr.fit(X_train, y_train)\r\n",
    "    score_train = dtr.score(X_train, y_train)\r\n",
    "    print ('Score_train:', score_train)\r\n",
    "    predictions_train = dtr.predict(X_train)\r\n",
    "    errores_train = abs(predictions_train - y_train)\r\n",
    "    np.mean(errores_train)\r\n",
    "    prop = 100 * (errores_train/y_train)\r\n",
    "    mape_train = np.mean(prop)\r\n",
    "    print ('MAPE_train:', mape_train)\r\n",
    "    \r\n",
    "    import_dict = {\r\n",
    "        'features': X_train.columns,\r\n",
    "        'importance_train': dtr.feature_importances_\r\n",
    "    }\r\n",
    "\r\n",
    "    Importance_variables_train = pd.DataFrame(import_dict).sort_values('importance_train', ascending=False)\r\n",
    "    print (Importance_variables_train)\r\n",
    "\r\n",
    "    print ('Test')\r\n",
    "\r\n",
    "    dtr = DecisionTreeRegressor(max_depth = max_depth)\r\n",
    "    dtr.fit(X_test, y_test)\r\n",
    "    score_test = dtr.score(X_test,y_test)\r\n",
    "    print ('Score_test:', score_test)\r\n",
    "    predictions_test = dtr.predict(X_test)\r\n",
    "    errores_test = abs(predictions_test - y_test)\r\n",
    "    np.mean(errores_test)\r\n",
    "    prop = 100 * (errores_test/y_test)\r\n",
    "    mape_test = np.mean(prop)\r\n",
    "    print ('MAPE_test:', mape_test)\r\n",
    "\r\n",
    "    import_dict = {\r\n",
    "        'features': X_test.columns,\r\n",
    "        'importance_test': dtr.feature_importances_\r\n",
    "    }\r\n",
    "\r\n",
    "    Importance_variables_test = pd.DataFrame(import_dict).sort_values('importance_test', ascending=False)\r\n",
    "    print (Importance_variables_test)\r\n",
    "\r\n",
    "    print ('Total')  \r\n",
    "    \r\n",
    "    dtr = DecisionTreeRegressor(max_depth = max_depth)\r\n",
    "    dtr.fit(X, y)\r\n",
    "    score_total = dtr.score(X,y)\r\n",
    "    print ('Score_total:', score_total)\r\n",
    "    predictions_total = dtr.predict(X)\r\n",
    "    errores_total = abs(predictions_total - y)\r\n",
    "    np.mean(errores_total)\r\n",
    "    prop = 100 * (errores_total/y)\r\n",
    "    mape_total = np.mean(prop)\r\n",
    "    print ('MAPE_total:', mape_total)\r\n",
    "\r\n",
    "    import_dict = {\r\n",
    "        'features': X.columns,\r\n",
    "        'importance_total': dtr.feature_importances_\r\n",
    "    }\r\n",
    "\r\n",
    "    Importance_variables_total = pd.DataFrame(import_dict).sort_values('importance_total', ascending=False)\r\n",
    "    print (Importance_variables_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENS_2017_C = pd.read_csv(\"../data/Bases_trabajo/ENS_2017_C.csv\", sep =',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ENS_2017_C[['CCAA', 'Sexo', 'Edad',\r\n",
    "       'Actividad_economica_actual', 'Nacionalidad_española', 'Convivencia',\r\n",
    "       'Estado_civil', 'Nivel_estudios', 'Vacunación_gripe',\r\n",
    "       'Toma_tensiónArterial_profesional', 'Medición_colesterol',\r\n",
    "       'Prueba_sangreHeces', 'Colonoscopia', 'Peso(Kg)',\r\n",
    "       'Freq_ActividadFísica', 'Freq_Consumo_FrutaFresca',\r\n",
    "       'Freq_Consumo_Carne', 'Freq_Consumo_Huevos', 'Freq_Consumo_Pescado',\r\n",
    "       'Freq_Consumo_PastaArrozPatatas', 'Freq_Consumo_PanCereales',\r\n",
    "       'Freq_Consumo_VerdurasEnsaladasHortalizas', 'Freq_Consumo_Legumbres',\r\n",
    "       'Freq_Consumo_EmbutidosFiambres', 'Freq_Consumo_Lácteos',\r\n",
    "       'Freq_Consumo_Dulces', 'Freq_Consumo_ComidaRápida',\r\n",
    "       'Freq_Consumo_ZumoNatural', 'Freq_Diaria_CepilladoDientes',\r\n",
    "       '¿Fuma actualmente', 'Freq_Consumo_Alcohol',\r\n",
    "       'ApoyoAfectivoPersonal_AmigosFamiliares', 'ClaseSocial_BasadaOcupación',\r\n",
    "       'Índice_MasaCorporal']]\r\n",
    "\r\n",
    "y = ENS_2017_C['Salud_percibida']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Base total')\r\n",
    "\r\n",
    "max_depth_min = 3\r\n",
    "max_depth_max = 5\r\n",
    "\r\n",
    "for max_depth in range (max_depth_min,max_depth_max +1):\r\n",
    "    \r\n",
    "    print ('max_depth:', max_depth)\r\n",
    "\r\n",
    "    print ('Train')\r\n",
    "\r\n",
    "    dtr = DecisionTreeRegressor(max_depth = max_depth)\r\n",
    "    dtr.fit(X_train, y_train)\r\n",
    "    score_train = dtr.score(X_train, y_train)\r\n",
    "    print ('Score_train:', score_train)\r\n",
    "    predictions_train = dtr.predict(X_train)\r\n",
    "    errores_train = abs(predictions_train - y_train)\r\n",
    "    np.mean(errores_train)\r\n",
    "    prop = 100 * (errores_train/y_train)\r\n",
    "    mape_train = np.mean(prop)\r\n",
    "    print ('MAPE_train:', mape_train)\r\n",
    "    \r\n",
    "    import_dict = {\r\n",
    "        'features': X_train.columns,\r\n",
    "        'importance_train': dtr.feature_importances_\r\n",
    "    }\r\n",
    "\r\n",
    "    Importance_variables_train = pd.DataFrame(import_dict).sort_values('importance_train', ascending=False)\r\n",
    "    print (Importance_variables_train)\r\n",
    "\r\n",
    "    print ('Test')\r\n",
    "\r\n",
    "    dtr = DecisionTreeRegressor(max_depth = max_depth)\r\n",
    "    dtr.fit(X_test, y_test)\r\n",
    "    score_test = dtr.score(X_test,y_test)\r\n",
    "    print ('Score_test:', score_test)\r\n",
    "    predictions_test = dtr.predict(X_test)\r\n",
    "    errores_test = abs(predictions_test - y_test)\r\n",
    "    np.mean(errores_test)\r\n",
    "    prop = 100 * (errores_test/y_test)\r\n",
    "    mape_test = np.mean(prop)\r\n",
    "    print ('MAPE_test:', mape_test)\r\n",
    "\r\n",
    "    import_dict = {\r\n",
    "        'features': X_test.columns,\r\n",
    "        'importance_test': dtr.feature_importances_\r\n",
    "    }\r\n",
    "\r\n",
    "    Importance_variables_test = pd.DataFrame(import_dict).sort_values('importance_test', ascending=False)\r\n",
    "    print (Importance_variables_test)\r\n",
    "\r\n",
    "    print ('Total')  \r\n",
    "    \r\n",
    "    dtr = DecisionTreeRegressor(max_depth = max_depth)\r\n",
    "    dtr.fit(X, y)\r\n",
    "    score_total = dtr.score(X,y)\r\n",
    "    print ('Score_total:', score_total)\r\n",
    "    predictions_total = dtr.predict(X)\r\n",
    "    errores_total = abs(predictions_total - y)\r\n",
    "    np.mean(errores_total)\r\n",
    "    prop = 100 * (errores_total/y)\r\n",
    "    mape_total = np.mean(prop)\r\n",
    "    print ('MAPE_total:', mape_total)\r\n",
    "\r\n",
    "    import_dict = {\r\n",
    "        'features': X.columns,\r\n",
    "        'importance_total': dtr.feature_importances_\r\n",
    "    }\r\n",
    "\r\n",
    "    Importance_variables_total = pd.DataFrame(import_dict).sort_values('importance_total', ascending=False)\r\n",
    "    print (Importance_variables_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENS_2017_C0= pd.read_csv('../data/Bases_trabajo/ENS_2017_C0.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ENS_2017_C0[['CCAA', 'Sexo', 'Edad',\r\n",
    "       'Actividad_economica_actual', 'Nacionalidad_española', 'Convivencia',\r\n",
    "       'Estado_civil', 'Nivel_estudios', 'Vacunación_gripe',\r\n",
    "       'Toma_tensiónArterial_profesional', 'Medición_colesterol',\r\n",
    "       'Prueba_sangreHeces', 'Colonoscopia', 'Peso(Kg)',\r\n",
    "       'Freq_ActividadFísica', 'Freq_Consumo_FrutaFresca',\r\n",
    "       'Freq_Consumo_Carne', 'Freq_Consumo_Huevos', 'Freq_Consumo_Pescado',\r\n",
    "       'Freq_Consumo_PastaArrozPatatas', 'Freq_Consumo_PanCereales',\r\n",
    "       'Freq_Consumo_VerdurasEnsaladasHortalizas', 'Freq_Consumo_Legumbres',\r\n",
    "       'Freq_Consumo_EmbutidosFiambres', 'Freq_Consumo_Lácteos',\r\n",
    "       'Freq_Consumo_Dulces', 'Freq_Consumo_ComidaRápida',\r\n",
    "       'Freq_Consumo_ZumoNatural', 'Freq_Diaria_CepilladoDientes',\r\n",
    "       '¿Fuma actualmente', 'Freq_Consumo_Alcohol',\r\n",
    "       'ApoyoAfectivoPersonal_AmigosFamiliares', 'ClaseSocial_BasadaOcupación',\r\n",
    "       'Índice_MasaCorporal']]\r\n",
    "\r\n",
    "y = ENS_2017_C0['Salud_percibida']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Cluster: 0')\r\n",
    "\r\n",
    "n_estimators_1 = [500, 1000, 2000]\r\n",
    "max_depth_1 = [3, 4, 5]\r\n",
    "\r\n",
    "for n_estimators in n_estimators_1:\r\n",
    "    for max_depth in max_depth_1:\r\n",
    "\r\n",
    "        print ('n_estimators:', n_estimators_1)\r\n",
    "        print ('max_depth', max_depth_1)\r\n",
    "        \r\n",
    "        model = RandomForestRegressor(n_estimators=n_estimators,\r\n",
    "                               max_depth = max_depth,\r\n",
    "                               random_state = 42)\r\n",
    "\r\n",
    "        model.fit(X_train, y_train)\r\n",
    "        score_train = model.score(X_train,y_train)\r\n",
    "        print ('Score_train:', score_train)\r\n",
    "        y_pred_reg = model.predict(X_train)\r\n",
    "        MSE_train = mean_squared_error(y_train, y_pred_reg)\r\n",
    "        print ('MSE_train:', MSE_train)\r\n",
    "\r\n",
    "        model.fit(X_test, y_test)\r\n",
    "        score_train = model.score(X_test,y_test)\r\n",
    "        print ('Score_test:', score_test)\r\n",
    "        y_pred_reg = model.predict(X_test)\r\n",
    "        MSE_test = mean_squared_error(y_test, y_pred_reg)\r\n",
    "        print ('MSE_test:', MSE_test)\r\n",
    "\r\n",
    "        model.fit(X, y)\r\n",
    "        score_total = model.score(X,y)\r\n",
    "        print ('Score_total:', score_total)\r\n",
    "        y_pred_reg = model.predict(X)\r\n",
    "        MSE_total = mean_squared_error(y, y_pred_reg)\r\n",
    "        print ('MSE_total:', MSE_total)\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENS_2017_C1= pd.read_csv('../data/Bases_trabajo/ENS_2017_C1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ENS_2017_C1[['CCAA', 'Sexo', 'Edad',\r\n",
    "       'Actividad_economica_actual', 'Nacionalidad_española', 'Convivencia',\r\n",
    "       'Estado_civil', 'Nivel_estudios', 'Vacunación_gripe',\r\n",
    "       'Toma_tensiónArterial_profesional', 'Medición_colesterol',\r\n",
    "       'Prueba_sangreHeces', 'Colonoscopia', 'Peso(Kg)',\r\n",
    "       'Freq_ActividadFísica', 'Freq_Consumo_FrutaFresca',\r\n",
    "       'Freq_Consumo_Carne', 'Freq_Consumo_Huevos', 'Freq_Consumo_Pescado',\r\n",
    "       'Freq_Consumo_PastaArrozPatatas', 'Freq_Consumo_PanCereales',\r\n",
    "       'Freq_Consumo_VerdurasEnsaladasHortalizas', 'Freq_Consumo_Legumbres',\r\n",
    "       'Freq_Consumo_EmbutidosFiambres', 'Freq_Consumo_Lácteos',\r\n",
    "       'Freq_Consumo_Dulces', 'Freq_Consumo_ComidaRápida',\r\n",
    "       'Freq_Consumo_ZumoNatural', 'Freq_Diaria_CepilladoDientes',\r\n",
    "       '¿Fuma actualmente', 'Freq_Consumo_Alcohol',\r\n",
    "       'ApoyoAfectivoPersonal_AmigosFamiliares', 'ClaseSocial_BasadaOcupación',\r\n",
    "       'Índice_MasaCorporal']]\r\n",
    "\r\n",
    "y = ENS_2017_C1['Salud_percibida']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Clúster: 1')\r\n",
    "\r\n",
    "n_estimators_1 = [500, 1000, 2000]\r\n",
    "max_depth_1 = [3, 4, 5]\r\n",
    "\r\n",
    "for n_estimators in n_estimators_1:\r\n",
    "    for max_depth in max_depth_1:\r\n",
    "\r\n",
    "        print ('n_estimators:', n_estimators)\r\n",
    "        print ('max_depth', max_depth)\r\n",
    "        \r\n",
    "        model = RandomForestRegressor(n_estimators=n_estimators,\r\n",
    "                               max_depth = max_depth,\r\n",
    "                               random_state = 42)\r\n",
    "\r\n",
    "        model.fit(X_train, y_train)\r\n",
    "        score_train = model.score(X_train,y_train)\r\n",
    "        print ('Score_train:', score_train)\r\n",
    "        y_pred_reg = model.predict(X_train)\r\n",
    "        MSE_train = mean_squared_error(y_train, y_pred_reg)\r\n",
    "        print ('MSE_train:', MSE_train)\r\n",
    "\r\n",
    "        model.fit(X_test, y_test)\r\n",
    "        score_train = model.score(X_test,y_test)\r\n",
    "        print ('Score_test:', score_test)\r\n",
    "        y_pred_reg = model.predict(X_test)\r\n",
    "        MSE_test = mean_squared_error(y_test, y_pred_reg)\r\n",
    "        print ('MSE_test:', MSE_test)\r\n",
    "\r\n",
    "        model.fit(X, y)\r\n",
    "        score_total = model.score(X,y)\r\n",
    "        print ('Score_total:', score_total)\r\n",
    "        y_pred_reg = model.predict(X)\r\n",
    "        MSE_total = mean_squared_error(y, y_pred_reg)\r\n",
    "        print ('MSE_total:', MSE_total)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENS_2017_C2= pd.read_csv('../data/Bases_trabajo/ENS_2017_C2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ENS_2017_C2[['CCAA', 'Sexo', 'Edad',\r\n",
    "       'Actividad_economica_actual', 'Nacionalidad_española', 'Convivencia',\r\n",
    "       'Estado_civil', 'Nivel_estudios', 'Vacunación_gripe',\r\n",
    "       'Toma_tensiónArterial_profesional', 'Medición_colesterol',\r\n",
    "       'Prueba_sangreHeces', 'Colonoscopia', 'Peso(Kg)',\r\n",
    "       'Freq_ActividadFísica', 'Freq_Consumo_FrutaFresca',\r\n",
    "       'Freq_Consumo_Carne', 'Freq_Consumo_Huevos', 'Freq_Consumo_Pescado',\r\n",
    "       'Freq_Consumo_PastaArrozPatatas', 'Freq_Consumo_PanCereales',\r\n",
    "       'Freq_Consumo_VerdurasEnsaladasHortalizas', 'Freq_Consumo_Legumbres',\r\n",
    "       'Freq_Consumo_EmbutidosFiambres', 'Freq_Consumo_Lácteos',\r\n",
    "       'Freq_Consumo_Dulces', 'Freq_Consumo_ComidaRápida',\r\n",
    "       'Freq_Consumo_ZumoNatural', 'Freq_Diaria_CepilladoDientes',\r\n",
    "       '¿Fuma actualmente', 'Freq_Consumo_Alcohol',\r\n",
    "       'ApoyoAfectivoPersonal_AmigosFamiliares', 'ClaseSocial_BasadaOcupación',\r\n",
    "       'Índice_MasaCorporal']]\r\n",
    "\r\n",
    "y = ENS_2017_C2['Salud_percibida']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Clúster: 2')\r\n",
    "\r\n",
    "n_estimators_1 = [500, 1000, 2000]\r\n",
    "max_depth_1 = [3, 4, 5]\r\n",
    "\r\n",
    "for n_estimators in n_estimators_1:\r\n",
    "    for max_depth in max_depth_1:\r\n",
    "\r\n",
    "        print ('n_estimators:', n_estimators)\r\n",
    "        print ('max_depth', max_depth)\r\n",
    "        \r\n",
    "        model = RandomForestRegressor(n_estimators=n_estimators,\r\n",
    "                               max_depth = max_depth,\r\n",
    "                               random_state = 42)\r\n",
    "\r\n",
    "        model.fit(X_train, y_train)\r\n",
    "        score_train = model.score(X_train,y_train)\r\n",
    "        print ('Score_train:', score_train)\r\n",
    "        y_pred_reg = model.predict(X_train)\r\n",
    "        MSE_train = mean_squared_error(y_train, y_pred_reg)\r\n",
    "        print ('MSE_train:', MSE_train)\r\n",
    "\r\n",
    "        model.fit(X_test, y_test)\r\n",
    "        score_train = model.score(X_test,y_test)\r\n",
    "        print ('Score_test:', score_test)\r\n",
    "        y_pred_reg = model.predict(X_test)\r\n",
    "        MSE_test = mean_squared_error(y_test, y_pred_reg)\r\n",
    "        print ('MSE_test:', MSE_test)\r\n",
    "\r\n",
    "        model.fit(X, y)\r\n",
    "        score_total = model.score(X,y)\r\n",
    "        print ('Score_total:', score_total)\r\n",
    "        y_pred_reg = model.predict(X)\r\n",
    "        MSE_total = mean_squared_error(y, y_pred_reg)\r\n",
    "        print ('MSE_total:', MSE_total)\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENS_2017_C= pd.read_csv('../data/Bases_trabajo/ENS_2017_C.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ENS_2017_C[['CCAA', 'Sexo', 'Edad',\r\n",
    "       'Actividad_economica_actual', 'Nacionalidad_española', 'Convivencia',\r\n",
    "       'Estado_civil', 'Nivel_estudios', 'Vacunación_gripe',\r\n",
    "       'Toma_tensiónArterial_profesional', 'Medición_colesterol',\r\n",
    "       'Prueba_sangreHeces', 'Colonoscopia', 'Peso(Kg)',\r\n",
    "       'Freq_ActividadFísica', 'Freq_Consumo_FrutaFresca',\r\n",
    "       'Freq_Consumo_Carne', 'Freq_Consumo_Huevos', 'Freq_Consumo_Pescado',\r\n",
    "       'Freq_Consumo_PastaArrozPatatas', 'Freq_Consumo_PanCereales',\r\n",
    "       'Freq_Consumo_VerdurasEnsaladasHortalizas', 'Freq_Consumo_Legumbres',\r\n",
    "       'Freq_Consumo_EmbutidosFiambres', 'Freq_Consumo_Lácteos',\r\n",
    "       'Freq_Consumo_Dulces', 'Freq_Consumo_ComidaRápida',\r\n",
    "       'Freq_Consumo_ZumoNatural', 'Freq_Diaria_CepilladoDientes',\r\n",
    "       '¿Fuma actualmente', 'Freq_Consumo_Alcohol',\r\n",
    "       'ApoyoAfectivoPersonal_AmigosFamiliares', 'ClaseSocial_BasadaOcupación',\r\n",
    "       'Índice_MasaCorporal']]\r\n",
    "\r\n",
    "y = ENS_2017_C['Salud_percibida']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Base total')\r\n",
    "\r\n",
    "n_estimators_1 = [500, 1000, 2000]\r\n",
    "max_depth_1 = [3, 4, 5]\r\n",
    "\r\n",
    "for n_estimators in n_estimators_1:\r\n",
    "    for max_depth in max_depth_1:\r\n",
    "\r\n",
    "        print ('n_estimators:', n_estimators)\r\n",
    "        print ('max_depth', max_depth)\r\n",
    "        \r\n",
    "        model = RandomForestRegressor(n_estimators=n_estimators,\r\n",
    "                               max_depth = max_depth,\r\n",
    "                               random_state = 42)\r\n",
    "\r\n",
    "        model.fit(X_train, y_train)\r\n",
    "        score_train = model.score(X_train,y_train)\r\n",
    "        print ('Score_train:', score_train)\r\n",
    "        y_pred_reg = model.predict(X_train)\r\n",
    "        MSE_train = mean_squared_error(y_train, y_pred_reg)\r\n",
    "        print ('MSE_train:', MSE_train)\r\n",
    "\r\n",
    "        model.fit(X_test, y_test)\r\n",
    "        score_train = model.score(X_test,y_test)\r\n",
    "        print ('Score_test:', score_test)\r\n",
    "        y_pred_reg = model.predict(X_test)\r\n",
    "        MSE_test = mean_squared_error(y_test, y_pred_reg)\r\n",
    "        print ('MSE_test:', MSE_test)\r\n",
    "\r\n",
    "        model.fit(X, y)\r\n",
    "        score_total = model.score(X,y)\r\n",
    "        print ('Score_total:', score_total)\r\n",
    "        y_pred_reg = model.predict(X)\r\n",
    "        MSE_total = mean_squared_error(y, y_pred_reg)\r\n",
    "        print ('MSE_total:', MSE_total)\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decission Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENS_2017_C0_agr = pd.read_csv(\"../data/Bases_trabajo/ENS_2017_C0_agr.csv\", sep =',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ENS_2017_C0_agr[['CCAA', 'Sexo', \r\n",
    "       'Actividad_economica_actual', 'Nacionalidad_española', 'Convivencia',\r\n",
    "       'Estado_civil', 'Nivel_estudios', 'Vacunación_gripe',\r\n",
    "       'Toma_tensiónArterial_profesional', 'Medición_colesterol',\r\n",
    "       'Prueba_sangreHeces', 'Colonoscopia', \r\n",
    "       'Freq_ActividadFísica', 'Freq_Consumo_FrutaFresca',\r\n",
    "       'Freq_Consumo_Carne', 'Freq_Consumo_Huevos', 'Freq_Consumo_Pescado',\r\n",
    "       'Freq_Consumo_PastaArrozPatatas', 'Freq_Consumo_PanCereales',\r\n",
    "       'Freq_Consumo_VerdurasEnsaladasHortalizas', 'Freq_Consumo_Legumbres',\r\n",
    "       'Freq_Consumo_EmbutidosFiambres', 'Freq_Consumo_Lácteos',\r\n",
    "       'Freq_Consumo_Dulces', 'Freq_Consumo_ComidaRápida',\r\n",
    "       'Freq_Consumo_ZumoNatural', 'Freq_Diaria_CepilladoDientes',\r\n",
    "       '¿Fuma actualmente', 'Freq_Consumo_Alcohol',\r\n",
    "       'ApoyoAfectivoPersonal_AmigosFamiliares', 'ClaseSocial_BasadaOcupación',\r\n",
    "       'Índice_MasaCorporal','Edad_ag','Peso_ag']]\r\n",
    "\r\n",
    "y = ENS_2017_C0_agr['Salud_percibida']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Cluster: 0')\r\n",
    "\r\n",
    "tree_clf = DecisionTreeClassifier(random_state=42)\r\n",
    "tree_clf.fit(X_train, y_train)\r\n",
    "score_train = tree_clf.score(X_train, y_train)\r\n",
    "print ('Score_train:', score_train)\r\n",
    "y_pred_tree = tree_clf.predict(X_train)\r\n",
    "print(\"Accuracy_train:\", metrics.accuracy_score(y_train, y_pred_tree))\r\n",
    "\r\n",
    "tree_clf = DecisionTreeClassifier(random_state=42)\r\n",
    "tree_clf.fit(X_test, y_test)\r\n",
    "score_test = tree_clf.score(X_test, y_test)\r\n",
    "print ('Score_test:', score_test)\r\n",
    "y_pred_tree = tree_clf.predict(X_test)\r\n",
    "print(\"Accuracy_test:\", metrics.accuracy_score(y_test, y_pred_tree))\r\n",
    "\r\n",
    "tree_clf = DecisionTreeClassifier(random_state=42)\r\n",
    "tree_clf.fit(X, y)\r\n",
    "score_total = tree_clf.score(X, y)\r\n",
    "print ('Score_total:', score_total)\r\n",
    "y_pred_tree = tree_clf.predict(X)\r\n",
    "print(\"Accuracy_total:\", metrics.accuracy_score(y, y_pred_tree))\r\n",
    "\r\n",
    "import_dict = {\r\n",
    "    'features': X_train.columns,\r\n",
    "    'importance': dtr.feature_importances_\r\n",
    "}\r\n",
    "\r\n",
    "pd.DataFrame(import_dict).sort_values('importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENS_2017_C1_agr = pd.read_csv(\"../data/Bases_trabajo/ENS_2017_C1_agr.csv\", sep =',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ENS_2017_C1_agr[['CCAA', 'Sexo', \r\n",
    "       'Actividad_economica_actual', 'Nacionalidad_española', 'Convivencia',\r\n",
    "       'Estado_civil', 'Nivel_estudios', 'Vacunación_gripe',\r\n",
    "       'Toma_tensiónArterial_profesional', 'Medición_colesterol',\r\n",
    "       'Prueba_sangreHeces', 'Colonoscopia', \r\n",
    "       'Freq_ActividadFísica', 'Freq_Consumo_FrutaFresca',\r\n",
    "       'Freq_Consumo_Carne', 'Freq_Consumo_Huevos', 'Freq_Consumo_Pescado',\r\n",
    "       'Freq_Consumo_PastaArrozPatatas', 'Freq_Consumo_PanCereales',\r\n",
    "       'Freq_Consumo_VerdurasEnsaladasHortalizas', 'Freq_Consumo_Legumbres',\r\n",
    "       'Freq_Consumo_EmbutidosFiambres', 'Freq_Consumo_Lácteos',\r\n",
    "       'Freq_Consumo_Dulces', 'Freq_Consumo_ComidaRápida',\r\n",
    "       'Freq_Consumo_ZumoNatural', 'Freq_Diaria_CepilladoDientes',\r\n",
    "       '¿Fuma actualmente', 'Freq_Consumo_Alcohol',\r\n",
    "       'ApoyoAfectivoPersonal_AmigosFamiliares', 'ClaseSocial_BasadaOcupación',\r\n",
    "       'Índice_MasaCorporal','Edad_ag','Peso_ag']]\r\n",
    "\r\n",
    "y = ENS_2017_C1_agr['Salud_percibida']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Cluster: 1')\r\n",
    "\r\n",
    "tree_clf = DecisionTreeClassifier(random_state=42)\r\n",
    "tree_clf.fit(X_train, y_train)\r\n",
    "score_train = tree_clf.score(X_train, y_train)\r\n",
    "print ('Score_train:', score_train)\r\n",
    "y_pred_tree = tree_clf.predict(X_train)\r\n",
    "print(\"Accuracy_train:\", metrics.accuracy_score(y_train, y_pred_tree))\r\n",
    "\r\n",
    "tree_clf = DecisionTreeClassifier(random_state=42)\r\n",
    "tree_clf.fit(X_test, y_test)\r\n",
    "score_test = tree_clf.score(X_test, y_test)\r\n",
    "print ('Score_test:', score_test)\r\n",
    "y_pred_tree = tree_clf.predict(X_test)\r\n",
    "print(\"Accuracy_test:\", metrics.accuracy_score(y_test, y_pred_tree))\r\n",
    "\r\n",
    "tree_clf = DecisionTreeClassifier(random_state=42)\r\n",
    "tree_clf.fit(X, y)\r\n",
    "score_total = tree_clf.score(X, y)\r\n",
    "print ('Score_total:', score_total)\r\n",
    "y_pred_tree = tree_clf.predict(X)\r\n",
    "print(\"Accuracy_total:\", metrics.accuracy_score(y, y_pred_tree))\r\n",
    "\r\n",
    "import_dict = {\r\n",
    "    'features': X_train.columns,\r\n",
    "    'importance': dtr.feature_importances_\r\n",
    "}\r\n",
    "\r\n",
    "pd.DataFrame(import_dict).sort_values('importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENS_2017_C2_agr = pd.read_csv(\"../data/Bases_trabajo/ENS_2017_C2_agr.csv\", sep =',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ENS_2017_C2_agr[['CCAA', 'Sexo', \r\n",
    "       'Actividad_economica_actual', 'Nacionalidad_española', 'Convivencia',\r\n",
    "       'Estado_civil', 'Nivel_estudios', 'Vacunación_gripe',\r\n",
    "       'Toma_tensiónArterial_profesional', 'Medición_colesterol',\r\n",
    "       'Prueba_sangreHeces', 'Colonoscopia', \r\n",
    "       'Freq_ActividadFísica', 'Freq_Consumo_FrutaFresca',\r\n",
    "       'Freq_Consumo_Carne', 'Freq_Consumo_Huevos', 'Freq_Consumo_Pescado',\r\n",
    "       'Freq_Consumo_PastaArrozPatatas', 'Freq_Consumo_PanCereales',\r\n",
    "       'Freq_Consumo_VerdurasEnsaladasHortalizas', 'Freq_Consumo_Legumbres',\r\n",
    "       'Freq_Consumo_EmbutidosFiambres', 'Freq_Consumo_Lácteos',\r\n",
    "       'Freq_Consumo_Dulces', 'Freq_Consumo_ComidaRápida',\r\n",
    "       'Freq_Consumo_ZumoNatural', 'Freq_Diaria_CepilladoDientes',\r\n",
    "       '¿Fuma actualmente', 'Freq_Consumo_Alcohol',\r\n",
    "       'ApoyoAfectivoPersonal_AmigosFamiliares', 'ClaseSocial_BasadaOcupación',\r\n",
    "       'Índice_MasaCorporal','Edad_ag','Peso_ag']]\r\n",
    "\r\n",
    "y = ENS_2017_C2_agr['Salud_percibida']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Cluster: 2')\r\n",
    "\r\n",
    "tree_clf = DecisionTreeClassifier(random_state=42)\r\n",
    "tree_clf.fit(X_train, y_train)\r\n",
    "score_train = tree_clf.score(X_train, y_train)\r\n",
    "print ('Score_train:', score_train)\r\n",
    "y_pred_tree = tree_clf.predict(X_train)\r\n",
    "print(\"Accuracy_train:\", metrics.accuracy_score(y_train, y_pred_tree))\r\n",
    "\r\n",
    "tree_clf = DecisionTreeClassifier(random_state=42)\r\n",
    "tree_clf.fit(X_test, y_test)\r\n",
    "score_test = tree_clf.score(X_test, y_test)\r\n",
    "print ('Score_test:', score_test)\r\n",
    "y_pred_tree = tree_clf.predict(X_test)\r\n",
    "print(\"Accuracy_test:\", metrics.accuracy_score(y_test, y_pred_tree))\r\n",
    "\r\n",
    "tree_clf = DecisionTreeClassifier(random_state=42)\r\n",
    "tree_clf.fit(X, y)\r\n",
    "score_total = tree_clf.score(X, y)\r\n",
    "print ('Score_total:', score_total)\r\n",
    "y_pred_tree = tree_clf.predict(X)\r\n",
    "print(\"Accuracy_total:\", metrics.accuracy_score(y, y_pred_tree))\r\n",
    "\r\n",
    "import_dict = {\r\n",
    "    'features': X_train.columns,\r\n",
    "    'importance': dtr.feature_importances_\r\n",
    "}\r\n",
    "\r\n",
    "pd.DataFrame(import_dict).sort_values('importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENS_2017_C_agr = pd.read_csv(\"../data/Bases_trabajo/ENS_2017_C_agr.csv\", sep =',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ENS_2017_C_agr[['CCAA', 'Sexo', \r\n",
    "       'Actividad_economica_actual', 'Nacionalidad_española', 'Convivencia',\r\n",
    "       'Estado_civil', 'Nivel_estudios', 'Vacunación_gripe',\r\n",
    "       'Toma_tensiónArterial_profesional', 'Medición_colesterol',\r\n",
    "       'Prueba_sangreHeces', 'Colonoscopia', \r\n",
    "       'Freq_ActividadFísica', 'Freq_Consumo_FrutaFresca',\r\n",
    "       'Freq_Consumo_Carne', 'Freq_Consumo_Huevos', 'Freq_Consumo_Pescado',\r\n",
    "       'Freq_Consumo_PastaArrozPatatas', 'Freq_Consumo_PanCereales',\r\n",
    "       'Freq_Consumo_VerdurasEnsaladasHortalizas', 'Freq_Consumo_Legumbres',\r\n",
    "       'Freq_Consumo_EmbutidosFiambres', 'Freq_Consumo_Lácteos',\r\n",
    "       'Freq_Consumo_Dulces', 'Freq_Consumo_ComidaRápida',\r\n",
    "       'Freq_Consumo_ZumoNatural', 'Freq_Diaria_CepilladoDientes',\r\n",
    "       '¿Fuma actualmente', 'Freq_Consumo_Alcohol',\r\n",
    "       'ApoyoAfectivoPersonal_AmigosFamiliares', 'ClaseSocial_BasadaOcupación',\r\n",
    "       'Índice_MasaCorporal','Edad_ag','Peso_ag']]\r\n",
    "\r\n",
    "y = ENS_2017_C_agr['Salud_percibida']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Base total')\r\n",
    "\r\n",
    "tree_clf = DecisionTreeClassifier(random_state=42)\r\n",
    "tree_clf.fit(X_train, y_train)\r\n",
    "score_train = tree_clf.score(X_train, y_train)\r\n",
    "print ('Score_train:', score_train)\r\n",
    "y_pred_tree = tree_clf.predict(X_train)\r\n",
    "print(\"Accuracy_train:\", metrics.accuracy_score(y_train, y_pred_tree))\r\n",
    "\r\n",
    "tree_clf = DecisionTreeClassifier(random_state=42)\r\n",
    "tree_clf.fit(X_test, y_test)\r\n",
    "score_test = tree_clf.score(X_test, y_test)\r\n",
    "print ('Score_test:', score_test)\r\n",
    "y_pred_tree = tree_clf.predict(X_test)\r\n",
    "print(\"Accuracy_test:\", metrics.accuracy_score(y_test, y_pred_tree))\r\n",
    "\r\n",
    "tree_clf = DecisionTreeClassifier(random_state=42)\r\n",
    "tree_clf.fit(X, y)\r\n",
    "score_total = tree_clf.score(X, y)\r\n",
    "print ('Score_total:', score_total)\r\n",
    "y_pred_tree = tree_clf.predict(X)\r\n",
    "print(\"Accuracy_total:\", metrics.accuracy_score(y, y_pred_tree))\r\n",
    "\r\n",
    "\r\n",
    "import_dict = {\r\n",
    "    'features': X_train.columns,\r\n",
    "    'importance': dtr.feature_importances_\r\n",
    "}\r\n",
    "\r\n",
    "pd.DataFrame(import_dict).sort_values('importance', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENS_2017_C0_agr = pd.read_csv(\"../data/Bases_trabajo/ENS_2017_C0_agr.csv\", sep =',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ENS_2017_C0_agr[['CCAA', 'Sexo', \r\n",
    "       'Actividad_economica_actual', 'Nacionalidad_española', 'Convivencia',\r\n",
    "       'Estado_civil', 'Nivel_estudios', 'Vacunación_gripe',\r\n",
    "       'Toma_tensiónArterial_profesional', 'Medición_colesterol',\r\n",
    "       'Prueba_sangreHeces', 'Colonoscopia', \r\n",
    "       'Freq_ActividadFísica', 'Freq_Consumo_FrutaFresca',\r\n",
    "       'Freq_Consumo_Carne', 'Freq_Consumo_Huevos', 'Freq_Consumo_Pescado',\r\n",
    "       'Freq_Consumo_PastaArrozPatatas', 'Freq_Consumo_PanCereales',\r\n",
    "       'Freq_Consumo_VerdurasEnsaladasHortalizas', 'Freq_Consumo_Legumbres',\r\n",
    "       'Freq_Consumo_EmbutidosFiambres', 'Freq_Consumo_Lácteos',\r\n",
    "       'Freq_Consumo_Dulces', 'Freq_Consumo_ComidaRápida',\r\n",
    "       'Freq_Consumo_ZumoNatural', 'Freq_Diaria_CepilladoDientes',\r\n",
    "       '¿Fuma actualmente', 'Freq_Consumo_Alcohol',\r\n",
    "       'ApoyoAfectivoPersonal_AmigosFamiliares', 'ClaseSocial_BasadaOcupación',\r\n",
    "       'Índice_MasaCorporal','Edad_ag','Peso_ag']]\r\n",
    "\r\n",
    "y = ENS_2017_C0_agr['Salud_percibida']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Clúster: 0')\r\n",
    "\r\n",
    "n_estimators_1 = [500, 1000, 2000]\r\n",
    "max_depth_1 = [3, 4, 5]\r\n",
    "\r\n",
    "for n_estimators in n_estimators_1:\r\n",
    "    for max_depth in max_depth_1:\r\n",
    "\r\n",
    "        print ('n_estimators:', n_estimators)\r\n",
    "        print ('max_depth', max_depth)\r\n",
    "        \r\n",
    "        model = RandomForestClassifier(n_estimators=n_estimators,\r\n",
    "                               max_depth = max_depth,\r\n",
    "                               random_state = 42)\r\n",
    "\r\n",
    "        model.fit(X_train, y_train)\r\n",
    "        score_train = model.score(X_train,y_train)\r\n",
    "        print ('Score_train:', score_train)\r\n",
    "        y_pred_train = model.predict(X_train)\r\n",
    "        print ('Accuracy_train:', metrics.accuracy_score(y_train, y_pred_train))\r\n",
    "\r\n",
    "        model.fit(X_test, y_test)\r\n",
    "        score_test = model.score(X_test,y_test)\r\n",
    "        print ('Score_test:', score_test)\r\n",
    "        y_pred_test = model.predict(X_test)\r\n",
    "        print ('Accuracy_test:', metrics.accuracy_score(y_test, y_pred_test))\r\n",
    "\r\n",
    "\r\n",
    "        model.fit(X, y)\r\n",
    "        score_total = model.score(X,y)\r\n",
    "        print ('Score_total:', score_total)\r\n",
    "        y_pred_total = model.predict(X)\r\n",
    "        print ('Accuracy_test:', metrics.accuracy_score(y_test, y_pred_test))\r\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENS_2017_C1_agr = pd.read_csv(\"../data/Bases_trabajo/ENS_2017_C1_agr.csv\", sep =',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ENS_2017_C1_agr[['CCAA', 'Sexo', \r\n",
    "       'Actividad_economica_actual', 'Nacionalidad_española', 'Convivencia',\r\n",
    "       'Estado_civil', 'Nivel_estudios', 'Vacunación_gripe',\r\n",
    "       'Toma_tensiónArterial_profesional', 'Medición_colesterol',\r\n",
    "       'Prueba_sangreHeces', 'Colonoscopia', \r\n",
    "       'Freq_ActividadFísica', 'Freq_Consumo_FrutaFresca',\r\n",
    "       'Freq_Consumo_Carne', 'Freq_Consumo_Huevos', 'Freq_Consumo_Pescado',\r\n",
    "       'Freq_Consumo_PastaArrozPatatas', 'Freq_Consumo_PanCereales',\r\n",
    "       'Freq_Consumo_VerdurasEnsaladasHortalizas', 'Freq_Consumo_Legumbres',\r\n",
    "       'Freq_Consumo_EmbutidosFiambres', 'Freq_Consumo_Lácteos',\r\n",
    "       'Freq_Consumo_Dulces', 'Freq_Consumo_ComidaRápida',\r\n",
    "       'Freq_Consumo_ZumoNatural', 'Freq_Diaria_CepilladoDientes',\r\n",
    "       '¿Fuma actualmente', 'Freq_Consumo_Alcohol',\r\n",
    "       'ApoyoAfectivoPersonal_AmigosFamiliares', 'ClaseSocial_BasadaOcupación',\r\n",
    "       'Índice_MasaCorporal','Edad_ag','Peso_ag']]\r\n",
    "\r\n",
    "y = ENS_2017_C1_agr['Salud_percibida']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Clúster: 1')\r\n",
    "\r\n",
    "n_estimators_1 = [500, 1000, 2000]\r\n",
    "max_depth_1 = [3, 4, 5]\r\n",
    "\r\n",
    "for n_estimators in n_estimators_1:\r\n",
    "    for max_depth in max_depth_1:\r\n",
    "\r\n",
    "        print ('n_estimators:', n_estimators)\r\n",
    "        print ('max_depth', max_depth)\r\n",
    "        \r\n",
    "        model = RandomForestClassifier(n_estimators=n_estimators,\r\n",
    "                               max_depth = max_depth,\r\n",
    "                               random_state = 42)\r\n",
    "\r\n",
    "        model.fit(X_train, y_train)\r\n",
    "        score_train = model.score(X_train,y_train)\r\n",
    "        print ('Score_train:', score_train)\r\n",
    "        y_pred_train = model.predict(X_train)\r\n",
    "        print ('Accuracy_train:', metrics.accuracy_score(y_train, y_pred_train))\r\n",
    "\r\n",
    "        model.fit(X_test, y_test)\r\n",
    "        score_test = model.score(X_test,y_test)\r\n",
    "        print ('Score_test:', score_test)\r\n",
    "        y_pred_test = model.predict(X_test)\r\n",
    "        print ('Accuracy_test:', metrics.accuracy_score(y_test, y_pred_test))\r\n",
    "\r\n",
    "\r\n",
    "        model.fit(X, y)\r\n",
    "        score_total = model.score(X,y)\r\n",
    "        print ('Score_total:', score_total)\r\n",
    "        y_pred_total = model.predict(X)\r\n",
    "        print ('Accuracy_test:', metrics.accuracy_score(y_test, y_pred_test))\r\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENS_2017_C2_agr = pd.read_csv(\"../data/Bases_trabajo/ENS_2017_C2_agr.csv\", sep =',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ENS_2017_C2_agr[['CCAA', 'Sexo', \r\n",
    "       'Actividad_economica_actual', 'Nacionalidad_española', 'Convivencia',\r\n",
    "       'Estado_civil', 'Nivel_estudios', 'Vacunación_gripe',\r\n",
    "       'Toma_tensiónArterial_profesional', 'Medición_colesterol',\r\n",
    "       'Prueba_sangreHeces', 'Colonoscopia', \r\n",
    "       'Freq_ActividadFísica', 'Freq_Consumo_FrutaFresca',\r\n",
    "       'Freq_Consumo_Carne', 'Freq_Consumo_Huevos', 'Freq_Consumo_Pescado',\r\n",
    "       'Freq_Consumo_PastaArrozPatatas', 'Freq_Consumo_PanCereales',\r\n",
    "       'Freq_Consumo_VerdurasEnsaladasHortalizas', 'Freq_Consumo_Legumbres',\r\n",
    "       'Freq_Consumo_EmbutidosFiambres', 'Freq_Consumo_Lácteos',\r\n",
    "       'Freq_Consumo_Dulces', 'Freq_Consumo_ComidaRápida',\r\n",
    "       'Freq_Consumo_ZumoNatural', 'Freq_Diaria_CepilladoDientes',\r\n",
    "       '¿Fuma actualmente', 'Freq_Consumo_Alcohol',\r\n",
    "       'ApoyoAfectivoPersonal_AmigosFamiliares', 'ClaseSocial_BasadaOcupación',\r\n",
    "       'Índice_MasaCorporal','Edad_ag','Peso_ag']]\r\n",
    "\r\n",
    "y = ENS_2017_C2_agr['Salud_percibida']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Clúster: 2')\r\n",
    "\r\n",
    "n_estimators_1 = [500, 1000, 2000]\r\n",
    "max_depth_1 = [3, 4, 5]\r\n",
    "\r\n",
    "for n_estimators in n_estimators_1:\r\n",
    "    for max_depth in max_depth_1:\r\n",
    "\r\n",
    "        print ('n_estimators:', n_estimators)\r\n",
    "        print ('max_depth', max_depth)\r\n",
    "        \r\n",
    "        model = RandomForestClassifier(n_estimators=n_estimators,\r\n",
    "                               max_depth = max_depth,\r\n",
    "                               random_state = 42)\r\n",
    "\r\n",
    "        model.fit(X_train, y_train)\r\n",
    "        score_train = model.score(X_train,y_train)\r\n",
    "        print ('Score_train:', score_train)\r\n",
    "        y_pred_train = model.predict(X_train)\r\n",
    "        print ('Accuracy_train:', metrics.accuracy_score(y_train, y_pred_train))\r\n",
    "\r\n",
    "        model.fit(X_test, y_test)\r\n",
    "        score_test = model.score(X_test,y_test)\r\n",
    "        print ('Score_test:', score_test)\r\n",
    "        y_pred_test = model.predict(X_test)\r\n",
    "        print ('Accuracy_test:', metrics.accuracy_score(y_test, y_pred_test))\r\n",
    "\r\n",
    "\r\n",
    "        model.fit(X, y)\r\n",
    "        score_total = model.score(X,y)\r\n",
    "        print ('Score_total:', score_total)\r\n",
    "        y_pred_total = model.predict(X)\r\n",
    "        print ('Accuracy_test:', metrics.accuracy_score(y_test, y_pred_test))\r\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENS_2017_C_agr = pd.read_csv(\"../data/Bases_trabajo/ENS_2017_C_agr.csv\", sep =',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ENS_2017_C_agr[['CCAA', 'Sexo', \r\n",
    "       'Actividad_economica_actual', 'Nacionalidad_española', 'Convivencia',\r\n",
    "       'Estado_civil', 'Nivel_estudios', 'Vacunación_gripe',\r\n",
    "       'Toma_tensiónArterial_profesional', 'Medición_colesterol',\r\n",
    "       'Prueba_sangreHeces', 'Colonoscopia', \r\n",
    "       'Freq_ActividadFísica', 'Freq_Consumo_FrutaFresca',\r\n",
    "       'Freq_Consumo_Carne', 'Freq_Consumo_Huevos', 'Freq_Consumo_Pescado',\r\n",
    "       'Freq_Consumo_PastaArrozPatatas', 'Freq_Consumo_PanCereales',\r\n",
    "       'Freq_Consumo_VerdurasEnsaladasHortalizas', 'Freq_Consumo_Legumbres',\r\n",
    "       'Freq_Consumo_EmbutidosFiambres', 'Freq_Consumo_Lácteos',\r\n",
    "       'Freq_Consumo_Dulces', 'Freq_Consumo_ComidaRápida',\r\n",
    "       'Freq_Consumo_ZumoNatural', 'Freq_Diaria_CepilladoDientes',\r\n",
    "       '¿Fuma actualmente', 'Freq_Consumo_Alcohol',\r\n",
    "       'ApoyoAfectivoPersonal_AmigosFamiliares', 'ClaseSocial_BasadaOcupación',\r\n",
    "       'Índice_MasaCorporal','Edad_ag','Peso_ag']]\r\n",
    "\r\n",
    "y = ENS_2017_C_agr['Salud_percibida']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Base total')\r\n",
    "\r\n",
    "n_estimators_1 = [500, 1000, 2000]\r\n",
    "max_depth_1 = [3, 4, 5]\r\n",
    "\r\n",
    "for n_estimators in n_estimators_1:\r\n",
    "    for max_depth in max_depth_1:\r\n",
    "\r\n",
    "        print ('n_estimators:', n_estimators)\r\n",
    "        print ('max_depth', max_depth)\r\n",
    "        \r\n",
    "        model = RandomForestClassifier(n_estimators=n_estimators,\r\n",
    "                               max_depth = max_depth,\r\n",
    "                               random_state = 42)\r\n",
    "\r\n",
    "        model.fit(X_train, y_train)\r\n",
    "        score_train = model.score(X_train,y_train)\r\n",
    "        print ('Score_train:', score_train)\r\n",
    "        y_pred_train = model.predict(X_train)\r\n",
    "        print ('Accuracy_train:', metrics.accuracy_score(y_train, y_pred_train))\r\n",
    "\r\n",
    "        model.fit(X_test, y_test)\r\n",
    "        score_test = model.score(X_test,y_test)\r\n",
    "        print ('Score_test:', score_test)\r\n",
    "        y_pred_test = model.predict(X_test)\r\n",
    "        print ('Accuracy_test:', metrics.accuracy_score(y_test, y_pred_test))\r\n",
    "\r\n",
    "\r\n",
    "        model.fit(X, y)\r\n",
    "        score_total = model.score(X,y)\r\n",
    "        print ('Score_total:', score_total)\r\n",
    "        y_pred_total = model.predict(X)\r\n",
    "        print ('Accuracy_test:', metrics.accuracy_score(y_test, y_pred_test))\r\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusión Modelos Tree y Random Forest \r\n",
    "## El mejor modelo de es el de Decission Tree Classifier: \r\n",
    "## score_test: 1.000000\r\n",
    "## Accuracy_test: 1.00000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Red neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\r\n",
    "from tensorflow import keras\r\n",
    "from tensorflow.keras import datasets, layers, models\r\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENS_2017_C0 = pd.read_csv(\"../data/Bases_trabajo/ENS_2017_C0.csv\", sep =',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ENS_2017_C0[['CCAA', 'Sexo', 'Edad',\r\n",
    "       'Actividad_economica_actual', 'Nacionalidad_española', 'Convivencia',\r\n",
    "       'Estado_civil', 'Nivel_estudios', 'Vacunación_gripe',\r\n",
    "       'Toma_tensiónArterial_profesional', 'Medición_colesterol',\r\n",
    "       'Prueba_sangreHeces', 'Colonoscopia', 'Peso(Kg)',\r\n",
    "       'Freq_ActividadFísica', 'Freq_Consumo_FrutaFresca',\r\n",
    "       'Freq_Consumo_Carne', 'Freq_Consumo_Huevos', 'Freq_Consumo_Pescado',\r\n",
    "       'Freq_Consumo_PastaArrozPatatas', 'Freq_Consumo_PanCereales',\r\n",
    "       'Freq_Consumo_VerdurasEnsaladasHortalizas', 'Freq_Consumo_Legumbres',\r\n",
    "       'Freq_Consumo_EmbutidosFiambres', 'Freq_Consumo_Lácteos',\r\n",
    "       'Freq_Consumo_Dulces', 'Freq_Consumo_ComidaRápida',\r\n",
    "       'Freq_Consumo_ZumoNatural', 'Freq_Diaria_CepilladoDientes',\r\n",
    "       '¿Fuma actualmente', 'Freq_Consumo_Alcohol',\r\n",
    "       'ApoyoAfectivoPersonal_AmigosFamiliares', 'ClaseSocial_BasadaOcupación',\r\n",
    "       'Índice_MasaCorporal']]\r\n",
    "\r\n",
    "y = ENS_2017_C0['Salud_percibida']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\r\n",
    "\r\n",
    "scaler_train = StandardScaler().fit(X_train)\r\n",
    "X_train = scaler_train.transform(X_train)\r\n",
    "\r\n",
    "scaler_test = StandardScaler().fit(X_train)\r\n",
    "X_test = scaler_test.transform(X_test)\r\n",
    "\r\n",
    "scaler_total = StandardScaler().fit(X)\r\n",
    "X = scaler_total.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Cluster: 0')\r\n",
    "\r\n",
    "model = models.Sequential()\r\n",
    "model.add(layers.Dense(32, activation='relu', input_shape = (34,)))\r\n",
    "model.add(layers.Dense(10, activation='relu'))\r\n",
    "model.add(layers.Dense(4,activation='softmax'))\r\n",
    "\r\n",
    "model.compile(optimizer='adam',\r\n",
    "              loss='sparse_categorical_crossentropy', \r\n",
    "              metrics=['accuracy']) \r\n",
    "\r\n",
    "model.fit(X_train, y_train, epochs=100)\r\n",
    "\r\n",
    "test_loss, test_acc = model.evaluate(X_train,  y_train, verbose=2)\r\n",
    "print('\\nTrain accuracy:', test_acc)\r\n",
    "\r\n",
    "model.fit(X_test, y_test, epochs=100)\r\n",
    "test_loss, test_acc = model.evaluate(X_test,  y_test, verbose=2)\r\n",
    "\r\n",
    "print('\\nTest accuracy:', test_acc)\r\n",
    "\r\n",
    "model.fit(X, y, epochs=100)\r\n",
    "test_loss, test_acc = model.evaluate(X,  y, verbose=2)\r\n",
    "\r\n",
    "print('\\nTotal accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENS_2017_C1 = pd.read_csv(\"../data/Bases_trabajo/ENS_2017_C1.csv\", sep =',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ENS_2017_C1[['CCAA', 'Sexo', 'Edad',\r\n",
    "       'Actividad_economica_actual', 'Nacionalidad_española', 'Convivencia',\r\n",
    "       'Estado_civil', 'Nivel_estudios', 'Vacunación_gripe',\r\n",
    "       'Toma_tensiónArterial_profesional', 'Medición_colesterol',\r\n",
    "       'Prueba_sangreHeces', 'Colonoscopia', 'Peso(Kg)',\r\n",
    "       'Freq_ActividadFísica', 'Freq_Consumo_FrutaFresca',\r\n",
    "       'Freq_Consumo_Carne', 'Freq_Consumo_Huevos', 'Freq_Consumo_Pescado',\r\n",
    "       'Freq_Consumo_PastaArrozPatatas', 'Freq_Consumo_PanCereales',\r\n",
    "       'Freq_Consumo_VerdurasEnsaladasHortalizas', 'Freq_Consumo_Legumbres',\r\n",
    "       'Freq_Consumo_EmbutidosFiambres', 'Freq_Consumo_Lácteos',\r\n",
    "       'Freq_Consumo_Dulces', 'Freq_Consumo_ComidaRápida',\r\n",
    "       'Freq_Consumo_ZumoNatural', 'Freq_Diaria_CepilladoDientes',\r\n",
    "       '¿Fuma actualmente', 'Freq_Consumo_Alcohol',\r\n",
    "       'ApoyoAfectivoPersonal_AmigosFamiliares', 'ClaseSocial_BasadaOcupación',\r\n",
    "       'Índice_MasaCorporal']]\r\n",
    "\r\n",
    "y = ENS_2017_C1['Salud_percibida']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\r\n",
    "\r\n",
    "scaler_train = StandardScaler().fit(X_train)\r\n",
    "X_train = scaler_train.transform(X_train)\r\n",
    "\r\n",
    "scaler_test = StandardScaler().fit(X_train)\r\n",
    "X_test = scaler_test.transform(X_test)\r\n",
    "\r\n",
    "scaler_total = StandardScaler().fit(X)\r\n",
    "X = scaler_total.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Clúster: 1')\r\n",
    "\r\n",
    "model = models.Sequential()\r\n",
    "model.add(layers.Dense(32, activation='relu', input_shape = (34,)))\r\n",
    "model.add(layers.Dense(10, activation='relu'))\r\n",
    "model.add(layers.Dense(4,activation='softmax'))\r\n",
    "\r\n",
    "model.compile(optimizer='adam',\r\n",
    "              loss='sparse_categorical_crossentropy', \r\n",
    "              metrics=['accuracy']) \r\n",
    "\r\n",
    "model.fit(X_train, y_train, epochs=100)\r\n",
    "\r\n",
    "test_loss, test_acc = model.evaluate(X_train,  y_train, verbose=2)\r\n",
    "print('\\nTrain accuracy:', test_acc)\r\n",
    "\r\n",
    "model.fit(X_test, y_test, epochs=100)\r\n",
    "test_loss, test_acc = model.evaluate(X_test,  y_test, verbose=2)\r\n",
    "\r\n",
    "print('\\nTest accuracy:', test_acc)\r\n",
    "\r\n",
    "model.fit(X, y, epochs=100)\r\n",
    "test_loss, test_acc = model.evaluate(X,  y, verbose=2)\r\n",
    "\r\n",
    "print('\\nTotal accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENS_2017_C2 = pd.read_csv(\"../data/Bases_trabajo/ENS_2017_C2.csv\", sep =',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ENS_2017_C2[['CCAA', 'Sexo', 'Edad',\r\n",
    "       'Actividad_economica_actual', 'Nacionalidad_española', 'Convivencia',\r\n",
    "       'Estado_civil', 'Nivel_estudios', 'Vacunación_gripe',\r\n",
    "       'Toma_tensiónArterial_profesional', 'Medición_colesterol',\r\n",
    "       'Prueba_sangreHeces', 'Colonoscopia', 'Peso(Kg)',\r\n",
    "       'Freq_ActividadFísica', 'Freq_Consumo_FrutaFresca',\r\n",
    "       'Freq_Consumo_Carne', 'Freq_Consumo_Huevos', 'Freq_Consumo_Pescado',\r\n",
    "       'Freq_Consumo_PastaArrozPatatas', 'Freq_Consumo_PanCereales',\r\n",
    "       'Freq_Consumo_VerdurasEnsaladasHortalizas', 'Freq_Consumo_Legumbres',\r\n",
    "       'Freq_Consumo_EmbutidosFiambres', 'Freq_Consumo_Lácteos',\r\n",
    "       'Freq_Consumo_Dulces', 'Freq_Consumo_ComidaRápida',\r\n",
    "       'Freq_Consumo_ZumoNatural', 'Freq_Diaria_CepilladoDientes',\r\n",
    "       '¿Fuma actualmente', 'Freq_Consumo_Alcohol',\r\n",
    "       'ApoyoAfectivoPersonal_AmigosFamiliares', 'ClaseSocial_BasadaOcupación',\r\n",
    "       'Índice_MasaCorporal']]\r\n",
    "\r\n",
    "y = ENS_2017_C2['Salud_percibida']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\r\n",
    "\r\n",
    "scaler_train = StandardScaler().fit(X_train)\r\n",
    "X_train = scaler_train.transform(X_train)\r\n",
    "\r\n",
    "scaler_test = StandardScaler().fit(X_train)\r\n",
    "X_test = scaler_test.transform(X_test)\r\n",
    "\r\n",
    "scaler_total = StandardScaler().fit(X)\r\n",
    "X = scaler_total.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Clúster: 2')\r\n",
    "\r\n",
    "model = models.Sequential()\r\n",
    "model.add(layers.Dense(32, activation='relu', input_shape = (34,)))\r\n",
    "model.add(layers.Dense(10, activation='relu'))\r\n",
    "model.add(layers.Dense(4,activation='softmax'))\r\n",
    "\r\n",
    "model.compile(optimizer='adam',\r\n",
    "              loss='sparse_categorical_crossentropy', \r\n",
    "              metrics=['accuracy']) \r\n",
    "\r\n",
    "model.fit(X_train, y_train, epochs=100)\r\n",
    "\r\n",
    "test_loss, test_acc = model.evaluate(X_train,  y_train, verbose=2)\r\n",
    "print('\\nTrain accuracy:', test_acc)\r\n",
    "\r\n",
    "model.fit(X_test, y_test, epochs=100)\r\n",
    "test_loss, test_acc = model.evaluate(X_test,  y_test, verbose=2)\r\n",
    "\r\n",
    "print('\\nTest accuracy:', test_acc)\r\n",
    "\r\n",
    "model.fit(X, y, epochs=100)\r\n",
    "test_loss, test_acc = model.evaluate(X,  y, verbose=2)\r\n",
    "\r\n",
    "print('\\nTotal accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENS_2017_C = pd.read_csv(\"../data/Bases_trabajo/ENS_2017_C.csv\", sep =',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ENS_2017_C[['CCAA', 'Sexo', 'Edad',\r\n",
    "       'Actividad_economica_actual', 'Nacionalidad_española', 'Convivencia',\r\n",
    "       'Estado_civil', 'Nivel_estudios', 'Vacunación_gripe',\r\n",
    "       'Toma_tensiónArterial_profesional', 'Medición_colesterol',\r\n",
    "       'Prueba_sangreHeces', 'Colonoscopia', 'Peso(Kg)',\r\n",
    "       'Freq_ActividadFísica', 'Freq_Consumo_FrutaFresca',\r\n",
    "       'Freq_Consumo_Carne', 'Freq_Consumo_Huevos', 'Freq_Consumo_Pescado',\r\n",
    "       'Freq_Consumo_PastaArrozPatatas', 'Freq_Consumo_PanCereales',\r\n",
    "       'Freq_Consumo_VerdurasEnsaladasHortalizas', 'Freq_Consumo_Legumbres',\r\n",
    "       'Freq_Consumo_EmbutidosFiambres', 'Freq_Consumo_Lácteos',\r\n",
    "       'Freq_Consumo_Dulces', 'Freq_Consumo_ComidaRápida',\r\n",
    "       'Freq_Consumo_ZumoNatural', 'Freq_Diaria_CepilladoDientes',\r\n",
    "       '¿Fuma actualmente', 'Freq_Consumo_Alcohol',\r\n",
    "       'ApoyoAfectivoPersonal_AmigosFamiliares', 'ClaseSocial_BasadaOcupación',\r\n",
    "       'Índice_MasaCorporal']]\r\n",
    "\r\n",
    "y = ENS_2017_C['Salud_percibida']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\r\n",
    "\r\n",
    "scaler_train = StandardScaler().fit(X_train)\r\n",
    "X_train = scaler_train.transform(X_train)\r\n",
    "\r\n",
    "scaler_test = StandardScaler().fit(X_train)\r\n",
    "X_test = scaler_test.transform(X_test)\r\n",
    "\r\n",
    "scaler_total = StandardScaler().fit(X)\r\n",
    "X = scaler_total.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Base total')\r\n",
    "\r\n",
    "model = models.Sequential()\r\n",
    "model.add(layers.Dense(32, activation='relu', input_shape = (34,)))\r\n",
    "model.add(layers.Dense(10, activation='relu'))\r\n",
    "model.add(layers.Dense(4,activation='softmax'))\r\n",
    "\r\n",
    "model.compile(optimizer='adam',\r\n",
    "              loss='sparse_categorical_crossentropy', \r\n",
    "              metrics=['accuracy']) \r\n",
    "\r\n",
    "model.fit(X_train, y_train, epochs=100)\r\n",
    "\r\n",
    "test_loss, test_acc = model.evaluate(X_train,  y_train, verbose=2)\r\n",
    "print('\\nTrain accuracy:', test_acc)\r\n",
    "\r\n",
    "model.fit(X_test, y_test, epochs=100)\r\n",
    "test_loss, test_acc = model.evaluate(X_test,  y_test, verbose=2)\r\n",
    "\r\n",
    "print('\\nTest accuracy:', test_acc)\r\n",
    "\r\n",
    "model.fit(X, y, epochs=100)\r\n",
    "test_loss, test_acc = model.evaluate(X,  y, verbose=2)\r\n",
    "\r\n",
    "print('\\nTotal accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusión Modelo Red neuronal \r\n",
    "## No es un buen modelo para los datos de los que se parten: \r\n",
    "## Accuracy_test: 0.6951\r\n",
    "## loss: 0.7066"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..............................................."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Una vez determinados los modelos con mejores resultados con todas las variables (SVC y Decission Tree Classifier). Utilizamos el modelo Gridsearch para identificar cual de ellos sería el mejor con las variables más importantes detectadas por el modelo Decission Tree Classifier. Esto es: \r\n",
    "\r\n",
    "### - Actividad económica actual (importancia: 0.436375),\r\n",
    "### - Frecuencia de consumo de carne (importancia: 0.200046), \r\n",
    "### - Nacionalidad (española, extranjera)(importancia: 0.146553)\r\n",
    "### - Clase social basada en la ocupación (importancia: 0.116566)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Este modelo lo utilizaremos con la base completa ya que el análisis anterior en el que se ha tenido en cuenta las posibles diferencias entre los diferenes grupos de clústers no se han encontrado diferencias de interés entre ellos en los resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\r\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENS_2017_C_agr = pd.read_csv(\"../data/Bases_trabajo/ENS_2017_C_agr.csv\", sep =',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ENS_2017_C_agr[['Actividad_economica_actual', 'Nacionalidad_española', 'Convivencia',\r\n",
    "       'Freq_Consumo_Carne', 'ClaseSocial_BasadaOcupación']]\r\n",
    "\r\n",
    "y = ENS_2017_C_agr['Salud_percibida']   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introducimos los dos modelos que se van a comparar con los parámetros con los que se obtuvieron mejores resultados\r\n",
    "pipe = Pipeline(steps=[('classifier', DecisionTreeClassifier())])\r\n",
    "\r\n",
    "\r\n",
    "decision_tree_params = {\r\n",
    "    'classifier': [DecisionTreeClassifier()],\r\n",
    "    }\r\n",
    "\r\n",
    "svm_params = {\r\n",
    "    'classifier': [svm.SVC()],\r\n",
    "    'classifier__kernel':('rbf', ), \r\n",
    "    'classifier__C':[10, ], \r\n",
    "    'classifier__gamma': [1, ]\r\n",
    "    }\r\n",
    "\r\n",
    "# Creamos el espacio de aprendizaje de los algoritmos que se van a comparar y sus hiperparámetros\r\n",
    "search_space = [\r\n",
    "    decision_tree_params,\r\n",
    "    svm_params\r\n",
    "    ]\r\n",
    "\r\n",
    "# Creamos grid search\r\n",
    "clf = GridSearchCV(estimator=pipe, param_grid=search_space, verbose=0, n_jobs=-1)\r\n",
    "\r\n",
    "# Fijamos el modelo\r\n",
    "best_model = clf.fit(X_train, y_train)\r\n",
    "prediction_train = best_model.predict(X_train)\r\n",
    "\r\n",
    "# Vemos el mejor modelo\r\n",
    "separator = \"\\n############################\\n\"\r\n",
    "print(separator)\r\n",
    "print(\"best estimator:\", best_model.best_estimator_.get_params()['classifier'])\r\n",
    "print(separator)\r\n",
    "print(\"clf.best_params_\", clf.best_params_)\r\n",
    "print(separator)\r\n",
    "# Score del mejor modelo\r\n",
    "print(\"clf.best_score\", clf.best_score_)\r\n",
    "# Exactitud del modelo\r\n",
    "print (\"Exactitud training data:\", accuracy_score (y_true = y_train, y_pred = prediction_train))\r\n",
    "\r\n",
    "\r\n",
    "# Fijamos el modelo\r\n",
    "best_model = clf.fit(X_test, y_test)\r\n",
    "prediction_test = best_model.predict(X_test)\r\n",
    "\r\n",
    "# Vemos el mejor modelo\r\n",
    "separator = \"\\n############################\\n\"\r\n",
    "print(separator)\r\n",
    "print(\"best estimator:\", best_model.best_estimator_.get_params()['classifier'])\r\n",
    "print(separator)\r\n",
    "print(\"clf.best_params_\", clf.best_params_)\r\n",
    "print(separator)\r\n",
    "# Score del mejor modelo\r\n",
    "print(\"clf.best_score\", clf.best_score_)\r\n",
    "# Exactitud del modelo\r\n",
    "print (\"Exactitud test data:\", accuracy_score (y_true = y_test, y_pred = prediction_test))\r\n",
    "\r\n",
    "# Fijamos el modelo\r\n",
    "best_model = clf.fit(X, y)\r\n",
    "prediction_total = best_model.predict(X)\r\n",
    "\r\n",
    "# Vemos el mejor modelo\r\n",
    "separator = \"\\n############################\\n\"\r\n",
    "print(separator)\r\n",
    "print(\"best estimator:\", best_model.best_estimator_.get_params()['classifier'])\r\n",
    "print(separator)\r\n",
    "print(\"clf.best_params_\", clf.best_params_)\r\n",
    "print(separator)\r\n",
    "# Score del mejor modelo\r\n",
    "print(\"clf.best_score\", clf.best_score_)\r\n",
    "# Exactitud del modelo\r\n",
    "print (\"Exactitud total data:\", accuracy_score (y_true = y, y_pred = prediction_total))\r\n",
    "\r\n",
    "#SAVE MODEL\r\n",
    "# save the model to disk\r\n",
    "# filename = 'finished_model.sav'\r\n",
    "# pickle.dump(best_model, open(filename, 'wb'))\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Los resultados obtenidos son: \r\n",
    "### El modelo SVC (kernel = rbf, C = 10 y gamma = 1) es el mejor modelo para los datos de entrenamiento y el de Decission tree classifier para los datos de test y el total de la base.\r\n",
    "\r\n",
    "### En todos los casos el score se situa en torno a 0.65 y la exactitud de la predicción en torno a 0.68\r\n",
    "\r\n",
    "### SVC:\r\n",
    "###     clf.best_score 0.6651\r\n",
    "###     Exactitud training data: 0.6832\r\n",
    "...................................................\r\n",
    "### Decission Tree Classifier:\r\n",
    "###     clf.best_score 0.6472\r\n",
    "###     Exactitud test data: 0.6998\r\n",
    "...............\r\n",
    "###     clf.best_score 0.6648\r\n",
    "###     Exactitud total data: 0.6809\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finalmente valoramos si utilizando conjuntamente los dos modelos se mejora el score y la exactitud utilizando las 4 variables más importantes. \r\n",
    "\r\n",
    "### Utilizaremos en este caso el modelo: voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\r\n",
    "from sklearn.tree import DecisionTreeClassifier\r\n",
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENS_2017_C_agr = pd.read_csv(\"../data/Bases_trabajo/ENS_2017_C_agr.csv\", sep =',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ENS_2017_C_agr[['Actividad_economica_actual', 'Nacionalidad_española', 'Convivencia',\r\n",
    "       'Freq_Consumo_Carne', 'ClaseSocial_BasadaOcupación']]\r\n",
    "\r\n",
    "y = ENS_2017_C_agr['Salud_percibida']   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\r\n",
    "from sklearn.tree import DecisionTreeClassifier\r\n",
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hard voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_clf = DecisionTreeClassifier(random_state=42)\r\n",
    "svm_clf = SVC(C = 10, gamma=1, kernel = 'rbf', random_state=42)\r\n",
    "\r\n",
    "estimators = [('dtc', dtc_clf), ('svc', svm_clf)]\r\n",
    "\r\n",
    "voting_clf = VotingClassifier(estimators = estimators,\r\n",
    "                             voting='hard')\r\n",
    "\r\n",
    "print ('Train')\r\n",
    "\r\n",
    "voting_clf.fit(X_train, y_train)\r\n",
    "\r\n",
    "for clf in (dtc_clf, svm_clf, voting_clf):\r\n",
    "    clf.fit(X_train, y_train)\r\n",
    "    y_pred_train = clf.predict(X_train)\r\n",
    "    print(clf.__class__.__name__, accuracy_score(y_train, y_pred_train))\r\n",
    "\r\n",
    "print ('Test')\r\n",
    "\r\n",
    "voting_clf.fit(X_test, y_test)\r\n",
    "\r\n",
    "for clf in (dtc_clf, svm_clf, voting_clf):\r\n",
    "    clf.fit(X_test, y_test)\r\n",
    "    y_pred_test = clf.predict(X_test)\r\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred_test))\r\n",
    "\r\n",
    "print ('Total')\r\n",
    "\r\n",
    "voting_clf.fit(X, y)\r\n",
    "\r\n",
    "for clf in (dtc_clf, svm_clf, voting_clf):\r\n",
    "    clf.fit(X, y)\r\n",
    "    y_pred_total = clf.predict(X)\r\n",
    "    print(clf.__class__.__name__, accuracy_score(y, y_pred_total))\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Soft voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_clf = DecisionTreeClassifier(random_state=42)\r\n",
    "svm_clf = SVC(C = 10, gamma=1, kernel = 'rbf', probability = True, random_state=42)\r\n",
    "\r\n",
    "estimators = [('dtc', dtc_clf), ('svc', svm_clf)]\r\n",
    "\r\n",
    "voting_clf = VotingClassifier(estimators = estimators,\r\n",
    "                             voting='soft')\r\n",
    "\r\n",
    "print ('Train')\r\n",
    "\r\n",
    "voting_clf.fit(X_train, y_train)\r\n",
    "\r\n",
    "for clf in (dtc_clf, svm_clf, voting_clf):\r\n",
    "    clf.fit(X_train, y_train)\r\n",
    "    y_pred_train = clf.predict(X_train)\r\n",
    "    print(clf.__class__.__name__, accuracy_score(y_train, y_pred_train))\r\n",
    "\r\n",
    "print ('Test')\r\n",
    "\r\n",
    "voting_clf.fit(X_test, y_test)\r\n",
    "\r\n",
    "for clf in (dtc_clf, svm_clf, voting_clf):\r\n",
    "    clf.fit(X_test, y_test)\r\n",
    "    y_pred_test = clf.predict(X_test)\r\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred_test))\r\n",
    "\r\n",
    "print ('Total')\r\n",
    "\r\n",
    "voting_clf.fit(X, y)\r\n",
    "\r\n",
    "for clf in (dtc_clf, svm_clf, voting_clf):\r\n",
    "    clf.fit(X, y)\r\n",
    "    y_pred_total = clf.predict(X)\r\n",
    "    print(clf.__class__.__name__, accuracy_score(y, y_pred_total))\r\n",
    "\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Los resultados utilizando conjuntamente ambos algoritmos mejoran ligeramente. La exactitud en la estimación (accuracy_score) con este modelo es (no varían si el modelo es hard o soft):\r\n",
    "\r\n",
    "### VotingClassifier: 0.6957\r\n",
    "\r\n",
    "### Teniendo en cuenta que con grid search, el modelo de SVC es mejor con los datos de entrenamiento y el de Decission Tree Classifier con los de test, se considera más adecuado utiizarlos conjuntamente a pesar de no detectarse importantes diferencias en la precisión de la predicción.\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    " "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7980ba124835d5faa10419b5aaaaec0d5be537aa3d05dd29d745d0092f32015f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}